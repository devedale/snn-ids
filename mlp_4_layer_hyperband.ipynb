{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Panoramica dei test privacy-preserving\n",
        "\n",
        "Questa sezione estende il notebook con una guida organica ai 5 scenari A–E, una sintesi teorica di Differential Privacy (DP) e Homomorphic Encryption (HE), e codice eseguibile per caricare e verificare i risultati di ciascuno scenario.\n",
        "\n",
        "- **Scopo**: rendere riproducibili e verificabili i test, con spiegazioni e controlli rapidi.\n",
        "- **Cosa trovi qui**:\n",
        "  - **Setup rapido** per import e percorsi.\n",
        "  - **Relazioni teoriche** tra HE e DP e il loro impatto atteso.\n",
        "  - **Caricamento summary esteso** con metriche aggiuntive (rounds, HE banda, DP, ecc.).\n",
        "  - **Utility per scenari A–E**: contesto, assunti, risultati attesi e funzione di check.\n",
        "  - **Codice per eseguire i controlli** per ogni scenario in modo indipendente.\n",
        "\n",
        "Nota: non rimuoviamo sezioni esistenti; aggiungiamo solo contenuti integrativi e non distruttivi.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup rapido: import, percorsi, utilità\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "BASE = Path(\"experiments_privacy\")\n",
        "RES_DIR = BASE / \"results\"\n",
        "SUMMARY_JSON = RES_DIR / \"summary.json\"\n",
        "SUMMARY_CSV = RES_DIR / \"summary.csv\"\n",
        "\n",
        "# Caricamento summary esteso (generato da experiments_privacy/shared/summary.py)\n",
        "def load_extended_summary():\n",
        "    if SUMMARY_JSON.exists():\n",
        "        with open(SUMMARY_JSON, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "        return pd.DataFrame(data)\n",
        "    elif SUMMARY_CSV.exists():\n",
        "        return pd.read_csv(SUMMARY_CSV)\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Nessun summary trovato. Esegui summarize_and_save prima.\")\n",
        "\n",
        "extended_summary_df = None\n",
        "try:\n",
        "    extended_summary_df = load_extended_summary()\n",
        "    display(extended_summary_df)\n",
        "except Exception as e:\n",
        "    print(\"[WARN] Impossibile caricare summary esteso:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Relazioni teoriche: Differential Privacy (DP) e Homomorphic Encryption (HE)\n",
        "\n",
        "- **DP**: garantisce privacy aggiungendo rumore controllato. Nella pratica (DP-SGD o varianti) introduce un trade-off tra **accuratezza** e **privacy**; la privacy è parametrizzata da \\(\\epsilon\\) (più basso = maggiore privacy) e \\(\\delta\\). Atteso: un calo di accuracy all'aumentare del rumore, con tempi simili di training locale, ma potenziale necessità di più round.\n",
        "- **HE**: cifratura omomorfica per eseguire operazioni su dati cifrati. Qui stimiamo l'overhead di comunicazione (dimensione ciphertext). Atteso: **accuracy invariata** (se si cifrano solo pesi/aggiornamenti), **overhead in banda** e possibili costi computazionali.\n",
        "- **DP + HE**: composizione in cui DP protegge i gradienti/pesi e HE protegge il **transito** e l'aggregazione. Atteso: combinazione degli effetti, con accuracy calante per DP e banda crescente per HE.\n",
        "\n",
        "Dove si riflette nel nostro codice:\n",
        "- `use_dp` controlla rumore/clipping su pesi locali.\n",
        "- `use_he` abilita la stima `he_round_overheads` con dimensioni ciphertext per round.\n",
        "- Nel summary esteso aggiungiamo colonne: `Epsilon`, `Delta`, `UseDP`, `UseHE`, `HE_MB_per_round`, `HE_MB_total`, `HE_MB_per_sec` e statistiche dei tempi per round.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility: loader e checker per scenari A–E\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "def load_scenario_row(df: pd.DataFrame, scenario: str) -> Optional[pd.Series]:\n",
        "    if df is None:\n",
        "        return None\n",
        "    rows = df[df[\"Scenario\"] == scenario]\n",
        "    if len(rows) == 0:\n",
        "        return None\n",
        "    return rows.iloc[0]\n",
        "\n",
        "\n",
        "def check_scenario(df: pd.DataFrame, scenario: str, expectations: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Verifica regole base per uno scenario.\n",
        "    expectations: dict con chiavi opzionali tra:\n",
        "      - expect_use_dp (bool)\n",
        "      - expect_use_he (bool)\n",
        "      - min_accuracy (float) / max_accuracy (float)\n",
        "      - max_he_mb_per_round (float)\n",
        "      - expect_epsilon_not_null (bool)\n",
        "    \"\"\"\n",
        "    res = {\"scenario\": scenario, \"passed\": True, \"violations\": []}\n",
        "    row = load_scenario_row(df, scenario)\n",
        "    if row is None:\n",
        "        res[\"passed\"] = False\n",
        "        res[\"violations\"].append(\"scenario non trovato nel summary\")\n",
        "        return res\n",
        "    # Regole\n",
        "    if \"expect_use_dp\" in expectations and not pd.isna(row.get(\"UseDP\")):\n",
        "        if bool(row.get(\"UseDP\")) != bool(expectations[\"expect_use_dp\"]):\n",
        "            res[\"passed\"] = False\n",
        "            res[\"violations\"].append(f\"UseDP atteso {expectations['expect_use_dp']}, trovato {row.get('UseDP')}\")\n",
        "    if \"expect_use_he\" in expectations and not pd.isna(row.get(\"UseHE\")):\n",
        "        if bool(row.get(\"UseHE\")) != bool(expectations[\"expect_use_he\"]):\n",
        "            res[\"passed\"] = False\n",
        "            res[\"violations\"].append(f\"UseHE atteso {expectations['expect_use_he']}, trovato {row.get('UseHE')}\")\n",
        "    if \"min_accuracy\" in expectations and not pd.isna(row.get(\"Accuracy\")):\n",
        "        if float(row.get(\"Accuracy\")) < float(expectations[\"min_accuracy\"]):\n",
        "            res[\"passed\"] = False\n",
        "            res[\"violations\"].append(f\"Accuracy {row.get('Accuracy'):.3f} < min {expectations['min_accuracy']}\")\n",
        "    if \"max_accuracy\" in expectations and not pd.isna(row.get(\"Accuracy\")):\n",
        "        if float(row.get(\"Accuracy\")) > float(expectations[\"max_accuracy\"]):\n",
        "            res[\"passed\"] = False\n",
        "            res[\"violations\"].append(f\"Accuracy {row.get('Accuracy'):.3f} > max {expectations['max_accuracy']}\")\n",
        "    if \"max_he_mb_per_round\" in expectations and not pd.isna(row.get(\"HE_MB_per_round\")):\n",
        "        if float(row.get(\"HE_MB_per_round\")) > float(expectations[\"max_he_mb_per_round\"]):\n",
        "            res[\"passed\"] = False\n",
        "            res[\"violations\"].append(f\"HE_MB_per_round {row.get('HE_MB_per_round'):.3f} > max {expectations['max_he_mb_per_round']}\")\n",
        "    if expectations.get(\"expect_epsilon_not_null\", False):\n",
        "        if pd.isna(row.get(\"Epsilon\")):\n",
        "            res[\"passed\"] = False\n",
        "            res[\"violations\"].append(\"Epsilon atteso non nullo, trovato NULL\")\n",
        "    res[\"row\"] = row\n",
        "    return res\n",
        "\n",
        "# Esempio veloce (non fallisce se summary manca)\n",
        "if extended_summary_df is not None:\n",
        "    print(check_scenario(extended_summary_df, \"A\", {\"expect_use_dp\": False, \"expect_use_he\": False}))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scenari A–E: contesto, assunti, risultati attesi\n",
        "\n",
        "Di seguito formalizziamo i 5 scenari e aggiungiamo per ciascuno un controllo automatico. Gli attesi sono qualitativi e vanno tarati sul dataset e sui risultati reali.\n",
        "\n",
        "- **Scenario A (Centralizzato - baseline)**\n",
        "  - **Contesto**: training centralizzato senza DP/HE.\n",
        "  - **Assunti**: massima accuracy rispetto ad altri scenari; tempi minori rispetto a FL.\n",
        "  - **Risultati attesi**: `UseDP=False`, `UseHE=False`, accuracy di riferimento per `Acc_vs_A=0`.\n",
        "\n",
        "- **Scenario B (FL senza privacy)**\n",
        "  - **Contesto**: Federated Learning standard (FedAvg), senza DP/HE.\n",
        "  - **Assunti**: accuracy inferiore a A ma ragionevole; latenza per round > 0.\n",
        "  - **Risultati attesi**: `UseDP=False`, `UseHE=False`, `HE_MB_per_round` nullo.\n",
        "\n",
        "- **Scenario C (FL + HE stimato)**\n",
        "  - **Contesto**: FL con stima overhead HE per comunicazione cifrata.\n",
        "  - **Assunti**: accuracy simile a B; `HE_MB_per_round > 0` e `HE_MB_total` > 0.\n",
        "  - **Risultati attesi**: `UseHE=True`, `UseDP=False`.\n",
        "\n",
        "- **Scenario D (FL + DP)**\n",
        "  - **Contesto**: FL con rumore DP e clipping; no HE.\n",
        "  - **Assunti**: accuracy più bassa di B; `Epsilon` e `Delta` presenti.\n",
        "  - **Risultati attesi**: `UseDP=True`, `UseHE=False`, `HE_MB_per_round` nullo.\n",
        "\n",
        "- **Scenario E (FL + DP + HE stimato)**\n",
        "  - **Contesto**: FL con DP e stima HE per la comunicazione.\n",
        "  - **Assunti**: accuracy ≤ D (o simile); `HE_MB_per_round > 0`.\n",
        "  - **Risultati attesi**: `UseDP=True`, `UseHE=True`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Controlli eseguibili per ciascuno scenario\n",
        "\n",
        "def scenario_expectations():\n",
        "    \"\"\"Definizione sintetica delle attese per gli scenari A–E.\n",
        "    Regola i threshold in base ai risultati correnti se necessario.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"A\": {\"expect_use_dp\": False, \"expect_use_he\": False, \"min_accuracy\": 0.70},\n",
        "        \"B\": {\"expect_use_dp\": False, \"expect_use_he\": False, \"min_accuracy\": 0.45},\n",
        "        \"C\": {\"expect_use_dp\": False, \"expect_use_he\": True,  \"min_accuracy\": 0.45, \"max_he_mb_per_round\": 20.0},\n",
        "        \"D\": {\"expect_use_dp\": True,  \"expect_use_he\": False, \"expect_epsilon_not_null\": True, \"max_accuracy\": 0.80},\n",
        "        \"E\": {\"expect_use_dp\": True,  \"expect_use_he\": True,  \"expect_epsilon_not_null\": True, \"max_he_mb_per_round\": 20.0}\n",
        "    }\n",
        "\n",
        "\n",
        "def run_all_checks(df: pd.DataFrame):\n",
        "    exp = scenario_expectations()\n",
        "    results = {}\n",
        "    for sc in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
        "        try:\n",
        "            results[sc] = check_scenario(df, sc, exp.get(sc, {}))\n",
        "        except Exception as e:\n",
        "            results[sc] = {\"scenario\": sc, \"passed\": False, \"violations\": [str(e)]}\n",
        "    return results\n",
        "\n",
        "if extended_summary_df is not None:\n",
        "    checks = run_all_checks(extended_summary_df)\n",
        "    for sc, out in checks.items():\n",
        "        status = \"OK\" if out[\"passed\"] else \"FAIL\"\n",
        "        print(f\"Scenario {sc}: {status} -> {out['violations']}\")\n",
        "else:\n",
        "    print(\"[INFO] Nessun summary caricato: salta controlli.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modalità HE: stima vs cifratura reale\n",
        "\n",
        "Ora la pipeline supporta due modalità:\n",
        "- `HE_Mode = estimate`: calcola solo la dimensione attesa dei ciphertext senza cifrare.\n",
        "- `HE_Mode = encrypt`: cifra realmente, somma omomorficamente e decifra l'aggregato.\n",
        "\n",
        "Nel summary vedremo tempi medi aggiuntivi: `HE_EncTimeMean_s`, `HE_AggTimeMean_s`, `HE_DecTimeMean_s`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tubFoHhBrKhH"
      },
      "source": [
        "# SNN-IDS Audit Notebook (CSE-CIC-IDS2018)\n",
        "\n",
        "Questo notebook è pensato per essere auditabile: ogni scelta è documentata file-per-file e riga-per-riga dove rilevante. Include:\n",
        "- Setup ambiente e dati\n",
        "- Pipeline dati riproducibile\n",
        "- Training recipe ottimizzata per tabulari (GRU per finestre temporali)\n",
        "- Metriche e calibrazione\n",
        "- Smoke test e test completo (finestre: 5s, 1m, 5m; LR grid)\n",
        "\n",
        "Note: il codice vive nel repository; il notebook chiama le funzioni senza duplicazioni di logica.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2PlK70ErKhI"
      },
      "source": [
        "## 1) Setup ambiente\n",
        "\n",
        "Requisiti minimi:\n",
        "- Python 3.10+\n",
        "- pacchetti: pandas, numpy, scikit-learn, tensorflow, matplotlib, seaborn, tqdm\n",
        "\n",
        "In Colab eseguire le celle seguenti; in locale assicurarsi che `pip install -r requirements.txt` sia stato eseguito.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r4T4UilrKhI",
        "outputId": "ae813989-7375-4c10-d46a-1f753311d007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'snn-ids'...\n",
            "remote: Enumerating objects: 921, done.\u001b[K\n",
            "remote: Counting objects: 100% (570/570), done.\u001b[K\n",
            "remote: Compressing objects: 100% (314/314), done.\u001b[K\n",
            "remote: Total 921 (delta 258), reused 520 (delta 219), pack-reused 351 (from 2)\u001b[K\n",
            "Receiving objects: 100% (921/921), 62.45 MiB | 28.91 MiB/s, done.\n",
            "Resolving deltas: 100% (431/431), done.\n",
            "/content/snn-ids\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: tensorflow>=2.15 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.19.0)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.66 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Collecting keras-tuner>=1.4.0 (from -r requirements.txt (line 8))\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3->-r requirements.txt (line 3)) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3->-r requirements.txt (line 3)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15->-r requirements.txt (line 4)) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 5)) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 5)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 5)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 5)) (3.2.3)\n",
            "Collecting kt-legacy (from keras-tuner>=1.4.0->-r requirements.txt (line 8))\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.15->-r requirements.txt (line 4)) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15->-r requirements.txt (line 4)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15->-r requirements.txt (line 4)) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15->-r requirements.txt (line 4)) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15->-r requirements.txt (line 4)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15->-r requirements.txt (line 4)) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15->-r requirements.txt (line 4)) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15->-r requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.15->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15->-r requirements.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15->-r requirements.txt (line 4)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.15->-r requirements.txt (line 4)) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "# Se sei in Colab, decommenta le righe seguenti\n",
        "#!git clone --single-branch --branch feat/hyperband-search https://github.com/devedale/snn-ids.git\n",
        "!git clone https://github.com/devedale/snn-ids.git\n",
        "#!git clone https://github.com/devedale/snn-ids.git\n",
        "%cd snn-ids\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt96ICs4rKhI"
      },
      "source": [
        "## 2) Setup dati\n",
        "Scarica i CSV CSE-CIC-IDS2018 nelle cartelle già attese da `config.py` (attualmente configurato sul path`/content/snn-ids/data`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3pB2J0bIsBn"
      },
      "outputs": [],
      "source": [
        "# Importa librerie del progetto\n",
        "import os, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from config import DATA_CONFIG, PREPROCESSING_CONFIG, TRAINING_CONFIG, BENCHMARK_CONFIG\n",
        "from preprocessing.process import preprocess_pipeline\n",
        "from training.train import train_model\n",
        "from evaluation.metrics import evaluate_model_comprehensive\n",
        "\n",
        "print(\"Config dataset:\", DATA_CONFIG[\"dataset_path\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvtEwC7mrKhI",
        "outputId": "9e083d99-28e3-451d-b599-3ae0ea8d45f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  9.8G  100  9.8G    0     0  73.7M      0  0:02:17  0:02:17 --:--:-- 71.6M\n",
            "Archive:  ./preprocessed_cache/preprocessed_cache.zip\n",
            "  inflating: ./preprocessed_cache/Friday-02-03-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Friday-02-03-2018/benign_records.csv  \n",
            "  inflating: ./preprocessed_cache/Friday-16-02-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Friday-16-02-2018/benign_records.csv  \n",
            "  inflating: ./preprocessed_cache/Friday-23-02-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Friday-23-02-2018/benign_records.csv  \n",
            "  inflating: ./preprocessed_cache/Thursday-01-03-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Thursday-01-03-2018/benign_records.csv  \n",
            "  inflating: ./preprocessed_cache/Thursday-15-02-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Thursday-15-02-2018/benign_records.csv  \n",
            "  inflating: ./preprocessed_cache/Thursday-22-02-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Thursday-22-02-2018/benign_records.csv  \n",
            "  inflating: ./preprocessed_cache/Tuesday-20-02-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Tuesday-20-02-2018/benign_records.csv  \n",
            "  inflating: ./preprocessed_cache/Wednesday-14-02-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Wednesday-14-02-2018/benign_records.csv  \n",
            "  inflating: ./preprocessed_cache/Wednesday-21-02-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Wednesday-21-02-2018/benign_records.csv  \n",
            "  inflating: ./preprocessed_cache/Wednesday-28-02-2018/attack_records.csv  \n",
            "  inflating: ./preprocessed_cache/Wednesday-28-02-2018/benign_records.csv  \n"
          ]
        }
      ],
      "source": [
        "#Uncomment to download full starting dataset\n",
        "#!curl -L -o ./data/cicids2018.zip  https://www.kaggle.com/api/v1/datasets/download/edoardodalesio/intrusion-detection-evaluation-dataset-cic-ids2018\n",
        "#!unzip -o ./data/cicids2018.zip  \"Tuesday-20-02-2018.csv\"   \"Wednesday-21-02-2018.csv\"  \"Thursday-22-02-2018.csv\" \"Friday-23-02-2018.csv\" -d ./data # or #!unzip -o ./data/cicids2018.zip -d ./data\n",
        "\n",
        "\n",
        "\n",
        "#Uncomment to use preprocessed cache\n",
        "!mkdir preprocessed_cache\n",
        "!curl -L -o ./preprocessed_cache/preprocessed_cache.zip  https://www.kaggle.com/api/v1/datasets/download/edoardodalesio/cic-ids-2018-benign-vs-attack\n",
        "!unzip -o ./preprocessed_cache/preprocessed_cache.zip -d ./preprocessed_cache\n",
        "!touch data/Friday-02-03-2018.csv data/Friday-16-02-2018.csv data/Friday-23-02-2018.csv data/Thursday-01-03-2018.csv data/Thursday-15-02-2018.csv data/Thursday-22-02-2018.csv data/Tuesday-20-02-2018.csv data/Wednesday-14-02-2018.csv data/Wednesday-21-02-2018.csv data/Wednesday-28-02-2018.csv\n",
        "#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpasXbqmCqz6",
        "outputId": "3ffff5a2-0109-4598-c4ef-29de3e5536c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 319ms/step - accuracy: 0.0218 - loss: 3872229.2500 - val_accuracy: 0.0291 - val_loss: 684934.6875\n",
            "Epoch 2/2\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0352 - loss: 579393.8125     \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 308888.7812\n",
            "  - Class 1: Loss = 223672.5469\n",
            "  - Class 2: Loss = 106.8611\n",
            "  - Class 3: Loss = 121006.7891\n",
            "  - Class 4: Loss = 374988.5000\n",
            "  - Class 5: Loss = 0.0000\n",
            "  - Class 6: Loss = 863203.1875\n",
            "  - Class 7: Loss = 159326.4531\n",
            "  - Class 8: Loss = 333213.3750\n",
            "  - Class 9: Loss = 13741.2773\n",
            "  - Class 10: Loss = 20443.7324\n",
            "  - Class 11: Loss = 1392942.6250\n",
            "  - Class 12: Loss = 794374.1250\n",
            "  - Class 13: Loss = 108316.2969\n",
            "  - Class 14: Loss = 163327.1250\n",
            "  - Class 15: Loss = 1022416.5625\n",
            "  - Class 16: Loss = 834491.8750\n",
            "  - Class 17: Loss = 111324.5703\n",
            "  - Class 18: Loss = 184165.8438\n",
            "  - Class 19: Loss = 272886.9688\n",
            "  - Class 20: Loss = 257115.8906\n",
            "  - Class 21: Loss = 98521.7734\n",
            "  - Class 22: Loss = 220204.6719\n",
            "  - Class 23: Loss = 920965.8750\n",
            "  - Class 24: Loss = 502560.6875\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.0422 - loss: 538888.3750 - val_accuracy: 0.0450 - val_loss: 325799.3125\n",
            "Trial 24 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.04497354477643967\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 14m 22s\n",
            "\n",
            "Search: Running Trial #25\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0001            |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "224               |256               |units_layer_1\n",
            "128               |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "32                |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "2025-08-27 09:53:04.665275: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 104 bytes spill stores, 104 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:05.124910: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_392', 28 bytes spill stores, 28 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:05.256586: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 936 bytes spill stores, 936 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:05.296674: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:05.482124: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 204 bytes spill stores, 204 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:05.579134: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_392', 24 bytes spill stores, 24 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:05.615780: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_392', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "\u001b[1m26/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1949 - loss: 2563891.2500     2025-08-27 09:53:08.822607: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2540 - loss: 2232332.25002025-08-27 09:53:12.517386: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 104 bytes spill stores, 104 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:12.728122: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 216 bytes spill stores, 216 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:12.894905: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:13.288326: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 936 bytes spill stores, 936 bytes spill loads\n",
            "\n",
            "\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 211061.2344\n",
            "2025-08-27 09:53:16.575130: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "  - Class 1: Loss = 2744318.7500\n",
            "2025-08-27 09:53:18.857381: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "  - Class 2: Loss = 1803.9408\n",
            "2025-08-27 09:53:20.998849: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 712 bytes spill stores, 712 bytes spill loads\n",
            "\n",
            "  - Class 3: Loss = 332470.1562\n",
            "2025-08-27 09:53:23.043422: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "  - Class 4: Loss = 2793960.2500\n",
            "  - Class 5: Loss = 2963115.5000\n",
            "  - Class 6: Loss = 2417220.0000\n",
            "2025-08-27 09:53:25.918185: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "  - Class 7: Loss = 854963.5000\n",
            "2025-08-27 09:53:28.128545: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "  - Class 8: Loss = 4620191.5000\n",
            "2025-08-27 09:53:30.090315: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:30.231581: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 216 bytes spill stores, 216 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:30.324674: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 104 bytes spill stores, 104 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:30.467422: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 936 bytes spill stores, 936 bytes spill loads\n",
            "\n",
            "  - Class 9: Loss = 347541.6562\n",
            "2025-08-27 09:53:32.527215: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "  - Class 10: Loss = 51186.7695\n",
            "2025-08-27 09:53:34.622822: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "  - Class 11: Loss = 4629243.5000\n",
            "2025-08-27 09:53:36.672580: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "  - Class 12: Loss = 10814651.0000\n",
            "  - Class 13: Loss = 667427.0625\n",
            "  - Class 14: Loss = 2136846.0000\n",
            "  - Class 15: Loss = 6694518.0000\n",
            "  - Class 16: Loss = 6503984.0000\n",
            "  - Class 17: Loss = 1904577.8750\n",
            "  - Class 18: Loss = 1813066.7500\n",
            "2025-08-27 09:53:39.157302: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 104 bytes spill stores, 104 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:39.182694: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 216 bytes spill stores, 216 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:39.433843: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 09:53:39.856557: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 936 bytes spill stores, 936 bytes spill loads\n",
            "\n",
            "  - Class 19: Loss = 4558177.5000\n",
            "  - Class 20: Loss = 2041410.8750\n",
            "  - Class 21: Loss = 4185492.7500\n",
            "2025-08-27 09:53:42.163009: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 748 bytes spill stores, 752 bytes spill loads\n",
            "\n",
            "  - Class 22: Loss = 1074917.2500\n",
            "  - Class 23: Loss = 3227663.2500\n",
            "  - Class 24: Loss = 7852987.0000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 766ms/step - accuracy: 0.2558 - loss: 2221493.2500 - val_accuracy: 0.3545 - val_loss: 1097675.3750\n",
            "Epoch 2/2\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4049 - loss: 808795.2500 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 91015.7578\n",
            "  - Class 1: Loss = 1779180.8750\n",
            "  - Class 2: Loss = 812.4047\n",
            "  - Class 3: Loss = 196520.8594\n",
            "  - Class 4: Loss = 1569301.6250\n",
            "  - Class 5: Loss = 2056931.7500\n",
            "  - Class 6: Loss = 995659.6250\n",
            "  - Class 7: Loss = 836708.7500\n",
            "  - Class 8: Loss = 3101531.7500\n",
            "  - Class 9: Loss = 208896.8594\n",
            "  - Class 10: Loss = 39369.7539\n",
            "  - Class 11: Loss = 2990996.0000\n",
            "  - Class 12: Loss = 7109298.0000\n",
            "  - Class 13: Loss = 402526.6250\n",
            "  - Class 14: Loss = 1304098.1250\n",
            "  - Class 15: Loss = 5159529.0000\n",
            "  - Class 16: Loss = 4221129.0000\n",
            "  - Class 17: Loss = 1240186.8750\n",
            "  - Class 18: Loss = 1221454.6250\n",
            "  - Class 19: Loss = 3066716.7500\n",
            "  - Class 20: Loss = 1426562.0000\n",
            "  - Class 21: Loss = 2924519.0000\n",
            "  - Class 22: Loss = 971759.9375\n",
            "  - Class 23: Loss = 2026649.6250\n",
            "  - Class 24: Loss = 5792167.0000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4160 - loss: 809965.8750 - val_accuracy: 0.3757 - val_loss: 765076.9375\n",
            "Trial 25 Complete [00h 00m 44s]\n",
            "val_accuracy: 0.37566137313842773\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 15m 06s\n",
            "\n",
            "Search: Running Trial #26\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.005             |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "64                |256               |units_layer_1\n",
            "64                |32                |units_layer_2\n",
            "32                |64                |units_layer_3\n",
            "24                |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2857 - loss: 1164579.8750\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 264.4328\n",
            "  - Class 1: Loss = 3.1863\n",
            "  - Class 2: Loss = 3.2047\n",
            "  - Class 3: Loss = 3.1535\n",
            "  - Class 4: Loss = 243.9304\n",
            "  - Class 5: Loss = 3.3611\n",
            "  - Class 6: Loss = 1492.8059\n",
            "  - Class 7: Loss = 3.2363\n",
            "  - Class 8: Loss = 3.2655\n",
            "  - Class 9: Loss = 3.1194\n",
            "  - Class 10: Loss = 97.6286\n",
            "  - Class 11: Loss = 3.2025\n",
            "  - Class 12: Loss = 3.3149\n",
            "  - Class 13: Loss = 802.0962\n",
            "  - Class 14: Loss = 3.2283\n",
            "  - Class 15: Loss = 3.2654\n",
            "  - Class 16: Loss = 3.2644\n",
            "  - Class 17: Loss = 662.7460\n",
            "  - Class 18: Loss = 3.1973\n",
            "  - Class 19: Loss = 3.3003\n",
            "  - Class 20: Loss = 3.1761\n",
            "  - Class 21: Loss = 3.3290\n",
            "  - Class 22: Loss = 3.3519\n",
            "  - Class 23: Loss = 3.2833\n",
            "  - Class 24: Loss = 3.3536\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 330ms/step - accuracy: 0.2839 - loss: 1149365.1250 - val_accuracy: 0.0608 - val_loss: 166.3609\n",
            "Epoch 2/2\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1172 - loss: 341.7914\n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 9.9389\n",
            "  - Class 1: Loss = 3.1973\n",
            "  - Class 2: Loss = 3.1616\n",
            "  - Class 3: Loss = 3.1014\n",
            "  - Class 4: Loss = 2.9562\n",
            "  - Class 5: Loss = 3.5326\n",
            "  - Class 6: Loss = 3.1836\n",
            "  - Class 7: Loss = 3.1807\n",
            "  - Class 8: Loss = 3.3883\n",
            "  - Class 9: Loss = 3.0324\n",
            "  - Class 10: Loss = 3.3381\n",
            "  - Class 11: Loss = 3.3178\n",
            "  - Class 12: Loss = 3.4510\n",
            "  - Class 13: Loss = 104.9333\n",
            "  - Class 14: Loss = 3.2439\n",
            "  - Class 15: Loss = 3.3159\n",
            "  - Class 16: Loss = 3.4159\n",
            "  - Class 17: Loss = 36.9391\n",
            "  - Class 18: Loss = 3.2247\n",
            "  - Class 19: Loss = 3.3229\n",
            "  - Class 20: Loss = 3.2322\n",
            "  - Class 21: Loss = 3.4429\n",
            "  - Class 22: Loss = 3.4890\n",
            "  - Class 23: Loss = 3.3304\n",
            "  - Class 24: Loss = 3.5394\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.2168 - loss: 251.3307 - val_accuracy: 0.5026 - val_loss: 29.5944\n",
            "Trial 26 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.5026454925537109\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 15m 27s\n",
            "\n",
            "Search: Running Trial #27\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "160               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "24                |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3472 - loss: 2.6439\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5810\n",
            "  - Class 1: Loss = 3.6473\n",
            "  - Class 2: Loss = 1.6916\n",
            "  - Class 3: Loss = 2.9980\n",
            "  - Class 4: Loss = 2.7218\n",
            "  - Class 5: Loss = 4.6635\n",
            "  - Class 6: Loss = 4.1699\n",
            "  - Class 7: Loss = 3.6090\n",
            "  - Class 8: Loss = 4.3370\n",
            "  - Class 9: Loss = 3.5175\n",
            "  - Class 10: Loss = 4.5279\n",
            "  - Class 11: Loss = 4.4124\n",
            "  - Class 12: Loss = 4.9328\n",
            "  - Class 13: Loss = 3.2332\n",
            "  - Class 14: Loss = 3.8682\n",
            "  - Class 15: Loss = 4.8692\n",
            "  - Class 16: Loss = 4.7498\n",
            "  - Class 17: Loss = 2.9921\n",
            "  - Class 18: Loss = 3.5730\n",
            "  - Class 19: Loss = 3.6663\n",
            "  - Class 20: Loss = 3.5439\n",
            "  - Class 21: Loss = 6.2354\n",
            "  - Class 22: Loss = 6.1791\n",
            "  - Class 23: Loss = 5.0077\n",
            "  - Class 24: Loss = 4.6657\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 759ms/step - accuracy: 0.3500 - loss: 2.6368 - val_accuracy: 0.5450 - val_loss: 2.0194\n",
            "Epoch 2/2\n",
            "\u001b[1m25/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5411 - loss: 1.9928 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5248\n",
            "  - Class 1: Loss = 3.5536\n",
            "  - Class 2: Loss = 0.8921\n",
            "  - Class 3: Loss = 3.1029\n",
            "  - Class 4: Loss = 1.5225\n",
            "  - Class 5: Loss = 5.3098\n",
            "  - Class 6: Loss = 3.1968\n",
            "  - Class 7: Loss = 3.4501\n",
            "  - Class 8: Loss = 4.4169\n",
            "  - Class 9: Loss = 3.1854\n",
            "  - Class 10: Loss = 4.7895\n",
            "  - Class 11: Loss = 4.3760\n",
            "  - Class 12: Loss = 5.2500\n",
            "  - Class 13: Loss = 2.8254\n",
            "  - Class 14: Loss = 3.8299\n",
            "  - Class 15: Loss = 4.6013\n",
            "  - Class 16: Loss = 4.9342\n",
            "  - Class 17: Loss = 2.4775\n",
            "  - Class 18: Loss = 3.8662\n",
            "  - Class 19: Loss = 3.9013\n",
            "  - Class 20: Loss = 3.6608\n",
            "  - Class 21: Loss = 6.0665\n",
            "  - Class 22: Loss = 5.9592\n",
            "  - Class 23: Loss = 4.6518\n",
            "  - Class 24: Loss = 5.1168\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5577 - loss: 1.9287 - val_accuracy: 0.5661 - val_loss: 1.8564\n",
            "Trial 27 Complete [00h 00m 45s]\n",
            "val_accuracy: 0.5661375522613525\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 16m 12s\n",
            "\n",
            "Search: Running Trial #28\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0001            |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "224               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "24                |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0307 - loss: 3595360.5000\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 901702.6875\n",
            "  - Class 1: Loss = 1889367.5000\n",
            "  - Class 2: Loss = 1094.4348\n",
            "  - Class 3: Loss = 541288.2500\n",
            "  - Class 4: Loss = 1289487.7500\n",
            "  - Class 5: Loss = 0.0000\n",
            "  - Class 6: Loss = 2313013.5000\n",
            "  - Class 7: Loss = 1889079.1250\n",
            "  - Class 8: Loss = 1445038.1250\n",
            "  - Class 9: Loss = 351765.0000\n",
            "  - Class 10: Loss = 45768.3242\n",
            "  - Class 11: Loss = 15409680.0000\n",
            "  - Class 12: Loss = 5734451.5000\n",
            "  - Class 13: Loss = 1126227.2500\n",
            "  - Class 14: Loss = 5675535.5000\n",
            "  - Class 15: Loss = 4288274.0000\n",
            "  - Class 16: Loss = 2432910.5000\n",
            "  - Class 17: Loss = 1880236.5000\n",
            "  - Class 18: Loss = 2218805.7500\n",
            "  - Class 19: Loss = 2528611.2500\n",
            "  - Class 20: Loss = 5475133.0000\n",
            "  - Class 21: Loss = 1821685.3750\n",
            "  - Class 22: Loss = 1905863.5000\n",
            "  - Class 23: Loss = 1688084.7500\n",
            "  - Class 24: Loss = 8445082.0000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 641ms/step - accuracy: 0.0315 - loss: 3577895.7500 - val_accuracy: 0.1455 - val_loss: 1477781.1250\n",
            "Epoch 2/2\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2257 - loss: 1420332.3750\n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 262425.3750\n",
            "  - Class 1: Loss = 1575942.3750\n",
            "  - Class 2: Loss = 463.0399\n",
            "  - Class 3: Loss = 404061.0938\n",
            "  - Class 4: Loss = 1002354.7500\n",
            "  - Class 5: Loss = 0.0000\n",
            "  - Class 6: Loss = 1579616.2500\n",
            "  - Class 7: Loss = 1446723.6250\n",
            "  - Class 8: Loss = 1151734.3750\n",
            "  - Class 9: Loss = 251029.6719\n",
            "  - Class 10: Loss = 33060.1016\n",
            "  - Class 11: Loss = 11015321.0000\n",
            "  - Class 12: Loss = 3199702.0000\n",
            "  - Class 13: Loss = 899902.8750\n",
            "  - Class 14: Loss = 4414515.5000\n",
            "  - Class 15: Loss = 3992053.0000\n",
            "  - Class 16: Loss = 2511360.5000\n",
            "  - Class 17: Loss = 1306270.1250\n",
            "  - Class 18: Loss = 1680066.0000\n",
            "  - Class 19: Loss = 1938084.0000\n",
            "  - Class 20: Loss = 4358158.5000\n",
            "  - Class 21: Loss = 1302012.2500\n",
            "  - Class 22: Loss = 1759340.2500\n",
            "  - Class 23: Loss = 1548694.3750\n",
            "  - Class 24: Loss = 10043482.0000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.2445 - loss: 1335733.5000 - val_accuracy: 0.2778 - val_loss: 990372.7500\n",
            "Trial 28 Complete [00h 00m 38s]\n",
            "val_accuracy: 0.2777777910232544\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 16m 50s\n",
            "\n",
            "Search: Running Trial #29\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "128               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "16                |64                |units_layer_3\n",
            "8                 |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1631 - loss: 1288244.1250\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2256.8394\n",
            "  - Class 1: Loss = 14.6080\n",
            "  - Class 2: Loss = 3.1889\n",
            "  - Class 3: Loss = 3771.4187\n",
            "  - Class 4: Loss = 2432.0771\n",
            "  - Class 5: Loss = 3.2410\n",
            "  - Class 6: Loss = 18257.7031\n",
            "  - Class 7: Loss = 11559.1650\n",
            "  - Class 8: Loss = 7202.3110\n",
            "  - Class 9: Loss = 2326.0403\n",
            "  - Class 10: Loss = 1221.1733\n",
            "  - Class 11: Loss = 3.2287\n",
            "  - Class 12: Loss = 3.2454\n",
            "  - Class 13: Loss = 6327.7729\n",
            "  - Class 14: Loss = 3.2171\n",
            "  - Class 15: Loss = 3.2172\n",
            "  - Class 16: Loss = 2656.1555\n",
            "  - Class 17: Loss = 19509.6973\n",
            "  - Class 18: Loss = 6154.5283\n",
            "  - Class 19: Loss = 3.2114\n",
            "  - Class 20: Loss = 3.2301\n",
            "  - Class 21: Loss = 3.2430\n",
            "  - Class 22: Loss = 163207.6562\n",
            "  - Class 23: Loss = 27649.0723\n",
            "  - Class 24: Loss = 3.2511\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 282ms/step - accuracy: 0.1659 - loss: 1272470.0000 - val_accuracy: 0.4788 - val_loss: 15507.6270\n",
            "Epoch 2/2\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5069 - loss: 2998.5249 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 62.8963\n",
            "  - Class 1: Loss = 3.2109\n",
            "  - Class 2: Loss = 3.1846\n",
            "  - Class 3: Loss = 61.1301\n",
            "  - Class 4: Loss = 3.1893\n",
            "  - Class 5: Loss = 3.2421\n",
            "  - Class 6: Loss = 4433.9199\n",
            "  - Class 7: Loss = 3.1650\n",
            "  - Class 8: Loss = 2732.6255\n",
            "  - Class 9: Loss = 6.2822\n",
            "  - Class 10: Loss = 3.2503\n",
            "  - Class 11: Loss = 3.2251\n",
            "  - Class 12: Loss = 3.2819\n",
            "  - Class 13: Loss = 212.8861\n",
            "  - Class 14: Loss = 3.2181\n",
            "  - Class 15: Loss = 3.2457\n",
            "  - Class 16: Loss = 3.2478\n",
            "  - Class 17: Loss = 406.4822\n",
            "  - Class 18: Loss = 3.2192\n",
            "  - Class 19: Loss = 3.2295\n",
            "  - Class 20: Loss = 3.2213\n",
            "  - Class 21: Loss = 3.2785\n",
            "  - Class 22: Loss = 3.2893\n",
            "  - Class 23: Loss = 3.2221\n",
            "  - Class 24: Loss = 3.2880\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5132 - loss: 2480.1338 - val_accuracy: 0.5000 - val_loss: 5945.2876\n",
            "Trial 29 Complete [00h 00m 19s]\n",
            "val_accuracy: 0.5\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 17m 09s\n",
            "\n",
            "Search: Running Trial #30\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0001            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "224               |256               |units_layer_1\n",
            "96                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "24                |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "2025-08-27 09:55:51.655073: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 80 bytes spill stores, 80 bytes spill loads\n",
            "\n",
            "2025-08-27 09:55:51.808393: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 120 bytes spill stores, 120 bytes spill loads\n",
            "\n",
            "2025-08-27 09:55:52.334135: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 968 bytes spill stores, 968 bytes spill loads\n",
            "\n",
            "2025-08-27 09:55:52.633290: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 216 bytes spill stores, 216 bytes spill loads\n",
            "\n",
            "2025-08-27 09:55:53.871761: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_388', 60 bytes spill stores, 60 bytes spill loads\n",
            "\n",
            "\u001b[1m26/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0592 - loss: 3.1428 2025-08-27 09:55:57.841451: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.0805 - loss: 3.09872025-08-27 09:56:02.128366: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 120 bytes spill stores, 120 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:02.268543: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 220 bytes spill stores, 220 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:02.654353: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 80 bytes spill stores, 80 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:02.654412: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 968 bytes spill stores, 972 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:02.850003: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.3790\n",
            "2025-08-27 09:56:06.804223: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "  - Class 1: Loss = 3.6490\n",
            "2025-08-27 09:56:09.397512: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "  - Class 2: Loss = 2.0041\n",
            "2025-08-27 09:56:12.060284: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 724 bytes spill stores, 724 bytes spill loads\n",
            "\n",
            "  - Class 3: Loss = 2.7268\n",
            "2025-08-27 09:56:14.505769: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "  - Class 4: Loss = 3.0000\n",
            "  - Class 5: Loss = 3.4174\n",
            "  - Class 6: Loss = 3.2442\n",
            "2025-08-27 09:56:17.975365: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "  - Class 7: Loss = 3.6078\n",
            "2025-08-27 09:56:20.757604: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "  - Class 8: Loss = 3.1352\n",
            "2025-08-27 09:56:23.016153: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 220 bytes spill stores, 220 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:23.475786: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:23.483396: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 968 bytes spill stores, 972 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:23.614799: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 120 bytes spill stores, 120 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:23.730482: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 80 bytes spill stores, 80 bytes spill loads\n",
            "\n",
            "  - Class 9: Loss = 3.1634\n",
            "2025-08-27 09:56:26.720237: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "  - Class 10: Loss = 3.3179\n",
            "2025-08-27 09:56:29.486063: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "  - Class 11: Loss = 2.8069\n",
            "2025-08-27 09:56:32.349350: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "  - Class 12: Loss = 3.4978\n",
            "  - Class 13: Loss = 3.0443\n",
            "  - Class 14: Loss = 3.1892\n",
            "  - Class 15: Loss = 3.1914\n",
            "  - Class 16: Loss = 3.6573\n",
            "  - Class 17: Loss = 3.0702\n",
            "  - Class 18: Loss = 3.0194\n",
            "2025-08-27 09:56:35.106582: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 220 bytes spill stores, 220 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:35.131306: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:35.456317: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 120 bytes spill stores, 120 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:35.783245: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 968 bytes spill stores, 972 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:35.842936: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 80 bytes spill stores, 80 bytes spill loads\n",
            "\n",
            "  - Class 19: Loss = 3.3964\n",
            "  - Class 20: Loss = 3.3130\n",
            "  - Class 21: Loss = 3.3646\n",
            "2025-08-27 09:56:38.910581: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 732 bytes spill stores, 732 bytes spill loads\n",
            "\n",
            "  - Class 22: Loss = 4.3419\n",
            "  - Class 23: Loss = 3.4767\n",
            "  - Class 24: Loss = 3.2278\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 944ms/step - accuracy: 0.0817 - loss: 3.0966 - val_accuracy: 0.3386 - val_loss: 2.7666\n",
            "Epoch 2/2\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4217 - loss: 2.6356 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.6981\n",
            "  - Class 1: Loss = 3.6452\n",
            "  - Class 2: Loss = 1.6451\n",
            "  - Class 3: Loss = 2.7869\n",
            "  - Class 4: Loss = 3.1539\n",
            "  - Class 5: Loss = 3.4818\n",
            "  - Class 6: Loss = 3.3745\n",
            "  - Class 7: Loss = 3.7505\n",
            "  - Class 8: Loss = 3.1081\n",
            "  - Class 9: Loss = 3.0748\n",
            "  - Class 10: Loss = 3.3155\n",
            "  - Class 11: Loss = 3.0332\n",
            "  - Class 12: Loss = 3.8120\n",
            "  - Class 13: Loss = 3.0554\n",
            "  - Class 14: Loss = 3.4455\n",
            "  - Class 15: Loss = 3.0485\n",
            "  - Class 16: Loss = 3.9521\n",
            "  - Class 17: Loss = 2.9394\n",
            "  - Class 18: Loss = 2.8610\n",
            "  - Class 19: Loss = 3.6346\n",
            "  - Class 20: Loss = 3.3440\n",
            "  - Class 21: Loss = 3.7415\n",
            "  - Class 22: Loss = 4.3053\n",
            "  - Class 23: Loss = 3.4790\n",
            "  - Class 24: Loss = 3.3721\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4401 - loss: 2.6051 - val_accuracy: 0.5000 - val_loss: 2.4366\n",
            "Trial 30 Complete [00h 00m 54s]\n",
            "val_accuracy: 0.5\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 18m 03s\n",
            "\n",
            "Search: Running Trial #31\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0005            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "96                |256               |units_layer_1\n",
            "128               |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "8                 |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "2025-08-27 09:56:45.858682: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.1844 - loss: 3.01072025-08-27 09:56:53.900833: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 09:56:54.696536: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 84 bytes spill stores, 84 bytes spill loads\n",
            "\n",
            "\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.0700\n",
            "  - Class 1: Loss = 3.8288\n",
            "  - Class 2: Loss = 1.6106\n",
            "  - Class 3: Loss = 3.0227\n",
            "  - Class 4: Loss = 3.5537\n",
            "  - Class 5: Loss = 2.4160\n",
            "  - Class 6: Loss = 2.6688\n",
            "  - Class 7: Loss = 3.6203\n",
            "  - Class 8: Loss = 2.8109\n",
            "2025-08-27 09:57:11.654014: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 84 bytes spill stores, 84 bytes spill loads\n",
            "\n",
            "2025-08-27 09:57:11.777930: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 9: Loss = 3.2363\n",
            "  - Class 10: Loss = 3.1711\n",
            "  - Class 11: Loss = 3.7838\n",
            "  - Class 12: Loss = 3.0373\n",
            "  - Class 13: Loss = 3.2568\n",
            "  - Class 14: Loss = 3.6257\n",
            "  - Class 15: Loss = 3.3687\n",
            "  - Class 16: Loss = 3.9234\n",
            "  - Class 17: Loss = 2.6383\n",
            "  - Class 18: Loss = 3.1779\n",
            "2025-08-27 09:57:20.840843: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 09:57:21.753060: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 84 bytes spill stores, 84 bytes spill loads\n",
            "\n",
            "  - Class 19: Loss = 3.0100\n",
            "  - Class 20: Loss = 3.2277\n",
            "  - Class 21: Loss = 4.4878\n",
            "  - Class 22: Loss = 3.3543\n",
            "  - Class 23: Loss = 3.6137\n",
            "  - Class 24: Loss = 3.7407\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 779ms/step - accuracy: 0.1872 - loss: 3.0075 - val_accuracy: 0.5397 - val_loss: 2.5902\n",
            "Epoch 2/2\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 2.4923 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.6146\n",
            "  - Class 1: Loss = 3.9055\n",
            "  - Class 2: Loss = 1.5160\n",
            "  - Class 3: Loss = 3.0566\n",
            "  - Class 4: Loss = 3.3126\n",
            "  - Class 5: Loss = 2.7215\n",
            "  - Class 6: Loss = 2.3351\n",
            "  - Class 7: Loss = 3.4977\n",
            "  - Class 8: Loss = 3.0105\n",
            "  - Class 9: Loss = 3.2229\n",
            "  - Class 10: Loss = 3.0375\n",
            "  - Class 11: Loss = 4.0542\n",
            "  - Class 12: Loss = 3.2043\n",
            "  - Class 13: Loss = 3.1172\n",
            "  - Class 14: Loss = 3.7622\n",
            "  - Class 15: Loss = 3.5485\n",
            "  - Class 16: Loss = 4.2506\n",
            "  - Class 17: Loss = 2.4896\n",
            "  - Class 18: Loss = 3.1799\n",
            "  - Class 19: Loss = 3.0899\n",
            "  - Class 20: Loss = 3.2811\n",
            "  - Class 21: Loss = 4.4878\n",
            "  - Class 22: Loss = 3.4852\n",
            "  - Class 23: Loss = 3.7675\n",
            "  - Class 24: Loss = 4.0122\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.5727 - loss: 2.4785 - val_accuracy: 0.5582 - val_loss: 2.3686\n",
            "Trial 31 Complete [00h 00m 45s]\n",
            "val_accuracy: 0.5582010746002197\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 18m 48s\n",
            "\n",
            "Search: Running Trial #32\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0005            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "64                |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "16                |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1933 - loss: 3.0249\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.7450\n",
            "  - Class 1: Loss = 3.1038\n",
            "  - Class 2: Loss = 2.0783\n",
            "  - Class 3: Loss = 3.0737\n",
            "  - Class 4: Loss = 2.5412\n",
            "  - Class 5: Loss = 3.2682\n",
            "  - Class 6: Loss = 3.1579\n",
            "  - Class 7: Loss = 3.8599\n",
            "  - Class 8: Loss = 4.2797\n",
            "  - Class 9: Loss = 2.8183\n",
            "  - Class 10: Loss = 3.1352\n",
            "  - Class 11: Loss = 2.7157\n",
            "  - Class 12: Loss = 4.0424\n",
            "  - Class 13: Loss = 3.2913\n",
            "  - Class 14: Loss = 3.3881\n",
            "  - Class 15: Loss = 3.3780\n",
            "  - Class 16: Loss = 4.1339\n",
            "  - Class 17: Loss = 3.2168\n",
            "  - Class 18: Loss = 4.0146\n",
            "  - Class 19: Loss = 3.4807\n",
            "  - Class 20: Loss = 3.5623\n",
            "  - Class 21: Loss = 3.4631\n",
            "  - Class 22: Loss = 4.2138\n",
            "  - Class 23: Loss = 3.4721\n",
            "  - Class 24: Loss = 3.6336\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 280ms/step - accuracy: 0.1958 - loss: 3.0211 - val_accuracy: 0.4921 - val_loss: 2.4949\n",
            "Epoch 2/2\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5009 - loss: 2.3599 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.9188\n",
            "  - Class 1: Loss = 3.3133\n",
            "  - Class 2: Loss = 1.4838\n",
            "  - Class 3: Loss = 3.1903\n",
            "  - Class 4: Loss = 2.3081\n",
            "  - Class 5: Loss = 3.4818\n",
            "  - Class 6: Loss = 3.1049\n",
            "  - Class 7: Loss = 4.1478\n",
            "  - Class 8: Loss = 4.7002\n",
            "  - Class 9: Loss = 2.8956\n",
            "  - Class 10: Loss = 3.4380\n",
            "  - Class 11: Loss = 3.2233\n",
            "  - Class 12: Loss = 4.5499\n",
            "  - Class 13: Loss = 3.2411\n",
            "  - Class 14: Loss = 3.6832\n",
            "  - Class 15: Loss = 3.8522\n",
            "  - Class 16: Loss = 4.6229\n",
            "  - Class 17: Loss = 3.1397\n",
            "  - Class 18: Loss = 4.4165\n",
            "  - Class 19: Loss = 3.9554\n",
            "  - Class 20: Loss = 3.8299\n",
            "  - Class 21: Loss = 3.9839\n",
            "  - Class 22: Loss = 4.6888\n",
            "  - Class 23: Loss = 3.9082\n",
            "  - Class 24: Loss = 4.4097\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5165 - loss: 2.3074 - val_accuracy: 0.5450 - val_loss: 2.1217\n",
            "Trial 32 Complete [00h 00m 19s]\n",
            "val_accuracy: 0.5449735522270203\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 19m 07s\n",
            "\n",
            "Search: Running Trial #33\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "64                |256               |units_layer_1\n",
            "96                |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "8                 |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2158 - loss: 3.0491\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.8352\n",
            "  - Class 1: Loss = 2.5462\n",
            "  - Class 2: Loss = 1.9789\n",
            "  - Class 3: Loss = 2.7231\n",
            "  - Class 4: Loss = 3.0887\n",
            "  - Class 5: Loss = 4.0530\n",
            "  - Class 6: Loss = 2.6092\n",
            "  - Class 7: Loss = 3.4638\n",
            "  - Class 8: Loss = 4.1973\n",
            "  - Class 9: Loss = 3.1693\n",
            "  - Class 10: Loss = 3.5528\n",
            "  - Class 11: Loss = 4.7233\n",
            "  - Class 12: Loss = 4.5306\n",
            "  - Class 13: Loss = 3.4896\n",
            "  - Class 14: Loss = 3.3713\n",
            "  - Class 15: Loss = 3.1937\n",
            "  - Class 16: Loss = 3.1309\n",
            "  - Class 17: Loss = 2.7794\n",
            "  - Class 18: Loss = 3.5283\n",
            "  - Class 19: Loss = 3.3992\n",
            "  - Class 20: Loss = 3.5801\n",
            "  - Class 21: Loss = 3.4074\n",
            "  - Class 22: Loss = 3.1731\n",
            "  - Class 23: Loss = 2.9072\n",
            "  - Class 24: Loss = 3.5624\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 321ms/step - accuracy: 0.2194 - loss: 3.0440 - val_accuracy: 0.5556 - val_loss: 2.4962\n",
            "Epoch 2/2\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5823 - loss: 2.3741 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.2905\n",
            "  - Class 1: Loss = 2.7816\n",
            "  - Class 2: Loss = 1.7895\n",
            "  - Class 3: Loss = 2.7663\n",
            "  - Class 4: Loss = 2.9080\n",
            "  - Class 5: Loss = 4.4974\n",
            "  - Class 6: Loss = 2.5941\n",
            "  - Class 7: Loss = 3.4172\n",
            "  - Class 8: Loss = 4.3754\n",
            "  - Class 9: Loss = 3.0592\n",
            "  - Class 10: Loss = 3.8136\n",
            "  - Class 11: Loss = 4.7215\n",
            "  - Class 12: Loss = 4.7673\n",
            "  - Class 13: Loss = 3.3888\n",
            "  - Class 14: Loss = 3.4365\n",
            "  - Class 15: Loss = 3.4773\n",
            "  - Class 16: Loss = 3.4301\n",
            "  - Class 17: Loss = 2.5018\n",
            "  - Class 18: Loss = 3.5073\n",
            "  - Class 19: Loss = 3.6204\n",
            "  - Class 20: Loss = 3.6235\n",
            "  - Class 21: Loss = 3.7616\n",
            "  - Class 22: Loss = 3.4748\n",
            "  - Class 23: Loss = 3.1921\n",
            "  - Class 24: Loss = 3.9829\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5819 - loss: 2.3375 - val_accuracy: 0.5688 - val_loss: 2.2023\n",
            "Trial 33 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.5687830448150635\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 19m 28s\n",
            "\n",
            "Search: Running Trial #34\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0005            |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "224               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "32                |16                |units_layer_4\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/2\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3433 - loss: 1130353.8750\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 160216.0625\n",
            "  - Class 1: Loss = 348761.2500\n",
            "  - Class 2: Loss = 37.6325\n",
            "  - Class 3: Loss = 69206.5469\n",
            "  - Class 4: Loss = 300281.5938\n",
            "  - Class 5: Loss = 933336.0000\n",
            "  - Class 6: Loss = 121802.3594\n",
            "  - Class 7: Loss = 444798.4688\n",
            "  - Class 8: Loss = 1024411.3750\n",
            "  - Class 9: Loss = 45540.6484\n",
            "  - Class 10: Loss = 29226.7441\n",
            "  - Class 11: Loss = 2763837.2500\n",
            "  - Class 12: Loss = 1637193.0000\n",
            "  - Class 13: Loss = 293333.8750\n",
            "  - Class 14: Loss = 951777.5000\n",
            "  - Class 15: Loss = 1119686.3750\n",
            "  - Class 16: Loss = 1089937.8750\n",
            "  - Class 17: Loss = 342955.2500\n",
            "  - Class 18: Loss = 591271.2500\n",
            "  - Class 19: Loss = 680702.4375\n",
            "  - Class 20: Loss = 883075.5625\n",
            "  - Class 21: Loss = 850572.3125\n",
            "  - Class 22: Loss = 601880.3125\n",
            "  - Class 23: Loss = 451083.4062\n",
            "  - Class 24: Loss = 931003.8125\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 332ms/step - accuracy: 0.3437 - loss: 1121994.3750 - val_accuracy: 0.2513 - val_loss: 320310.4062\n",
            "Epoch 2/2\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3541 - loss: 268000.8750 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 44452.4805\n",
            "  - Class 1: Loss = 248370.2500\n",
            "  - Class 2: Loss = 229.4850\n",
            "  - Class 3: Loss = 19567.3770\n",
            "  - Class 4: Loss = 35900.8008\n",
            "  - Class 5: Loss = 124249.3906\n",
            "  - Class 6: Loss = 54140.5703\n",
            "  - Class 7: Loss = 75062.4141\n",
            "  - Class 8: Loss = 442584.7188\n",
            "  - Class 9: Loss = 14879.9463\n",
            "  - Class 10: Loss = 10257.2100\n",
            "  - Class 11: Loss = 140800.4844\n",
            "  - Class 12: Loss = 168605.3750\n",
            "  - Class 13: Loss = 94437.2031\n",
            "  - Class 14: Loss = 280214.2500\n",
            "  - Class 15: Loss = 69003.2188\n",
            "  - Class 16: Loss = 238231.6562\n",
            "  - Class 17: Loss = 122198.1641\n",
            "  - Class 18: Loss = 255386.5469\n",
            "  - Class 19: Loss = 205867.6250\n",
            "  - Class 20: Loss = 348659.0000\n",
            "  - Class 21: Loss = 228519.8906\n",
            "  - Class 22: Loss = 43159.2852\n",
            "  - Class 23: Loss = 148732.9688\n",
            "  - Class 24: Loss = 238595.1875\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.3612 - loss: 236047.8906 - val_accuracy: 0.2063 - val_loss: 111436.3359\n",
            "Trial 34 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.25132274627685547\n",
            "\n",
            "Best val_accuracy So Far: 0.5978835821151733\n",
            "Total elapsed time: 00h 19m 49s\n",
            "\n",
            "Search: Running Trial #35\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "256               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "16                |16                |units_layer_4\n",
            "4                 |2                 |tuner/epochs\n",
            "2                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |0                 |tuner/round\n",
            "0018              |None              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6435 - loss: 1.6330\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5475\n",
            "  - Class 1: Loss = 3.7745\n",
            "  - Class 2: Loss = 0.4286\n",
            "  - Class 3: Loss = 2.5722\n",
            "  - Class 4: Loss = 1.2094\n",
            "  - Class 5: Loss = 5.8815\n",
            "  - Class 6: Loss = 1.2830\n",
            "  - Class 7: Loss = 3.1178\n",
            "  - Class 8: Loss = 4.1164\n",
            "  - Class 9: Loss = 3.0151\n",
            "  - Class 10: Loss = 3.4212\n",
            "  - Class 11: Loss = 4.1967\n",
            "  - Class 12: Loss = 4.7887\n",
            "  - Class 13: Loss = 2.4949\n",
            "  - Class 14: Loss = 3.2160\n",
            "  - Class 15: Loss = 4.4312\n",
            "  - Class 16: Loss = 3.9264\n",
            "  - Class 17: Loss = 2.0686\n",
            "  - Class 18: Loss = 3.5733\n",
            "  - Class 19: Loss = 4.1844\n",
            "  - Class 20: Loss = 3.6917\n",
            "  - Class 21: Loss = 5.1236\n",
            "  - Class 22: Loss = 4.0937\n",
            "  - Class 23: Loss = 4.0592\n",
            "  - Class 24: Loss = 4.6745\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 285ms/step - accuracy: 0.6435 - loss: 1.6331 - val_accuracy: 0.6005 - val_loss: 1.7584\n",
            "Epoch 4/4\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6863 - loss: 1.4707 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4813\n",
            "  - Class 1: Loss = 3.6671\n",
            "  - Class 2: Loss = 0.2962\n",
            "  - Class 3: Loss = 2.4062\n",
            "  - Class 4: Loss = 0.9288\n",
            "  - Class 5: Loss = 5.9708\n",
            "  - Class 6: Loss = 1.1577\n",
            "  - Class 7: Loss = 2.7626\n",
            "  - Class 8: Loss = 4.1332\n",
            "  - Class 9: Loss = 2.7960\n",
            "  - Class 10: Loss = 3.2793\n",
            "  - Class 11: Loss = 4.0248\n",
            "  - Class 12: Loss = 5.0144\n",
            "  - Class 13: Loss = 2.2998\n",
            "  - Class 14: Loss = 3.0156\n",
            "  - Class 15: Loss = 4.1979\n",
            "  - Class 16: Loss = 4.1362\n",
            "  - Class 17: Loss = 1.8844\n",
            "  - Class 18: Loss = 3.4590\n",
            "  - Class 19: Loss = 4.2330\n",
            "  - Class 20: Loss = 3.4242\n",
            "  - Class 21: Loss = 5.1656\n",
            "  - Class 22: Loss = 4.2622\n",
            "  - Class 23: Loss = 4.0113\n",
            "  - Class 24: Loss = 5.0211\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6739 - loss: 1.4872 - val_accuracy: 0.5979 - val_loss: 1.6853\n",
            "Trial 35 Complete [00h 00m 19s]\n",
            "val_accuracy: 0.6005290746688843\n",
            "\n",
            "Best val_accuracy So Far: 0.6005290746688843\n",
            "Total elapsed time: 00h 20m 08s\n",
            "\n",
            "Search: Running Trial #36\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "128               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "32                |16                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0007              |0018              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6247 - loss: 1.6072\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5403\n",
            "  - Class 1: Loss = 3.6726\n",
            "  - Class 2: Loss = 0.3059\n",
            "  - Class 3: Loss = 2.6331\n",
            "  - Class 4: Loss = 0.8148\n",
            "  - Class 5: Loss = 5.1331\n",
            "  - Class 6: Loss = 0.9025\n",
            "  - Class 7: Loss = 2.9298\n",
            "  - Class 8: Loss = 4.2328\n",
            "  - Class 9: Loss = 2.5274\n",
            "  - Class 10: Loss = 3.2572\n",
            "  - Class 11: Loss = 4.4375\n",
            "  - Class 12: Loss = 6.0421\n",
            "  - Class 13: Loss = 2.2304\n",
            "  - Class 14: Loss = 3.2438\n",
            "  - Class 15: Loss = 4.8025\n",
            "  - Class 16: Loss = 5.1066\n",
            "  - Class 17: Loss = 1.8246\n",
            "  - Class 18: Loss = 3.7088\n",
            "  - Class 19: Loss = 4.0338\n",
            "  - Class 20: Loss = 3.6913\n",
            "  - Class 21: Loss = 5.1399\n",
            "  - Class 22: Loss = 5.4214\n",
            "  - Class 23: Loss = 4.3916\n",
            "  - Class 24: Loss = 6.2305\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 310ms/step - accuracy: 0.6249 - loss: 1.6064 - val_accuracy: 0.5979 - val_loss: 1.6526\n",
            "Epoch 4/4\n",
            "\u001b[1m30/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6474 - loss: 1.4464 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5034\n",
            "  - Class 1: Loss = 3.5431\n",
            "  - Class 2: Loss = 0.2121\n",
            "  - Class 3: Loss = 2.4816\n",
            "  - Class 4: Loss = 0.6160\n",
            "  - Class 5: Loss = 5.3929\n",
            "  - Class 6: Loss = 0.5733\n",
            "  - Class 7: Loss = 2.5158\n",
            "  - Class 8: Loss = 4.1538\n",
            "  - Class 9: Loss = 2.3647\n",
            "  - Class 10: Loss = 3.1805\n",
            "  - Class 11: Loss = 4.3550\n",
            "  - Class 12: Loss = 6.1218\n",
            "  - Class 13: Loss = 2.0895\n",
            "  - Class 14: Loss = 2.8685\n",
            "  - Class 15: Loss = 4.7700\n",
            "  - Class 16: Loss = 4.9820\n",
            "  - Class 17: Loss = 1.7345\n",
            "  - Class 18: Loss = 3.5137\n",
            "  - Class 19: Loss = 3.8501\n",
            "  - Class 20: Loss = 3.2885\n",
            "  - Class 21: Loss = 5.5144\n",
            "  - Class 22: Loss = 5.6137\n",
            "  - Class 23: Loss = 3.9500\n",
            "  - Class 24: Loss = 6.1272\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6499 - loss: 1.4349 - val_accuracy: 0.5979 - val_loss: 1.5885\n",
            "Trial 36 Complete [00h 00m 20s]\n",
            "val_accuracy: 0.5978835821151733\n",
            "\n",
            "Best val_accuracy So Far: 0.6005290746688843\n",
            "Total elapsed time: 00h 20m 29s\n",
            "\n",
            "Search: Running Trial #37\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "256               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "24                |16                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0021              |0018              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6505 - loss: 1.5551\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5259\n",
            "  - Class 1: Loss = 3.6372\n",
            "  - Class 2: Loss = 0.3265\n",
            "  - Class 3: Loss = 2.4914\n",
            "  - Class 4: Loss = 0.8336\n",
            "  - Class 5: Loss = 4.2955\n",
            "  - Class 6: Loss = 0.8221\n",
            "  - Class 7: Loss = 2.8413\n",
            "  - Class 8: Loss = 4.5669\n",
            "  - Class 9: Loss = 2.8050\n",
            "  - Class 10: Loss = 3.7617\n",
            "  - Class 11: Loss = 3.9828\n",
            "  - Class 12: Loss = 5.3047\n",
            "  - Class 13: Loss = 2.1361\n",
            "  - Class 14: Loss = 3.4753\n",
            "  - Class 15: Loss = 5.0568\n",
            "  - Class 16: Loss = 4.3636\n",
            "  - Class 17: Loss = 1.7327\n",
            "  - Class 18: Loss = 3.5903\n",
            "  - Class 19: Loss = 4.2875\n",
            "  - Class 20: Loss = 3.4493\n",
            "  - Class 21: Loss = 5.4674\n",
            "  - Class 22: Loss = 4.8739\n",
            "  - Class 23: Loss = 4.0591\n",
            "  - Class 24: Loss = 6.3016\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 299ms/step - accuracy: 0.6504 - loss: 1.5554 - val_accuracy: 0.6005 - val_loss: 1.6946\n",
            "Epoch 4/4\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6668 - loss: 1.3497 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4243\n",
            "  - Class 1: Loss = 3.5174\n",
            "  - Class 2: Loss = 0.2048\n",
            "  - Class 3: Loss = 2.2233\n",
            "  - Class 4: Loss = 0.6341\n",
            "  - Class 5: Loss = 4.6071\n",
            "  - Class 6: Loss = 0.4305\n",
            "  - Class 7: Loss = 2.8951\n",
            "  - Class 8: Loss = 4.1093\n",
            "  - Class 9: Loss = 2.7897\n",
            "  - Class 10: Loss = 3.6325\n",
            "  - Class 11: Loss = 3.7576\n",
            "  - Class 12: Loss = 5.2683\n",
            "  - Class 13: Loss = 2.0290\n",
            "  - Class 14: Loss = 3.0315\n",
            "  - Class 15: Loss = 5.2134\n",
            "  - Class 16: Loss = 4.4638\n",
            "  - Class 17: Loss = 1.6116\n",
            "  - Class 18: Loss = 3.5016\n",
            "  - Class 19: Loss = 4.2356\n",
            "  - Class 20: Loss = 3.3382\n",
            "  - Class 21: Loss = 5.4966\n",
            "  - Class 22: Loss = 5.0330\n",
            "  - Class 23: Loss = 3.9722\n",
            "  - Class 24: Loss = 6.7814\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6668 - loss: 1.3643 - val_accuracy: 0.6085 - val_loss: 1.6400\n",
            "Trial 37 Complete [00h 00m 20s]\n",
            "val_accuracy: 0.6084656119346619\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 20m 49s\n",
            "\n",
            "Search: Running Trial #38\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "64                |256               |units_layer_1\n",
            "96                |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "8                 |24                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0032              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5540 - loss: 2.1205\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.9247\n",
            "  - Class 1: Loss = 3.0749\n",
            "  - Class 2: Loss = 1.6006\n",
            "  - Class 3: Loss = 2.8722\n",
            "  - Class 4: Loss = 2.8285\n",
            "  - Class 5: Loss = 4.8840\n",
            "  - Class 6: Loss = 2.4891\n",
            "  - Class 7: Loss = 3.4674\n",
            "  - Class 8: Loss = 4.5651\n",
            "  - Class 9: Loss = 3.0682\n",
            "  - Class 10: Loss = 4.0164\n",
            "  - Class 11: Loss = 4.8100\n",
            "  - Class 12: Loss = 5.0721\n",
            "  - Class 13: Loss = 3.2960\n",
            "  - Class 14: Loss = 3.5240\n",
            "  - Class 15: Loss = 3.8281\n",
            "  - Class 16: Loss = 3.8052\n",
            "  - Class 17: Loss = 2.3496\n",
            "  - Class 18: Loss = 3.5549\n",
            "  - Class 19: Loss = 3.8505\n",
            "  - Class 20: Loss = 3.6967\n",
            "  - Class 21: Loss = 4.1856\n",
            "  - Class 22: Loss = 3.8659\n",
            "  - Class 23: Loss = 3.4045\n",
            "  - Class 24: Loss = 4.3419\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 320ms/step - accuracy: 0.5547 - loss: 2.1185 - val_accuracy: 0.5714 - val_loss: 2.0282\n",
            "Epoch 4/4\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5560 - loss: 2.0081 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.7421\n",
            "  - Class 1: Loss = 3.2983\n",
            "  - Class 2: Loss = 1.4268\n",
            "  - Class 3: Loss = 2.8332\n",
            "  - Class 4: Loss = 2.8595\n",
            "  - Class 5: Loss = 5.2350\n",
            "  - Class 6: Loss = 2.1943\n",
            "  - Class 7: Loss = 3.4929\n",
            "  - Class 8: Loss = 4.5485\n",
            "  - Class 9: Loss = 3.1352\n",
            "  - Class 10: Loss = 3.9902\n",
            "  - Class 11: Loss = 4.8117\n",
            "  - Class 12: Loss = 5.3718\n",
            "  - Class 13: Loss = 3.1459\n",
            "  - Class 14: Loss = 3.6498\n",
            "  - Class 15: Loss = 4.1200\n",
            "  - Class 16: Loss = 4.1429\n",
            "  - Class 17: Loss = 2.1626\n",
            "  - Class 18: Loss = 3.5272\n",
            "  - Class 19: Loss = 4.0293\n",
            "  - Class 20: Loss = 3.7583\n",
            "  - Class 21: Loss = 4.5162\n",
            "  - Class 22: Loss = 4.2167\n",
            "  - Class 23: Loss = 3.5231\n",
            "  - Class 24: Loss = 4.4803\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5702 - loss: 1.9621 - val_accuracy: 0.5661 - val_loss: 1.9525\n",
            "Trial 38 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.5714285969734192\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 21m 10s\n",
            "\n",
            "Search: Running Trial #39\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.005             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "96                |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "8                 |24                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0004              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6262 - loss: 1.6741\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4095\n",
            "  - Class 1: Loss = 3.7858\n",
            "  - Class 2: Loss = 0.4857\n",
            "  - Class 3: Loss = 2.7907\n",
            "  - Class 4: Loss = 1.4408\n",
            "  - Class 5: Loss = 4.0358\n",
            "  - Class 6: Loss = 1.3829\n",
            "  - Class 7: Loss = 3.0943\n",
            "  - Class 8: Loss = 4.6018\n",
            "  - Class 9: Loss = 2.9687\n",
            "  - Class 10: Loss = 4.0671\n",
            "  - Class 11: Loss = 4.7498\n",
            "  - Class 12: Loss = 6.3403\n",
            "  - Class 13: Loss = 2.3369\n",
            "  - Class 14: Loss = 3.7007\n",
            "  - Class 15: Loss = 5.1615\n",
            "  - Class 16: Loss = 5.4476\n",
            "  - Class 17: Loss = 2.0177\n",
            "  - Class 18: Loss = 3.9458\n",
            "  - Class 19: Loss = 4.3926\n",
            "  - Class 20: Loss = 3.9037\n",
            "  - Class 21: Loss = 6.1816\n",
            "  - Class 22: Loss = 5.7602\n",
            "  - Class 23: Loss = 4.3743\n",
            "  - Class 24: Loss = 6.9535\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 301ms/step - accuracy: 0.6264 - loss: 1.6730 - val_accuracy: 0.5794 - val_loss: 1.7530\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6480 - loss: 1.5237 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4342\n",
            "  - Class 1: Loss = 3.7488\n",
            "  - Class 2: Loss = 0.2476\n",
            "  - Class 3: Loss = 2.4461\n",
            "  - Class 4: Loss = 1.1223\n",
            "  - Class 5: Loss = 4.3923\n",
            "  - Class 6: Loss = 1.0782\n",
            "  - Class 7: Loss = 2.8029\n",
            "  - Class 8: Loss = 4.4975\n",
            "  - Class 9: Loss = 2.4883\n",
            "  - Class 10: Loss = 4.2585\n",
            "  - Class 11: Loss = 4.1313\n",
            "  - Class 12: Loss = 6.0607\n",
            "  - Class 13: Loss = 1.9746\n",
            "  - Class 14: Loss = 3.3398\n",
            "  - Class 15: Loss = 4.6851\n",
            "  - Class 16: Loss = 5.2161\n",
            "  - Class 17: Loss = 1.7764\n",
            "  - Class 18: Loss = 3.6637\n",
            "  - Class 19: Loss = 4.1446\n",
            "  - Class 20: Loss = 3.8303\n",
            "  - Class 21: Loss = 6.1780\n",
            "  - Class 22: Loss = 5.7922\n",
            "  - Class 23: Loss = 4.1541\n",
            "  - Class 24: Loss = 6.6650\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6499 - loss: 1.5217 - val_accuracy: 0.5741 - val_loss: 1.6974\n",
            "Trial 39 Complete [00h 00m 20s]\n",
            "val_accuracy: 0.579365074634552\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 21m 30s\n",
            "\n",
            "Search: Running Trial #40\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "160               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "24                |24                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0026              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6066 - loss: 1.6792\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5419\n",
            "  - Class 1: Loss = 3.5943\n",
            "  - Class 2: Loss = 0.4726\n",
            "  - Class 3: Loss = 2.8951\n",
            "  - Class 4: Loss = 0.7025\n",
            "  - Class 5: Loss = 5.4814\n",
            "  - Class 6: Loss = 2.0515\n",
            "  - Class 7: Loss = 3.2199\n",
            "  - Class 8: Loss = 4.2439\n",
            "  - Class 9: Loss = 3.0074\n",
            "  - Class 10: Loss = 4.9375\n",
            "  - Class 11: Loss = 4.4691\n",
            "  - Class 12: Loss = 5.5311\n",
            "  - Class 13: Loss = 2.4110\n",
            "  - Class 14: Loss = 3.6279\n",
            "  - Class 15: Loss = 4.5461\n",
            "  - Class 16: Loss = 4.9597\n",
            "  - Class 17: Loss = 2.0333\n",
            "  - Class 18: Loss = 3.8693\n",
            "  - Class 19: Loss = 3.7702\n",
            "  - Class 20: Loss = 3.5289\n",
            "  - Class 21: Loss = 6.0487\n",
            "  - Class 22: Loss = 5.7062\n",
            "  - Class 23: Loss = 4.2011\n",
            "  - Class 24: Loss = 5.4064\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 341ms/step - accuracy: 0.6067 - loss: 1.6788 - val_accuracy: 0.5820 - val_loss: 1.7550\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 1.5854 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4861\n",
            "  - Class 1: Loss = 3.6541\n",
            "  - Class 2: Loss = 0.2898\n",
            "  - Class 3: Loss = 2.6191\n",
            "  - Class 4: Loss = 0.5583\n",
            "  - Class 5: Loss = 5.4776\n",
            "  - Class 6: Loss = 1.3260\n",
            "  - Class 7: Loss = 2.8584\n",
            "  - Class 8: Loss = 4.3672\n",
            "  - Class 9: Loss = 2.7240\n",
            "  - Class 10: Loss = 4.8207\n",
            "  - Class 11: Loss = 4.4977\n",
            "  - Class 12: Loss = 5.9668\n",
            "  - Class 13: Loss = 2.2942\n",
            "  - Class 14: Loss = 3.2695\n",
            "  - Class 15: Loss = 4.8316\n",
            "  - Class 16: Loss = 5.2265\n",
            "  - Class 17: Loss = 1.8687\n",
            "  - Class 18: Loss = 3.8371\n",
            "  - Class 19: Loss = 3.6020\n",
            "  - Class 20: Loss = 3.5559\n",
            "  - Class 21: Loss = 6.1327\n",
            "  - Class 22: Loss = 5.6361\n",
            "  - Class 23: Loss = 4.0841\n",
            "  - Class 24: Loss = 5.6192\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6195 - loss: 1.5618 - val_accuracy: 0.5926 - val_loss: 1.6825\n",
            "Trial 40 Complete [00h 00m 22s]\n",
            "val_accuracy: 0.5925925970077515\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 21m 52s\n",
            "\n",
            "Search: Running Trial #41\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0005            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "96                |256               |units_layer_1\n",
            "128               |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "8                 |24                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0030              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5775 - loss: 2.2766\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.3197\n",
            "  - Class 1: Loss = 3.9261\n",
            "  - Class 2: Loss = 1.4416\n",
            "  - Class 3: Loss = 3.0724\n",
            "  - Class 4: Loss = 2.8165\n",
            "  - Class 5: Loss = 2.9519\n",
            "  - Class 6: Loss = 2.1633\n",
            "  - Class 7: Loss = 3.4539\n",
            "  - Class 8: Loss = 3.1291\n",
            "  - Class 9: Loss = 3.2025\n",
            "  - Class 10: Loss = 3.0767\n",
            "  - Class 11: Loss = 4.1575\n",
            "  - Class 12: Loss = 3.3948\n",
            "  - Class 13: Loss = 3.0566\n",
            "  - Class 14: Loss = 3.7938\n",
            "  - Class 15: Loss = 3.6814\n",
            "  - Class 16: Loss = 4.4414\n",
            "  - Class 17: Loss = 2.4004\n",
            "  - Class 18: Loss = 3.2500\n",
            "  - Class 19: Loss = 3.2564\n",
            "  - Class 20: Loss = 3.3482\n",
            "  - Class 21: Loss = 4.6195\n",
            "  - Class 22: Loss = 3.6401\n",
            "  - Class 23: Loss = 3.8602\n",
            "  - Class 24: Loss = 4.2178\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 336ms/step - accuracy: 0.5778 - loss: 2.2752 - val_accuracy: 0.5688 - val_loss: 2.2097\n",
            "Epoch 4/4\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6226 - loss: 2.0821 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.1309\n",
            "  - Class 1: Loss = 3.9204\n",
            "  - Class 2: Loss = 1.3869\n",
            "  - Class 3: Loss = 3.0782\n",
            "  - Class 4: Loss = 2.5062\n",
            "  - Class 5: Loss = 3.0515\n",
            "  - Class 6: Loss = 2.0715\n",
            "  - Class 7: Loss = 3.4396\n",
            "  - Class 8: Loss = 3.1663\n",
            "  - Class 9: Loss = 3.1588\n",
            "  - Class 10: Loss = 3.0538\n",
            "  - Class 11: Loss = 4.2315\n",
            "  - Class 12: Loss = 3.5856\n",
            "  - Class 13: Loss = 2.9891\n",
            "  - Class 14: Loss = 3.8098\n",
            "  - Class 15: Loss = 3.8243\n",
            "  - Class 16: Loss = 4.4988\n",
            "  - Class 17: Loss = 2.2854\n",
            "  - Class 18: Loss = 3.2955\n",
            "  - Class 19: Loss = 3.4029\n",
            "  - Class 20: Loss = 3.4303\n",
            "  - Class 21: Loss = 4.7404\n",
            "  - Class 22: Loss = 3.8169\n",
            "  - Class 23: Loss = 3.9533\n",
            "  - Class 24: Loss = 4.4085\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6208 - loss: 2.0755 - val_accuracy: 0.5767 - val_loss: 2.1065\n",
            "Trial 41 Complete [00h 00m 22s]\n",
            "val_accuracy: 0.5767195820808411\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 22m 14s\n",
            "\n",
            "Search: Running Trial #42\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "128               |256               |units_layer_1\n",
            "96                |32                |units_layer_2\n",
            "32                |64                |units_layer_3\n",
            "8                 |24                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0013              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5988 - loss: 2.0400\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.9368\n",
            "  - Class 1: Loss = 3.2927\n",
            "  - Class 2: Loss = 1.4292\n",
            "  - Class 3: Loss = 3.1273\n",
            "  - Class 4: Loss = 1.9767\n",
            "  - Class 5: Loss = 2.6432\n",
            "  - Class 6: Loss = 2.0283\n",
            "  - Class 7: Loss = 3.0827\n",
            "  - Class 8: Loss = 4.0664\n",
            "  - Class 9: Loss = 2.9551\n",
            "  - Class 10: Loss = 3.1271\n",
            "  - Class 11: Loss = 4.1721\n",
            "  - Class 12: Loss = 3.9563\n",
            "  - Class 13: Loss = 3.0470\n",
            "  - Class 14: Loss = 3.9024\n",
            "  - Class 15: Loss = 4.4344\n",
            "  - Class 16: Loss = 3.9148\n",
            "  - Class 17: Loss = 2.4406\n",
            "  - Class 18: Loss = 3.7087\n",
            "  - Class 19: Loss = 3.4191\n",
            "  - Class 20: Loss = 3.5199\n",
            "  - Class 21: Loss = 4.0911\n",
            "  - Class 22: Loss = 3.8336\n",
            "  - Class 23: Loss = 3.6406\n",
            "  - Class 24: Loss = 3.3353\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 323ms/step - accuracy: 0.5990 - loss: 2.0389 - val_accuracy: 0.5820 - val_loss: 1.9880\n",
            "Epoch 4/4\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6476 - loss: 1.8232 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.7460\n",
            "  - Class 1: Loss = 3.4356\n",
            "  - Class 2: Loss = 1.2274\n",
            "  - Class 3: Loss = 3.0157\n",
            "  - Class 4: Loss = 1.5267\n",
            "  - Class 5: Loss = 2.5605\n",
            "  - Class 6: Loss = 1.6640\n",
            "  - Class 7: Loss = 3.1454\n",
            "  - Class 8: Loss = 3.9881\n",
            "  - Class 9: Loss = 2.9370\n",
            "  - Class 10: Loss = 3.1020\n",
            "  - Class 11: Loss = 4.2686\n",
            "  - Class 12: Loss = 4.1519\n",
            "  - Class 13: Loss = 3.0910\n",
            "  - Class 14: Loss = 3.8800\n",
            "  - Class 15: Loss = 4.5629\n",
            "  - Class 16: Loss = 4.1041\n",
            "  - Class 17: Loss = 2.2696\n",
            "  - Class 18: Loss = 3.7309\n",
            "  - Class 19: Loss = 3.4805\n",
            "  - Class 20: Loss = 3.4755\n",
            "  - Class 21: Loss = 4.4649\n",
            "  - Class 22: Loss = 3.9480\n",
            "  - Class 23: Loss = 3.5775\n",
            "  - Class 24: Loss = 3.7654\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6439 - loss: 1.8199 - val_accuracy: 0.5952 - val_loss: 1.8858\n",
            "Trial 42 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.5952380895614624\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 22m 35s\n",
            "\n",
            "Search: Running Trial #43\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0005            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "64                |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "16                |24                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0031              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5700 - loss: 1.9612\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.6800\n",
            "  - Class 1: Loss = 3.4553\n",
            "  - Class 2: Loss = 1.1685\n",
            "  - Class 3: Loss = 3.1979\n",
            "  - Class 4: Loss = 1.8411\n",
            "  - Class 5: Loss = 3.5443\n",
            "  - Class 6: Loss = 2.4877\n",
            "  - Class 7: Loss = 3.8571\n",
            "  - Class 8: Loss = 4.5183\n",
            "  - Class 9: Loss = 2.9737\n",
            "  - Class 10: Loss = 3.8348\n",
            "  - Class 11: Loss = 3.3915\n",
            "  - Class 12: Loss = 4.9228\n",
            "  - Class 13: Loss = 3.1877\n",
            "  - Class 14: Loss = 3.5023\n",
            "  - Class 15: Loss = 4.1549\n",
            "  - Class 16: Loss = 4.8974\n",
            "  - Class 17: Loss = 2.9315\n",
            "  - Class 18: Loss = 4.4424\n",
            "  - Class 19: Loss = 4.2535\n",
            "  - Class 20: Loss = 3.9841\n",
            "  - Class 21: Loss = 4.4431\n",
            "  - Class 22: Loss = 4.8234\n",
            "  - Class 23: Loss = 4.1519\n",
            "  - Class 24: Loss = 4.8756\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 281ms/step - accuracy: 0.5701 - loss: 1.9605 - val_accuracy: 0.5556 - val_loss: 1.9788\n",
            "Epoch 4/4\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6085 - loss: 1.8184 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5982\n",
            "  - Class 1: Loss = 3.5764\n",
            "  - Class 2: Loss = 0.9774\n",
            "  - Class 3: Loss = 3.0843\n",
            "  - Class 4: Loss = 1.5720\n",
            "  - Class 5: Loss = 3.5675\n",
            "  - Class 6: Loss = 1.9939\n",
            "  - Class 7: Loss = 3.5954\n",
            "  - Class 8: Loss = 4.3952\n",
            "  - Class 9: Loss = 2.9553\n",
            "  - Class 10: Loss = 4.0643\n",
            "  - Class 11: Loss = 3.4850\n",
            "  - Class 12: Loss = 5.1792\n",
            "  - Class 13: Loss = 3.0923\n",
            "  - Class 14: Loss = 3.4083\n",
            "  - Class 15: Loss = 4.3750\n",
            "  - Class 16: Loss = 4.9277\n",
            "  - Class 17: Loss = 2.7267\n",
            "  - Class 18: Loss = 4.3880\n",
            "  - Class 19: Loss = 4.3917\n",
            "  - Class 20: Loss = 4.1012\n",
            "  - Class 21: Loss = 4.7818\n",
            "  - Class 22: Loss = 4.9308\n",
            "  - Class 23: Loss = 4.2535\n",
            "  - Class 24: Loss = 5.1269\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6083 - loss: 1.7985 - val_accuracy: 0.5794 - val_loss: 1.9127\n",
            "Trial 43 Complete [00h 00m 19s]\n",
            "val_accuracy: 0.579365074634552\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 22m 54s\n",
            "\n",
            "Search: Running Trial #44\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0005            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "64                |256               |units_layer_1\n",
            "96                |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "8                 |24                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0003              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5806 - loss: 2.2885\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.3955\n",
            "  - Class 1: Loss = 3.0705\n",
            "  - Class 2: Loss = 1.9109\n",
            "  - Class 3: Loss = 3.1135\n",
            "  - Class 4: Loss = 2.3960\n",
            "  - Class 5: Loss = 3.6471\n",
            "  - Class 6: Loss = 3.4734\n",
            "  - Class 7: Loss = 3.4567\n",
            "  - Class 8: Loss = 3.7015\n",
            "  - Class 9: Loss = 3.0537\n",
            "  - Class 10: Loss = 3.2852\n",
            "  - Class 11: Loss = 4.0769\n",
            "  - Class 12: Loss = 4.0421\n",
            "  - Class 13: Loss = 2.7396\n",
            "  - Class 14: Loss = 4.0987\n",
            "  - Class 15: Loss = 4.5063\n",
            "  - Class 16: Loss = 4.4334\n",
            "  - Class 17: Loss = 2.5243\n",
            "  - Class 18: Loss = 3.2217\n",
            "  - Class 19: Loss = 3.7362\n",
            "  - Class 20: Loss = 3.5840\n",
            "  - Class 21: Loss = 3.3756\n",
            "  - Class 22: Loss = 4.1606\n",
            "  - Class 23: Loss = 4.0522\n",
            "  - Class 24: Loss = 3.6840\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 320ms/step - accuracy: 0.5803 - loss: 2.2880 - val_accuracy: 0.5370 - val_loss: 2.2472\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5570 - loss: 2.2063 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.2054\n",
            "  - Class 1: Loss = 3.1812\n",
            "  - Class 2: Loss = 1.8168\n",
            "  - Class 3: Loss = 3.0433\n",
            "  - Class 4: Loss = 2.2082\n",
            "  - Class 5: Loss = 3.8083\n",
            "  - Class 6: Loss = 3.2707\n",
            "  - Class 7: Loss = 3.4214\n",
            "  - Class 8: Loss = 3.8283\n",
            "  - Class 9: Loss = 2.9582\n",
            "  - Class 10: Loss = 3.4106\n",
            "  - Class 11: Loss = 4.0562\n",
            "  - Class 12: Loss = 4.2167\n",
            "  - Class 13: Loss = 2.7780\n",
            "  - Class 14: Loss = 4.0589\n",
            "  - Class 15: Loss = 4.4971\n",
            "  - Class 16: Loss = 4.4319\n",
            "  - Class 17: Loss = 2.4648\n",
            "  - Class 18: Loss = 3.3082\n",
            "  - Class 19: Loss = 3.8004\n",
            "  - Class 20: Loss = 3.6387\n",
            "  - Class 21: Loss = 3.5480\n",
            "  - Class 22: Loss = 4.2866\n",
            "  - Class 23: Loss = 4.0719\n",
            "  - Class 24: Loss = 3.8054\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5621 - loss: 2.1757 - val_accuracy: 0.5397 - val_loss: 2.1392\n",
            "Trial 44 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.5396825671195984\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 23m 15s\n",
            "\n",
            "Search: Running Trial #45\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.005             |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "128               |256               |units_layer_1\n",
            "96                |32                |units_layer_2\n",
            "32                |64                |units_layer_3\n",
            "16                |24                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0001              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5453 - loss: 3.0125\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.6278\n",
            "  - Class 1: Loss = 3.2036\n",
            "  - Class 2: Loss = 3.1825\n",
            "  - Class 3: Loss = 3.1673\n",
            "  - Class 4: Loss = 3.0195\n",
            "  - Class 5: Loss = 3.3605\n",
            "  - Class 6: Loss = 3.1999\n",
            "  - Class 7: Loss = 3.1504\n",
            "  - Class 8: Loss = 3.3627\n",
            "  - Class 9: Loss = 3.0622\n",
            "  - Class 10: Loss = 3.3883\n",
            "  - Class 11: Loss = 3.3562\n",
            "  - Class 12: Loss = 3.4739\n",
            "  - Class 13: Loss = 3.0537\n",
            "  - Class 14: Loss = 3.2440\n",
            "  - Class 15: Loss = 3.3840\n",
            "  - Class 16: Loss = 3.4052\n",
            "  - Class 17: Loss = 2.8123\n",
            "  - Class 18: Loss = 3.2297\n",
            "  - Class 19: Loss = 3.3441\n",
            "  - Class 20: Loss = 3.3044\n",
            "  - Class 21: Loss = 3.4114\n",
            "  - Class 22: Loss = 3.4818\n",
            "  - Class 23: Loss = 3.3257\n",
            "  - Class 24: Loss = 3.4835\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 305ms/step - accuracy: 0.5451 - loss: 3.0115 - val_accuracy: 0.5079 - val_loss: 2.8724\n",
            "Epoch 4/4\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5405 - loss: 2.8312 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.3067\n",
            "  - Class 1: Loss = 3.2489\n",
            "  - Class 2: Loss = 3.1325\n",
            "  - Class 3: Loss = 3.1685\n",
            "  - Class 4: Loss = 2.9404\n",
            "  - Class 5: Loss = 3.4883\n",
            "  - Class 6: Loss = 3.2054\n",
            "  - Class 7: Loss = 3.1466\n",
            "  - Class 8: Loss = 3.4664\n",
            "  - Class 9: Loss = 3.0108\n",
            "  - Class 10: Loss = 3.4925\n",
            "  - Class 11: Loss = 3.4551\n",
            "  - Class 12: Loss = 3.5999\n",
            "  - Class 13: Loss = 2.9924\n",
            "  - Class 14: Loss = 3.2766\n",
            "  - Class 15: Loss = 3.4837\n",
            "  - Class 16: Loss = 3.5187\n",
            "  - Class 17: Loss = 2.6837\n",
            "  - Class 18: Loss = 3.2768\n",
            "  - Class 19: Loss = 3.4106\n",
            "  - Class 20: Loss = 3.3556\n",
            "  - Class 21: Loss = 3.5274\n",
            "  - Class 22: Loss = 3.6032\n",
            "  - Class 23: Loss = 3.4025\n",
            "  - Class 24: Loss = 3.6104\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5391 - loss: 2.8109 - val_accuracy: 0.5079 - val_loss: 2.7010\n",
            "Trial 45 Complete [00h 00m 20s]\n",
            "val_accuracy: 0.5079365372657776\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 23m 35s\n",
            "\n",
            "Search: Running Trial #46\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.005             |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "192               |256               |units_layer_1\n",
            "96                |32                |units_layer_2\n",
            "32                |64                |units_layer_3\n",
            "32                |24                |units_layer_4\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0002              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 3/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5152 - loss: 5.3368\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.3993\n",
            "  - Class 1: Loss = 3.2226\n",
            "  - Class 2: Loss = 3.1586\n",
            "  - Class 3: Loss = 3.0804\n",
            "  - Class 4: Loss = 2.9449\n",
            "  - Class 5: Loss = 3.5598\n",
            "  - Class 6: Loss = 3.2403\n",
            "  - Class 7: Loss = 3.1133\n",
            "  - Class 8: Loss = 3.5013\n",
            "  - Class 9: Loss = 2.9493\n",
            "  - Class 10: Loss = 3.4532\n",
            "  - Class 11: Loss = 3.4399\n",
            "  - Class 12: Loss = 3.4702\n",
            "  - Class 13: Loss = 3.0199\n",
            "  - Class 14: Loss = 3.2052\n",
            "  - Class 15: Loss = 3.4572\n",
            "  - Class 16: Loss = 3.3858\n",
            "  - Class 17: Loss = 2.8493\n",
            "  - Class 18: Loss = 3.2456\n",
            "  - Class 19: Loss = 3.3947\n",
            "  - Class 20: Loss = 3.2749\n",
            "  - Class 21: Loss = 3.5955\n",
            "  - Class 22: Loss = 3.6036\n",
            "  - Class 23: Loss = 3.3919\n",
            "  - Class 24: Loss = 3.5335\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 350ms/step - accuracy: 0.5156 - loss: 5.3128 - val_accuracy: 0.5079 - val_loss: 2.7526\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5665 - loss: 2.6773 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.0838\n",
            "  - Class 1: Loss = 3.2518\n",
            "  - Class 2: Loss = 3.1644\n",
            "  - Class 3: Loss = 3.1080\n",
            "  - Class 4: Loss = 2.9092\n",
            "  - Class 5: Loss = 3.6877\n",
            "  - Class 6: Loss = 3.2208\n",
            "  - Class 7: Loss = 3.1214\n",
            "  - Class 8: Loss = 3.6018\n",
            "  - Class 9: Loss = 2.9437\n",
            "  - Class 10: Loss = 3.5511\n",
            "  - Class 11: Loss = 3.5296\n",
            "  - Class 12: Loss = 3.5994\n",
            "  - Class 13: Loss = 3.0021\n",
            "  - Class 14: Loss = 3.2451\n",
            "  - Class 15: Loss = 3.5561\n",
            "  - Class 16: Loss = 3.4962\n",
            "  - Class 17: Loss = 2.7135\n",
            "  - Class 18: Loss = 3.2914\n",
            "  - Class 19: Loss = 3.4760\n",
            "  - Class 20: Loss = 3.3359\n",
            "  - Class 21: Loss = 3.7202\n",
            "  - Class 22: Loss = 3.7226\n",
            "  - Class 23: Loss = 3.4687\n",
            "  - Class 24: Loss = 3.6643\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5552 - loss: 2.6692 - val_accuracy: 0.5079 - val_loss: 2.5914\n",
            "Trial 46 Complete [00h 00m 23s]\n",
            "val_accuracy: 0.5079365372657776\n",
            "\n",
            "Best val_accuracy So Far: 0.6084656119346619\n",
            "Total elapsed time: 00h 23m 58s\n",
            "\n",
            "Search: Running Trial #47\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "256               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "24                |24                |units_layer_4\n",
            "10                |4                 |tuner/epochs\n",
            "4                 |2                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "2                 |1                 |tuner/round\n",
            "0036              |0021              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 5/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6719 - loss: 1.3064\n",
            "Epoch 5: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4048\n",
            "  - Class 1: Loss = 3.5210\n",
            "  - Class 2: Loss = 0.1344\n",
            "  - Class 3: Loss = 1.9536\n",
            "  - Class 4: Loss = 0.5754\n",
            "  - Class 5: Loss = 4.8825\n",
            "  - Class 6: Loss = 0.2860\n",
            "  - Class 7: Loss = 2.3799\n",
            "  - Class 8: Loss = 4.2650\n",
            "  - Class 9: Loss = 2.3253\n",
            "  - Class 10: Loss = 3.4088\n",
            "  - Class 11: Loss = 3.6193\n",
            "  - Class 12: Loss = 5.3650\n",
            "  - Class 13: Loss = 1.7388\n",
            "  - Class 14: Loss = 2.4683\n",
            "  - Class 15: Loss = 5.0733\n",
            "  - Class 16: Loss = 4.4609\n",
            "  - Class 17: Loss = 1.5201\n",
            "  - Class 18: Loss = 3.3517\n",
            "  - Class 19: Loss = 4.1507\n",
            "  - Class 20: Loss = 3.3740\n",
            "  - Class 21: Loss = 5.2735\n",
            "  - Class 22: Loss = 5.0893\n",
            "  - Class 23: Loss = 3.9406\n",
            "  - Class 24: Loss = 7.1037\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 301ms/step - accuracy: 0.6718 - loss: 1.3065 - val_accuracy: 0.6058 - val_loss: 1.5795\n",
            "Epoch 6/10\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6868 - loss: 1.2295 \n",
            "Epoch 6: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3394\n",
            "  - Class 1: Loss = 3.4792\n",
            "  - Class 2: Loss = 0.0993\n",
            "  - Class 3: Loss = 1.6894\n",
            "  - Class 4: Loss = 0.4280\n",
            "  - Class 5: Loss = 4.9658\n",
            "  - Class 6: Loss = 0.2126\n",
            "  - Class 7: Loss = 2.4093\n",
            "  - Class 8: Loss = 3.7804\n",
            "  - Class 9: Loss = 2.3256\n",
            "  - Class 10: Loss = 3.2664\n",
            "  - Class 11: Loss = 3.4564\n",
            "  - Class 12: Loss = 5.1174\n",
            "  - Class 13: Loss = 1.6197\n",
            "  - Class 14: Loss = 2.2901\n",
            "  - Class 15: Loss = 5.1547\n",
            "  - Class 16: Loss = 4.5619\n",
            "  - Class 17: Loss = 1.4591\n",
            "  - Class 18: Loss = 3.2579\n",
            "  - Class 19: Loss = 4.0119\n",
            "  - Class 20: Loss = 3.2869\n",
            "  - Class 21: Loss = 5.1753\n",
            "  - Class 22: Loss = 5.1996\n",
            "  - Class 23: Loss = 3.8221\n",
            "  - Class 24: Loss = 7.5794\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6835 - loss: 1.2291 - val_accuracy: 0.5979 - val_loss: 1.5763\n",
            "Epoch 7/10\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6850 - loss: 1.1202 \n",
            "Epoch 7: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3930\n",
            "  - Class 1: Loss = 3.3971\n",
            "  - Class 2: Loss = 0.0786\n",
            "  - Class 3: Loss = 1.6680\n",
            "  - Class 4: Loss = 0.3603\n",
            "  - Class 5: Loss = 5.0230\n",
            "  - Class 6: Loss = 0.1959\n",
            "  - Class 7: Loss = 1.9494\n",
            "  - Class 8: Loss = 3.5440\n",
            "  - Class 9: Loss = 1.8814\n",
            "  - Class 10: Loss = 2.9016\n",
            "  - Class 11: Loss = 3.2617\n",
            "  - Class 12: Loss = 4.9874\n",
            "  - Class 13: Loss = 1.4857\n",
            "  - Class 14: Loss = 1.9913\n",
            "  - Class 15: Loss = 4.8005\n",
            "  - Class 16: Loss = 4.3566\n",
            "  - Class 17: Loss = 1.2273\n",
            "  - Class 18: Loss = 2.9815\n",
            "  - Class 19: Loss = 3.7075\n",
            "  - Class 20: Loss = 2.9344\n",
            "  - Class 21: Loss = 5.1631\n",
            "  - Class 22: Loss = 5.1837\n",
            "  - Class 23: Loss = 3.5721\n",
            "  - Class 24: Loss = 7.0266\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6912 - loss: 1.1210 - val_accuracy: 0.6138 - val_loss: 1.5533\n",
            "Epoch 8/10\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.9997 \n",
            "Epoch 8: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3431\n",
            "  - Class 1: Loss = 3.3190\n",
            "  - Class 2: Loss = 0.0733\n",
            "  - Class 3: Loss = 1.4626\n",
            "  - Class 4: Loss = 0.3633\n",
            "  - Class 5: Loss = 5.0085\n",
            "  - Class 6: Loss = 0.1534\n",
            "  - Class 7: Loss = 1.9539\n",
            "  - Class 8: Loss = 3.2179\n",
            "  - Class 9: Loss = 1.8661\n",
            "  - Class 10: Loss = 2.5552\n",
            "  - Class 11: Loss = 3.1504\n",
            "  - Class 12: Loss = 5.0292\n",
            "  - Class 13: Loss = 1.4709\n",
            "  - Class 14: Loss = 1.7307\n",
            "  - Class 15: Loss = 4.7935\n",
            "  - Class 16: Loss = 4.3809\n",
            "  - Class 17: Loss = 1.1494\n",
            "  - Class 18: Loss = 2.7899\n",
            "  - Class 19: Loss = 3.2962\n",
            "  - Class 20: Loss = 2.8668\n",
            "  - Class 21: Loss = 5.2075\n",
            "  - Class 22: Loss = 5.2446\n",
            "  - Class 23: Loss = 3.4052\n",
            "  - Class 24: Loss = 7.1523\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7172 - loss: 1.0318 - val_accuracy: 0.6243 - val_loss: 1.5202\n",
            "Epoch 9/10\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 1.0188 \n",
            "Epoch 9: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3032\n",
            "  - Class 1: Loss = 3.4066\n",
            "  - Class 2: Loss = 0.0614\n",
            "  - Class 3: Loss = 1.2106\n",
            "  - Class 4: Loss = 0.3182\n",
            "  - Class 5: Loss = 4.9989\n",
            "  - Class 6: Loss = 0.1286\n",
            "  - Class 7: Loss = 1.8477\n",
            "  - Class 8: Loss = 3.0008\n",
            "  - Class 9: Loss = 1.6417\n",
            "  - Class 10: Loss = 2.4102\n",
            "  - Class 11: Loss = 3.0315\n",
            "  - Class 12: Loss = 4.8452\n",
            "  - Class 13: Loss = 1.3349\n",
            "  - Class 14: Loss = 1.6313\n",
            "  - Class 15: Loss = 4.6525\n",
            "  - Class 16: Loss = 4.3368\n",
            "  - Class 17: Loss = 1.1663\n",
            "  - Class 18: Loss = 2.9506\n",
            "  - Class 19: Loss = 2.6725\n",
            "  - Class 20: Loss = 2.8242\n",
            "  - Class 21: Loss = 5.1453\n",
            "  - Class 22: Loss = 5.2232\n",
            "  - Class 23: Loss = 3.0959\n",
            "  - Class 24: Loss = 7.5846\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7322 - loss: 1.0130 - val_accuracy: 0.6190 - val_loss: 1.5304\n",
            "Epoch 10/10\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7480 - loss: 0.9268 \n",
            "Epoch 10: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2499\n",
            "  - Class 1: Loss = 3.3818\n",
            "  - Class 2: Loss = 0.0640\n",
            "  - Class 3: Loss = 1.2188\n",
            "  - Class 4: Loss = 0.2850\n",
            "  - Class 5: Loss = 5.2099\n",
            "  - Class 6: Loss = 0.1127\n",
            "  - Class 7: Loss = 1.7207\n",
            "  - Class 8: Loss = 2.9525\n",
            "  - Class 9: Loss = 1.4850\n",
            "  - Class 10: Loss = 2.3796\n",
            "  - Class 11: Loss = 2.8167\n",
            "  - Class 12: Loss = 4.7848\n",
            "  - Class 13: Loss = 1.2984\n",
            "  - Class 14: Loss = 1.4525\n",
            "  - Class 15: Loss = 4.5236\n",
            "  - Class 16: Loss = 4.1841\n",
            "  - Class 17: Loss = 1.0087\n",
            "  - Class 18: Loss = 2.7945\n",
            "  - Class 19: Loss = 2.3983\n",
            "  - Class 20: Loss = 2.6911\n",
            "  - Class 21: Loss = 4.9722\n",
            "  - Class 22: Loss = 5.1899\n",
            "  - Class 23: Loss = 2.8279\n",
            "  - Class 24: Loss = 7.1885\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7452 - loss: 0.9365 - val_accuracy: 0.6243 - val_loss: 1.5282\n",
            "Trial 47 Complete [00h 00m 28s]\n",
            "val_accuracy: 0.6243386268615723\n",
            "\n",
            "Best val_accuracy So Far: 0.6243386268615723\n",
            "Total elapsed time: 00h 24m 26s\n",
            "\n",
            "Search: Running Trial #48\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "256               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "16                |24                |units_layer_4\n",
            "10                |10                |tuner/epochs\n",
            "4                 |4                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "2                 |2                 |tuner/round\n",
            "0034              |0036              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 5/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6648 - loss: 1.5136\n",
            "Epoch 5: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4364\n",
            "  - Class 1: Loss = 3.7889\n",
            "  - Class 2: Loss = 0.3047\n",
            "  - Class 3: Loss = 2.5936\n",
            "  - Class 4: Loss = 1.0143\n",
            "  - Class 5: Loss = 6.1538\n",
            "  - Class 6: Loss = 1.2387\n",
            "  - Class 7: Loss = 2.7956\n",
            "  - Class 8: Loss = 4.2648\n",
            "  - Class 9: Loss = 2.7299\n",
            "  - Class 10: Loss = 3.6146\n",
            "  - Class 11: Loss = 4.0684\n",
            "  - Class 12: Loss = 5.1959\n",
            "  - Class 13: Loss = 2.2478\n",
            "  - Class 14: Loss = 3.1339\n",
            "  - Class 15: Loss = 4.4518\n",
            "  - Class 16: Loss = 4.2683\n",
            "  - Class 17: Loss = 1.8697\n",
            "  - Class 18: Loss = 3.5225\n",
            "  - Class 19: Loss = 4.3485\n",
            "  - Class 20: Loss = 3.5384\n",
            "  - Class 21: Loss = 5.3836\n",
            "  - Class 22: Loss = 4.3449\n",
            "  - Class 23: Loss = 4.0348\n",
            "  - Class 24: Loss = 5.1878\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 285ms/step - accuracy: 0.6648 - loss: 1.5134 - val_accuracy: 0.6032 - val_loss: 1.6748\n",
            "Epoch 6/10\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6814 - loss: 1.3746 \n",
            "Epoch 6: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4032\n",
            "  - Class 1: Loss = 3.6788\n",
            "  - Class 2: Loss = 0.2293\n",
            "  - Class 3: Loss = 2.3234\n",
            "  - Class 4: Loss = 0.7402\n",
            "  - Class 5: Loss = 6.1751\n",
            "  - Class 6: Loss = 1.0046\n",
            "  - Class 7: Loss = 2.5400\n",
            "  - Class 8: Loss = 4.2127\n",
            "  - Class 9: Loss = 2.5754\n",
            "  - Class 10: Loss = 3.4878\n",
            "  - Class 11: Loss = 3.9003\n",
            "  - Class 12: Loss = 5.2592\n",
            "  - Class 13: Loss = 2.1431\n",
            "  - Class 14: Loss = 2.8455\n",
            "  - Class 15: Loss = 4.1478\n",
            "  - Class 16: Loss = 4.3553\n",
            "  - Class 17: Loss = 1.7859\n",
            "  - Class 18: Loss = 3.3990\n",
            "  - Class 19: Loss = 4.2871\n",
            "  - Class 20: Loss = 3.4432\n",
            "  - Class 21: Loss = 5.3163\n",
            "  - Class 22: Loss = 4.4573\n",
            "  - Class 23: Loss = 3.9862\n",
            "  - Class 24: Loss = 5.5371\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6789 - loss: 1.3773 - val_accuracy: 0.6032 - val_loss: 1.6367\n",
            "Epoch 7/10\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6667 - loss: 1.3457 \n",
            "Epoch 7: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3414\n",
            "  - Class 1: Loss = 3.6414\n",
            "  - Class 2: Loss = 0.1900\n",
            "  - Class 3: Loss = 2.1848\n",
            "  - Class 4: Loss = 0.6936\n",
            "  - Class 5: Loss = 6.1481\n",
            "  - Class 6: Loss = 0.8968\n",
            "  - Class 7: Loss = 2.4731\n",
            "  - Class 8: Loss = 4.2234\n",
            "  - Class 9: Loss = 2.4209\n",
            "  - Class 10: Loss = 3.4400\n",
            "  - Class 11: Loss = 3.7622\n",
            "  - Class 12: Loss = 5.4223\n",
            "  - Class 13: Loss = 2.0245\n",
            "  - Class 14: Loss = 2.8286\n",
            "  - Class 15: Loss = 4.3147\n",
            "  - Class 16: Loss = 4.5326\n",
            "  - Class 17: Loss = 1.6532\n",
            "  - Class 18: Loss = 3.4100\n",
            "  - Class 19: Loss = 4.2659\n",
            "  - Class 20: Loss = 3.3237\n",
            "  - Class 21: Loss = 5.2666\n",
            "  - Class 22: Loss = 4.7367\n",
            "  - Class 23: Loss = 4.0072\n",
            "  - Class 24: Loss = 5.9666\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6675 - loss: 1.3418 - val_accuracy: 0.6058 - val_loss: 1.5980\n",
            "Epoch 8/10\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6642 - loss: 1.3306 \n",
            "Epoch 8: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3462\n",
            "  - Class 1: Loss = 3.4558\n",
            "  - Class 2: Loss = 0.1586\n",
            "  - Class 3: Loss = 1.9954\n",
            "  - Class 4: Loss = 0.5288\n",
            "  - Class 5: Loss = 6.0507\n",
            "  - Class 6: Loss = 0.6191\n",
            "  - Class 7: Loss = 2.2839\n",
            "  - Class 8: Loss = 4.0567\n",
            "  - Class 9: Loss = 2.2310\n",
            "  - Class 10: Loss = 3.2943\n",
            "  - Class 11: Loss = 3.4963\n",
            "  - Class 12: Loss = 5.3697\n",
            "  - Class 13: Loss = 1.8491\n",
            "  - Class 14: Loss = 2.5194\n",
            "  - Class 15: Loss = 3.9910\n",
            "  - Class 16: Loss = 4.5121\n",
            "  - Class 17: Loss = 1.4954\n",
            "  - Class 18: Loss = 3.3613\n",
            "  - Class 19: Loss = 4.1839\n",
            "  - Class 20: Loss = 3.1181\n",
            "  - Class 21: Loss = 5.3541\n",
            "  - Class 22: Loss = 4.5631\n",
            "  - Class 23: Loss = 3.8256\n",
            "  - Class 24: Loss = 6.1417\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6719 - loss: 1.2995 - val_accuracy: 0.6190 - val_loss: 1.5848\n",
            "Epoch 9/10\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6926 - loss: 1.1987 \n",
            "Epoch 9: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3244\n",
            "  - Class 1: Loss = 3.3345\n",
            "  - Class 2: Loss = 0.1470\n",
            "  - Class 3: Loss = 1.7527\n",
            "  - Class 4: Loss = 0.4118\n",
            "  - Class 5: Loss = 6.0579\n",
            "  - Class 6: Loss = 0.5496\n",
            "  - Class 7: Loss = 2.2933\n",
            "  - Class 8: Loss = 3.9973\n",
            "  - Class 9: Loss = 2.0146\n",
            "  - Class 10: Loss = 3.1564\n",
            "  - Class 11: Loss = 3.1598\n",
            "  - Class 12: Loss = 5.5238\n",
            "  - Class 13: Loss = 1.6842\n",
            "  - Class 14: Loss = 2.2471\n",
            "  - Class 15: Loss = 3.9924\n",
            "  - Class 16: Loss = 4.6229\n",
            "  - Class 17: Loss = 1.3411\n",
            "  - Class 18: Loss = 3.3013\n",
            "  - Class 19: Loss = 4.0241\n",
            "  - Class 20: Loss = 2.9400\n",
            "  - Class 21: Loss = 5.0913\n",
            "  - Class 22: Loss = 4.4956\n",
            "  - Class 23: Loss = 3.7171\n",
            "  - Class 24: Loss = 6.2747\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6964 - loss: 1.1862 - val_accuracy: 0.6058 - val_loss: 1.5678\n",
            "Epoch 10/10\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6913 - loss: 1.1437 \n",
            "Epoch 10: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2743\n",
            "  - Class 1: Loss = 3.2635\n",
            "  - Class 2: Loss = 0.1548\n",
            "  - Class 3: Loss = 1.6030\n",
            "  - Class 4: Loss = 0.3523\n",
            "  - Class 5: Loss = 6.0757\n",
            "  - Class 6: Loss = 0.4652\n",
            "  - Class 7: Loss = 2.1989\n",
            "  - Class 8: Loss = 3.8755\n",
            "  - Class 9: Loss = 1.8113\n",
            "  - Class 10: Loss = 3.0326\n",
            "  - Class 11: Loss = 2.8034\n",
            "  - Class 12: Loss = 5.4016\n",
            "  - Class 13: Loss = 1.7849\n",
            "  - Class 14: Loss = 2.0296\n",
            "  - Class 15: Loss = 4.0337\n",
            "  - Class 16: Loss = 4.6539\n",
            "  - Class 17: Loss = 1.3146\n",
            "  - Class 18: Loss = 3.3818\n",
            "  - Class 19: Loss = 3.8054\n",
            "  - Class 20: Loss = 2.9331\n",
            "  - Class 21: Loss = 5.2911\n",
            "  - Class 22: Loss = 4.5768\n",
            "  - Class 23: Loss = 3.6587\n",
            "  - Class 24: Loss = 6.4319\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6993 - loss: 1.1304 - val_accuracy: 0.6323 - val_loss: 1.5569\n",
            "Trial 48 Complete [00h 00m 28s]\n",
            "val_accuracy: 0.6322751045227051\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 24m 54s\n",
            "\n",
            "Search: Running Trial #49\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "128               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "32                |16                |units_layer_4\n",
            "10                |10                |tuner/epochs\n",
            "4                 |4                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "2                 |2                 |tuner/round\n",
            "0035              |0034              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 5/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6421 - loss: 1.4773\n",
            "Epoch 5: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4966\n",
            "  - Class 1: Loss = 3.5278\n",
            "  - Class 2: Loss = 0.2203\n",
            "  - Class 3: Loss = 2.3554\n",
            "  - Class 4: Loss = 0.4942\n",
            "  - Class 5: Loss = 5.3468\n",
            "  - Class 6: Loss = 0.7389\n",
            "  - Class 7: Loss = 2.7020\n",
            "  - Class 8: Loss = 4.0654\n",
            "  - Class 9: Loss = 2.4131\n",
            "  - Class 10: Loss = 3.1061\n",
            "  - Class 11: Loss = 4.4758\n",
            "  - Class 12: Loss = 6.2931\n",
            "  - Class 13: Loss = 1.9915\n",
            "  - Class 14: Loss = 2.9591\n",
            "  - Class 15: Loss = 4.7053\n",
            "  - Class 16: Loss = 5.0551\n",
            "  - Class 17: Loss = 1.7366\n",
            "  - Class 18: Loss = 3.5907\n",
            "  - Class 19: Loss = 3.8444\n",
            "  - Class 20: Loss = 3.5474\n",
            "  - Class 21: Loss = 5.6389\n",
            "  - Class 22: Loss = 5.5170\n",
            "  - Class 23: Loss = 4.1680\n",
            "  - Class 24: Loss = 6.2005\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 308ms/step - accuracy: 0.6422 - loss: 1.4766 - val_accuracy: 0.5926 - val_loss: 1.5952\n",
            "Epoch 6/10\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6386 - loss: 1.3836 \n",
            "Epoch 6: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4232\n",
            "  - Class 1: Loss = 3.5355\n",
            "  - Class 2: Loss = 0.1676\n",
            "  - Class 3: Loss = 2.1906\n",
            "  - Class 4: Loss = 0.4293\n",
            "  - Class 5: Loss = 5.4972\n",
            "  - Class 6: Loss = 0.4405\n",
            "  - Class 7: Loss = 2.4485\n",
            "  - Class 8: Loss = 4.1203\n",
            "  - Class 9: Loss = 2.3787\n",
            "  - Class 10: Loss = 2.9191\n",
            "  - Class 11: Loss = 4.5194\n",
            "  - Class 12: Loss = 6.4264\n",
            "  - Class 13: Loss = 1.9448\n",
            "  - Class 14: Loss = 2.8289\n",
            "  - Class 15: Loss = 4.7790\n",
            "  - Class 16: Loss = 4.9472\n",
            "  - Class 17: Loss = 1.8034\n",
            "  - Class 18: Loss = 3.4120\n",
            "  - Class 19: Loss = 3.5485\n",
            "  - Class 20: Loss = 3.0785\n",
            "  - Class 21: Loss = 5.8605\n",
            "  - Class 22: Loss = 5.7164\n",
            "  - Class 23: Loss = 3.4454\n",
            "  - Class 24: Loss = 6.2124\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6462 - loss: 1.3686 - val_accuracy: 0.5979 - val_loss: 1.5485\n",
            "Epoch 7/10\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6639 - loss: 1.3180 \n",
            "Epoch 7: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4432\n",
            "  - Class 1: Loss = 3.2843\n",
            "  - Class 2: Loss = 0.1389\n",
            "  - Class 3: Loss = 1.8984\n",
            "  - Class 4: Loss = 0.3954\n",
            "  - Class 5: Loss = 5.5700\n",
            "  - Class 6: Loss = 0.3815\n",
            "  - Class 7: Loss = 2.3620\n",
            "  - Class 8: Loss = 3.9081\n",
            "  - Class 9: Loss = 2.1849\n",
            "  - Class 10: Loss = 2.5410\n",
            "  - Class 11: Loss = 4.3265\n",
            "  - Class 12: Loss = 6.4421\n",
            "  - Class 13: Loss = 1.8086\n",
            "  - Class 14: Loss = 2.6294\n",
            "  - Class 15: Loss = 4.6946\n",
            "  - Class 16: Loss = 4.8788\n",
            "  - Class 17: Loss = 1.5707\n",
            "  - Class 18: Loss = 3.3133\n",
            "  - Class 19: Loss = 2.7753\n",
            "  - Class 20: Loss = 2.8878\n",
            "  - Class 21: Loss = 5.7732\n",
            "  - Class 22: Loss = 5.7305\n",
            "  - Class 23: Loss = 2.8559\n",
            "  - Class 24: Loss = 5.8787\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6674 - loss: 1.2948 - val_accuracy: 0.6111 - val_loss: 1.5073\n",
            "Epoch 8/10\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6642 - loss: 1.2092 \n",
            "Epoch 8: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3446\n",
            "  - Class 1: Loss = 3.2764\n",
            "  - Class 2: Loss = 0.1153\n",
            "  - Class 3: Loss = 1.7977\n",
            "  - Class 4: Loss = 0.3735\n",
            "  - Class 5: Loss = 5.5197\n",
            "  - Class 6: Loss = 0.4010\n",
            "  - Class 7: Loss = 2.3154\n",
            "  - Class 8: Loss = 3.8231\n",
            "  - Class 9: Loss = 2.2414\n",
            "  - Class 10: Loss = 2.3801\n",
            "  - Class 11: Loss = 4.4099\n",
            "  - Class 12: Loss = 6.8205\n",
            "  - Class 13: Loss = 1.7078\n",
            "  - Class 14: Loss = 2.4748\n",
            "  - Class 15: Loss = 4.8391\n",
            "  - Class 16: Loss = 4.9585\n",
            "  - Class 17: Loss = 1.5826\n",
            "  - Class 18: Loss = 3.3486\n",
            "  - Class 19: Loss = 2.6309\n",
            "  - Class 20: Loss = 2.9498\n",
            "  - Class 21: Loss = 5.8958\n",
            "  - Class 22: Loss = 5.8524\n",
            "  - Class 23: Loss = 2.7845\n",
            "  - Class 24: Loss = 6.0780\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6689 - loss: 1.2082 - val_accuracy: 0.6164 - val_loss: 1.4904\n",
            "Epoch 9/10\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 1.2182 \n",
            "Epoch 9: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3099\n",
            "  - Class 1: Loss = 3.2472\n",
            "  - Class 2: Loss = 0.1072\n",
            "  - Class 3: Loss = 1.8718\n",
            "  - Class 4: Loss = 0.3304\n",
            "  - Class 5: Loss = 5.5645\n",
            "  - Class 6: Loss = 0.3799\n",
            "  - Class 7: Loss = 2.0624\n",
            "  - Class 8: Loss = 3.7571\n",
            "  - Class 9: Loss = 2.0837\n",
            "  - Class 10: Loss = 2.2022\n",
            "  - Class 11: Loss = 4.1528\n",
            "  - Class 12: Loss = 7.0264\n",
            "  - Class 13: Loss = 1.4762\n",
            "  - Class 14: Loss = 2.1258\n",
            "  - Class 15: Loss = 4.8944\n",
            "  - Class 16: Loss = 4.9207\n",
            "  - Class 17: Loss = 1.5962\n",
            "  - Class 18: Loss = 3.4506\n",
            "  - Class 19: Loss = 2.4449\n",
            "  - Class 20: Loss = 2.8786\n",
            "  - Class 21: Loss = 5.8340\n",
            "  - Class 22: Loss = 5.8211\n",
            "  - Class 23: Loss = 2.6330\n",
            "  - Class 24: Loss = 5.9415\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6721 - loss: 1.1867 - val_accuracy: 0.6111 - val_loss: 1.4678\n",
            "Epoch 10/10\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 1.0526 \n",
            "Epoch 10: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3132\n",
            "  - Class 1: Loss = 3.0853\n",
            "  - Class 2: Loss = 0.0852\n",
            "  - Class 3: Loss = 1.7177\n",
            "  - Class 4: Loss = 0.3235\n",
            "  - Class 5: Loss = 5.5449\n",
            "  - Class 6: Loss = 0.3307\n",
            "  - Class 7: Loss = 2.2257\n",
            "  - Class 8: Loss = 3.6607\n",
            "  - Class 9: Loss = 1.9206\n",
            "  - Class 10: Loss = 1.7748\n",
            "  - Class 11: Loss = 3.7577\n",
            "  - Class 12: Loss = 6.9451\n",
            "  - Class 13: Loss = 1.3482\n",
            "  - Class 14: Loss = 2.2910\n",
            "  - Class 15: Loss = 4.7272\n",
            "  - Class 16: Loss = 4.7706\n",
            "  - Class 17: Loss = 1.4971\n",
            "  - Class 18: Loss = 3.2420\n",
            "  - Class 19: Loss = 1.8523\n",
            "  - Class 20: Loss = 2.6040\n",
            "  - Class 21: Loss = 5.7448\n",
            "  - Class 22: Loss = 5.7976\n",
            "  - Class 23: Loss = 2.2522\n",
            "  - Class 24: Loss = 5.9312\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7105 - loss: 1.0658 - val_accuracy: 0.6164 - val_loss: 1.4624\n",
            "Trial 49 Complete [00h 00m 29s]\n",
            "val_accuracy: 0.6164020895957947\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 25m 23s\n",
            "\n",
            "Search: Running Trial #50\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "128               |256               |units_layer_1\n",
            "96                |32                |units_layer_2\n",
            "32                |64                |units_layer_3\n",
            "8                 |16                |units_layer_4\n",
            "10                |10                |tuner/epochs\n",
            "4                 |4                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "2                 |2                 |tuner/round\n",
            "0041              |0034              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 5/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6644 - loss: 1.6777\n",
            "Epoch 5: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.6137\n",
            "  - Class 1: Loss = 3.4913\n",
            "  - Class 2: Loss = 1.0286\n",
            "  - Class 3: Loss = 2.9267\n",
            "  - Class 4: Loss = 1.2991\n",
            "  - Class 5: Loss = 2.5670\n",
            "  - Class 6: Loss = 1.3391\n",
            "  - Class 7: Loss = 3.0916\n",
            "  - Class 8: Loss = 3.7901\n",
            "  - Class 9: Loss = 2.9210\n",
            "  - Class 10: Loss = 3.1513\n",
            "  - Class 11: Loss = 4.3938\n",
            "  - Class 12: Loss = 4.3612\n",
            "  - Class 13: Loss = 3.0445\n",
            "  - Class 14: Loss = 3.9817\n",
            "  - Class 15: Loss = 4.7012\n",
            "  - Class 16: Loss = 4.3464\n",
            "  - Class 17: Loss = 2.1340\n",
            "  - Class 18: Loss = 3.7492\n",
            "  - Class 19: Loss = 3.5821\n",
            "  - Class 20: Loss = 3.4856\n",
            "  - Class 21: Loss = 4.8343\n",
            "  - Class 22: Loss = 4.0037\n",
            "  - Class 23: Loss = 3.5729\n",
            "  - Class 24: Loss = 4.2783\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 324ms/step - accuracy: 0.6642 - loss: 1.6777 - val_accuracy: 0.6032 - val_loss: 1.8301\n",
            "Epoch 6/10\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6718 - loss: 1.5934 \n",
            "Epoch 6: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4897\n",
            "  - Class 1: Loss = 3.5310\n",
            "  - Class 2: Loss = 0.8501\n",
            "  - Class 3: Loss = 2.9233\n",
            "  - Class 4: Loss = 1.1980\n",
            "  - Class 5: Loss = 2.6319\n",
            "  - Class 6: Loss = 1.2000\n",
            "  - Class 7: Loss = 2.9034\n",
            "  - Class 8: Loss = 3.9652\n",
            "  - Class 9: Loss = 2.9575\n",
            "  - Class 10: Loss = 3.1708\n",
            "  - Class 11: Loss = 4.4572\n",
            "  - Class 12: Loss = 4.6320\n",
            "  - Class 13: Loss = 3.0408\n",
            "  - Class 14: Loss = 4.0305\n",
            "  - Class 15: Loss = 4.7974\n",
            "  - Class 16: Loss = 4.5805\n",
            "  - Class 17: Loss = 1.9989\n",
            "  - Class 18: Loss = 3.8085\n",
            "  - Class 19: Loss = 3.7251\n",
            "  - Class 20: Loss = 3.6226\n",
            "  - Class 21: Loss = 5.0852\n",
            "  - Class 22: Loss = 4.2701\n",
            "  - Class 23: Loss = 3.6819\n",
            "  - Class 24: Loss = 4.6658\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6698 - loss: 1.5897 - val_accuracy: 0.5979 - val_loss: 1.7805\n",
            "Epoch 7/10\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6722 - loss: 1.5167 \n",
            "Epoch 7: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4892\n",
            "  - Class 1: Loss = 3.4805\n",
            "  - Class 2: Loss = 0.7236\n",
            "  - Class 3: Loss = 2.6406\n",
            "  - Class 4: Loss = 1.0569\n",
            "  - Class 5: Loss = 2.7439\n",
            "  - Class 6: Loss = 1.0787\n",
            "  - Class 7: Loss = 2.7579\n",
            "  - Class 8: Loss = 3.9145\n",
            "  - Class 9: Loss = 2.7086\n",
            "  - Class 10: Loss = 3.2093\n",
            "  - Class 11: Loss = 4.0769\n",
            "  - Class 12: Loss = 4.5264\n",
            "  - Class 13: Loss = 2.9766\n",
            "  - Class 14: Loss = 3.9558\n",
            "  - Class 15: Loss = 4.8682\n",
            "  - Class 16: Loss = 4.3039\n",
            "  - Class 17: Loss = 1.8940\n",
            "  - Class 18: Loss = 3.7552\n",
            "  - Class 19: Loss = 3.5885\n",
            "  - Class 20: Loss = 3.3506\n",
            "  - Class 21: Loss = 5.0802\n",
            "  - Class 22: Loss = 4.2880\n",
            "  - Class 23: Loss = 3.5561\n",
            "  - Class 24: Loss = 4.9136\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6711 - loss: 1.5197 - val_accuracy: 0.5952 - val_loss: 1.7486\n",
            "Epoch 8/10\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6701 - loss: 1.4925 \n",
            "Epoch 8: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3724\n",
            "  - Class 1: Loss = 3.4826\n",
            "  - Class 2: Loss = 0.6011\n",
            "  - Class 3: Loss = 2.6089\n",
            "  - Class 4: Loss = 1.0056\n",
            "  - Class 5: Loss = 2.8740\n",
            "  - Class 6: Loss = 0.8803\n",
            "  - Class 7: Loss = 2.8287\n",
            "  - Class 8: Loss = 3.9253\n",
            "  - Class 9: Loss = 2.7822\n",
            "  - Class 10: Loss = 3.1917\n",
            "  - Class 11: Loss = 4.2576\n",
            "  - Class 12: Loss = 4.6205\n",
            "  - Class 13: Loss = 2.9705\n",
            "  - Class 14: Loss = 3.8960\n",
            "  - Class 15: Loss = 4.9550\n",
            "  - Class 16: Loss = 4.4686\n",
            "  - Class 17: Loss = 1.8752\n",
            "  - Class 18: Loss = 3.7926\n",
            "  - Class 19: Loss = 3.7108\n",
            "  - Class 20: Loss = 3.5218\n",
            "  - Class 21: Loss = 5.3868\n",
            "  - Class 22: Loss = 4.4541\n",
            "  - Class 23: Loss = 3.6235\n",
            "  - Class 24: Loss = 5.1657\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6693 - loss: 1.4881 - val_accuracy: 0.5952 - val_loss: 1.7305\n",
            "Epoch 9/10\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6881 - loss: 1.3511 \n",
            "Epoch 9: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3581\n",
            "  - Class 1: Loss = 3.4604\n",
            "  - Class 2: Loss = 0.5092\n",
            "  - Class 3: Loss = 2.4117\n",
            "  - Class 4: Loss = 0.9084\n",
            "  - Class 5: Loss = 3.0316\n",
            "  - Class 6: Loss = 0.7238\n",
            "  - Class 7: Loss = 2.6975\n",
            "  - Class 8: Loss = 3.9653\n",
            "  - Class 9: Loss = 2.6239\n",
            "  - Class 10: Loss = 3.1904\n",
            "  - Class 11: Loss = 3.9650\n",
            "  - Class 12: Loss = 4.6159\n",
            "  - Class 13: Loss = 2.8817\n",
            "  - Class 14: Loss = 3.8081\n",
            "  - Class 15: Loss = 4.9651\n",
            "  - Class 16: Loss = 4.2507\n",
            "  - Class 17: Loss = 1.8005\n",
            "  - Class 18: Loss = 3.7627\n",
            "  - Class 19: Loss = 3.5673\n",
            "  - Class 20: Loss = 3.3825\n",
            "  - Class 21: Loss = 5.4031\n",
            "  - Class 22: Loss = 4.5136\n",
            "  - Class 23: Loss = 3.5652\n",
            "  - Class 24: Loss = 5.2950\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6851 - loss: 1.3669 - val_accuracy: 0.5899 - val_loss: 1.7092\n",
            "Epoch 10/10\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7152 - loss: 1.2610 \n",
            "Epoch 10: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3100\n",
            "  - Class 1: Loss = 3.3986\n",
            "  - Class 2: Loss = 0.4321\n",
            "  - Class 3: Loss = 2.3660\n",
            "  - Class 4: Loss = 0.8191\n",
            "  - Class 5: Loss = 3.1499\n",
            "  - Class 6: Loss = 0.6963\n",
            "  - Class 7: Loss = 2.6826\n",
            "  - Class 8: Loss = 3.8504\n",
            "  - Class 9: Loss = 2.5323\n",
            "  - Class 10: Loss = 3.1400\n",
            "  - Class 11: Loss = 3.8807\n",
            "  - Class 12: Loss = 4.7937\n",
            "  - Class 13: Loss = 2.8659\n",
            "  - Class 14: Loss = 3.6489\n",
            "  - Class 15: Loss = 4.9250\n",
            "  - Class 16: Loss = 4.1825\n",
            "  - Class 17: Loss = 1.8555\n",
            "  - Class 18: Loss = 3.7815\n",
            "  - Class 19: Loss = 3.5721\n",
            "  - Class 20: Loss = 3.4227\n",
            "  - Class 21: Loss = 5.4414\n",
            "  - Class 22: Loss = 4.6274\n",
            "  - Class 23: Loss = 3.5685\n",
            "  - Class 24: Loss = 5.4480\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7022 - loss: 1.2993 - val_accuracy: 0.5952 - val_loss: 1.6759\n",
            "Trial 50 Complete [00h 00m 30s]\n",
            "val_accuracy: 0.60317462682724\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 25m 52s\n",
            "\n",
            "Search: Running Trial #51\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "256               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "16                |16                |units_layer_4\n",
            "30                |10                |tuner/epochs\n",
            "10                |4                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "3                 |2                 |tuner/round\n",
            "0047              |0034              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 11/30\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7309 - loss: 1.0195\n",
            "Epoch 11: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3019\n",
            "  - Class 1: Loss = 3.2000\n",
            "  - Class 2: Loss = 0.1207\n",
            "  - Class 3: Loss = 1.5371\n",
            "  - Class 4: Loss = 0.3065\n",
            "  - Class 5: Loss = 6.2149\n",
            "  - Class 6: Loss = 0.3926\n",
            "  - Class 7: Loss = 1.9843\n",
            "  - Class 8: Loss = 3.6737\n",
            "  - Class 9: Loss = 1.6370\n",
            "  - Class 10: Loss = 2.9286\n",
            "  - Class 11: Loss = 2.7405\n",
            "  - Class 12: Loss = 5.1440\n",
            "  - Class 13: Loss = 1.5494\n",
            "  - Class 14: Loss = 1.9216\n",
            "  - Class 15: Loss = 3.7841\n",
            "  - Class 16: Loss = 4.5678\n",
            "  - Class 17: Loss = 1.1909\n",
            "  - Class 18: Loss = 3.1872\n",
            "  - Class 19: Loss = 3.6591\n",
            "  - Class 20: Loss = 2.5106\n",
            "  - Class 21: Loss = 4.6505\n",
            "  - Class 22: Loss = 4.6521\n",
            "  - Class 23: Loss = 3.3367\n",
            "  - Class 24: Loss = 6.3731\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 284ms/step - accuracy: 0.7308 - loss: 1.0203 - val_accuracy: 0.6190 - val_loss: 1.5553\n",
            "Epoch 12/30\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.9763 \n",
            "Epoch 12: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2287\n",
            "  - Class 1: Loss = 3.1526\n",
            "  - Class 2: Loss = 0.1044\n",
            "  - Class 3: Loss = 1.4728\n",
            "  - Class 4: Loss = 0.2624\n",
            "  - Class 5: Loss = 6.2667\n",
            "  - Class 6: Loss = 0.3428\n",
            "  - Class 7: Loss = 1.9016\n",
            "  - Class 8: Loss = 3.6628\n",
            "  - Class 9: Loss = 1.6201\n",
            "  - Class 10: Loss = 2.8283\n",
            "  - Class 11: Loss = 2.7367\n",
            "  - Class 12: Loss = 5.3011\n",
            "  - Class 13: Loss = 1.4702\n",
            "  - Class 14: Loss = 1.9304\n",
            "  - Class 15: Loss = 3.8467\n",
            "  - Class 16: Loss = 4.6367\n",
            "  - Class 17: Loss = 1.1930\n",
            "  - Class 18: Loss = 3.0941\n",
            "  - Class 19: Loss = 3.6209\n",
            "  - Class 20: Loss = 2.5458\n",
            "  - Class 21: Loss = 4.7794\n",
            "  - Class 22: Loss = 4.6756\n",
            "  - Class 23: Loss = 3.2766\n",
            "  - Class 24: Loss = 6.7453\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7425 - loss: 0.9887 - val_accuracy: 0.6190 - val_loss: 1.5699\n",
            "Epoch 13/30\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7434 - loss: 0.9898 \n",
            "Epoch 13: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2537\n",
            "  - Class 1: Loss = 3.0123\n",
            "  - Class 2: Loss = 0.0907\n",
            "  - Class 3: Loss = 1.2117\n",
            "  - Class 4: Loss = 0.2309\n",
            "  - Class 5: Loss = 6.2534\n",
            "  - Class 6: Loss = 0.2779\n",
            "  - Class 7: Loss = 1.8647\n",
            "  - Class 8: Loss = 3.6383\n",
            "  - Class 9: Loss = 1.4162\n",
            "  - Class 10: Loss = 2.7477\n",
            "  - Class 11: Loss = 2.6901\n",
            "  - Class 12: Loss = 5.0379\n",
            "  - Class 13: Loss = 1.3290\n",
            "  - Class 14: Loss = 1.9244\n",
            "  - Class 15: Loss = 3.7230\n",
            "  - Class 16: Loss = 4.5184\n",
            "  - Class 17: Loss = 0.9980\n",
            "  - Class 18: Loss = 3.0958\n",
            "  - Class 19: Loss = 3.3715\n",
            "  - Class 20: Loss = 2.3135\n",
            "  - Class 21: Loss = 4.5583\n",
            "  - Class 22: Loss = 4.4997\n",
            "  - Class 23: Loss = 3.0534\n",
            "  - Class 24: Loss = 6.0823\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7519 - loss: 0.9645 - val_accuracy: 0.6085 - val_loss: 1.5738\n",
            "Epoch 14/30\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7472 - loss: 0.9535 \n",
            "Epoch 14: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2191\n",
            "  - Class 1: Loss = 3.0235\n",
            "  - Class 2: Loss = 0.0835\n",
            "  - Class 3: Loss = 1.2054\n",
            "  - Class 4: Loss = 0.1695\n",
            "  - Class 5: Loss = 6.2497\n",
            "  - Class 6: Loss = 0.2620\n",
            "  - Class 7: Loss = 1.7151\n",
            "  - Class 8: Loss = 3.4870\n",
            "  - Class 9: Loss = 1.4565\n",
            "  - Class 10: Loss = 2.6878\n",
            "  - Class 11: Loss = 2.6022\n",
            "  - Class 12: Loss = 5.1254\n",
            "  - Class 13: Loss = 1.2907\n",
            "  - Class 14: Loss = 1.8081\n",
            "  - Class 15: Loss = 3.6163\n",
            "  - Class 16: Loss = 4.4535\n",
            "  - Class 17: Loss = 1.0376\n",
            "  - Class 18: Loss = 2.9918\n",
            "  - Class 19: Loss = 3.1109\n",
            "  - Class 20: Loss = 2.1873\n",
            "  - Class 21: Loss = 4.6190\n",
            "  - Class 22: Loss = 4.5931\n",
            "  - Class 23: Loss = 2.7953\n",
            "  - Class 24: Loss = 5.7903\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7517 - loss: 0.9453 - val_accuracy: 0.6111 - val_loss: 1.6078\n",
            "Epoch 15/30\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.7961 \n",
            "Epoch 15: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.1944\n",
            "  - Class 1: Loss = 3.0504\n",
            "  - Class 2: Loss = 0.0769\n",
            "  - Class 3: Loss = 1.1125\n",
            "  - Class 4: Loss = 0.1827\n",
            "  - Class 5: Loss = 6.2024\n",
            "  - Class 6: Loss = 0.2615\n",
            "  - Class 7: Loss = 1.6124\n",
            "  - Class 8: Loss = 3.4039\n",
            "  - Class 9: Loss = 1.2881\n",
            "  - Class 10: Loss = 2.5835\n",
            "  - Class 11: Loss = 2.3724\n",
            "  - Class 12: Loss = 4.8237\n",
            "  - Class 13: Loss = 1.1894\n",
            "  - Class 14: Loss = 1.6796\n",
            "  - Class 15: Loss = 3.5583\n",
            "  - Class 16: Loss = 4.4511\n",
            "  - Class 17: Loss = 0.9027\n",
            "  - Class 18: Loss = 2.9356\n",
            "  - Class 19: Loss = 2.6792\n",
            "  - Class 20: Loss = 2.1048\n",
            "  - Class 21: Loss = 4.6524\n",
            "  - Class 22: Loss = 4.5655\n",
            "  - Class 23: Loss = 2.6280\n",
            "  - Class 24: Loss = 5.7380\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7861 - loss: 0.8191 - val_accuracy: 0.6190 - val_loss: 1.5967\n",
            "Epoch 16/30\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7617 - loss: 0.8623 \n",
            "Epoch 16: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.1661\n",
            "  - Class 1: Loss = 2.9437\n",
            "  - Class 2: Loss = 0.0717\n",
            "  - Class 3: Loss = 0.9866\n",
            "  - Class 4: Loss = 0.1265\n",
            "  - Class 5: Loss = 6.0309\n",
            "  - Class 6: Loss = 0.2207\n",
            "  - Class 7: Loss = 1.5473\n",
            "  - Class 8: Loss = 3.4536\n",
            "  - Class 9: Loss = 1.2006\n",
            "  - Class 10: Loss = 2.4305\n",
            "  - Class 11: Loss = 2.4154\n",
            "  - Class 12: Loss = 4.8631\n",
            "  - Class 13: Loss = 1.1765\n",
            "  - Class 14: Loss = 1.7252\n",
            "  - Class 15: Loss = 3.4846\n",
            "  - Class 16: Loss = 4.4090\n",
            "  - Class 17: Loss = 0.8703\n",
            "  - Class 18: Loss = 2.9732\n",
            "  - Class 19: Loss = 2.5860\n",
            "  - Class 20: Loss = 2.0919\n",
            "  - Class 21: Loss = 4.3924\n",
            "  - Class 22: Loss = 4.5855\n",
            "  - Class 23: Loss = 2.5828\n",
            "  - Class 24: Loss = 5.7853\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7702 - loss: 0.8455 - val_accuracy: 0.6190 - val_loss: 1.5989\n",
            "Trial 51 Complete [00h 00m 28s]\n",
            "val_accuracy: 0.6190476417541504\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 26m 20s\n",
            "\n",
            "Search: Running Trial #52\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "256               |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "24                |16                |units_layer_4\n",
            "30                |10                |tuner/epochs\n",
            "10                |4                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "3                 |2                 |tuner/round\n",
            "0046              |0034              |tuner/trial_id\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 11/30\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7327 - loss: 1.0156\n",
            "Epoch 11: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3186\n",
            "  - Class 1: Loss = 3.3972\n",
            "  - Class 2: Loss = 0.0618\n",
            "  - Class 3: Loss = 1.2774\n",
            "  - Class 4: Loss = 0.2956\n",
            "  - Class 5: Loss = 5.0940\n",
            "  - Class 6: Loss = 0.1218\n",
            "  - Class 7: Loss = 1.8724\n",
            "  - Class 8: Loss = 3.0990\n",
            "  - Class 9: Loss = 1.6172\n",
            "  - Class 10: Loss = 2.4166\n",
            "  - Class 11: Loss = 2.9835\n",
            "  - Class 12: Loss = 5.0148\n",
            "  - Class 13: Loss = 1.2886\n",
            "  - Class 14: Loss = 1.4946\n",
            "  - Class 15: Loss = 4.7143\n",
            "  - Class 16: Loss = 4.2968\n",
            "  - Class 17: Loss = 1.1801\n",
            "  - Class 18: Loss = 2.9449\n",
            "  - Class 19: Loss = 2.7128\n",
            "  - Class 20: Loss = 2.7468\n",
            "  - Class 21: Loss = 5.1006\n",
            "  - Class 22: Loss = 5.1383\n",
            "  - Class 23: Loss = 2.9735\n",
            "  - Class 24: Loss = 7.4237\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 298ms/step - accuracy: 0.7326 - loss: 1.0159 - val_accuracy: 0.6243 - val_loss: 1.5198\n",
            "Epoch 12/30\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.9910 \n",
            "Epoch 12: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2326\n",
            "  - Class 1: Loss = 3.4657\n",
            "  - Class 2: Loss = 0.0540\n",
            "  - Class 3: Loss = 1.3055\n",
            "  - Class 4: Loss = 0.3384\n",
            "  - Class 5: Loss = 5.0164\n",
            "  - Class 6: Loss = 0.1365\n",
            "  - Class 7: Loss = 1.7290\n",
            "  - Class 8: Loss = 3.1061\n",
            "  - Class 9: Loss = 1.4716\n",
            "  - Class 10: Loss = 2.2942\n",
            "  - Class 11: Loss = 2.9584\n",
            "  - Class 12: Loss = 4.9331\n",
            "  - Class 13: Loss = 1.2361\n",
            "  - Class 14: Loss = 1.5100\n",
            "  - Class 15: Loss = 4.6113\n",
            "  - Class 16: Loss = 4.3164\n",
            "  - Class 17: Loss = 1.1433\n",
            "  - Class 18: Loss = 2.8287\n",
            "  - Class 19: Loss = 2.2562\n",
            "  - Class 20: Loss = 2.6164\n",
            "  - Class 21: Loss = 4.9965\n",
            "  - Class 22: Loss = 5.2137\n",
            "  - Class 23: Loss = 2.8225\n",
            "  - Class 24: Loss = 7.3771\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7320 - loss: 0.9711 - val_accuracy: 0.6296 - val_loss: 1.5286\n",
            "Epoch 13/30\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.8327 \n",
            "Epoch 13: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2984\n",
            "  - Class 1: Loss = 3.2440\n",
            "  - Class 2: Loss = 0.0547\n",
            "  - Class 3: Loss = 1.1368\n",
            "  - Class 4: Loss = 0.2918\n",
            "  - Class 5: Loss = 5.1707\n",
            "  - Class 6: Loss = 0.0874\n",
            "  - Class 7: Loss = 1.5563\n",
            "  - Class 8: Loss = 2.8291\n",
            "  - Class 9: Loss = 1.2530\n",
            "  - Class 10: Loss = 2.1249\n",
            "  - Class 11: Loss = 2.7387\n",
            "  - Class 12: Loss = 4.5837\n",
            "  - Class 13: Loss = 1.1579\n",
            "  - Class 14: Loss = 1.2201\n",
            "  - Class 15: Loss = 4.3604\n",
            "  - Class 16: Loss = 4.1622\n",
            "  - Class 17: Loss = 0.8242\n",
            "  - Class 18: Loss = 2.5257\n",
            "  - Class 19: Loss = 1.7454\n",
            "  - Class 20: Loss = 2.3900\n",
            "  - Class 21: Loss = 4.9733\n",
            "  - Class 22: Loss = 4.9212\n",
            "  - Class 23: Loss = 2.6544\n",
            "  - Class 24: Loss = 6.8769\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7802 - loss: 0.8458 - val_accuracy: 0.6085 - val_loss: 1.5419\n",
            "Epoch 14/30\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.8646 \n",
            "Epoch 14: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2583\n",
            "  - Class 1: Loss = 3.2059\n",
            "  - Class 2: Loss = 0.0492\n",
            "  - Class 3: Loss = 0.9993\n",
            "  - Class 4: Loss = 0.2395\n",
            "  - Class 5: Loss = 5.1360\n",
            "  - Class 6: Loss = 0.0971\n",
            "  - Class 7: Loss = 1.4285\n",
            "  - Class 8: Loss = 2.5949\n",
            "  - Class 9: Loss = 1.2054\n",
            "  - Class 10: Loss = 1.9437\n",
            "  - Class 11: Loss = 2.5474\n",
            "  - Class 12: Loss = 4.5116\n",
            "  - Class 13: Loss = 1.0670\n",
            "  - Class 14: Loss = 1.0920\n",
            "  - Class 15: Loss = 4.2478\n",
            "  - Class 16: Loss = 3.9424\n",
            "  - Class 17: Loss = 0.7957\n",
            "  - Class 18: Loss = 2.5147\n",
            "  - Class 19: Loss = 1.6037\n",
            "  - Class 20: Loss = 2.2270\n",
            "  - Class 21: Loss = 4.8892\n",
            "  - Class 22: Loss = 5.0387\n",
            "  - Class 23: Loss = 2.4604\n",
            "  - Class 24: Loss = 6.6330\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7765 - loss: 0.8474 - val_accuracy: 0.6085 - val_loss: 1.5453\n",
            "Epoch 15/30\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8116 - loss: 0.7687 \n",
            "Epoch 15: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2256\n",
            "  - Class 1: Loss = 3.1025\n",
            "  - Class 2: Loss = 0.0500\n",
            "  - Class 3: Loss = 0.9361\n",
            "  - Class 4: Loss = 0.2534\n",
            "  - Class 5: Loss = 5.1362\n",
            "  - Class 6: Loss = 0.0652\n",
            "  - Class 7: Loss = 1.4217\n",
            "  - Class 8: Loss = 2.2169\n",
            "  - Class 9: Loss = 1.1236\n",
            "  - Class 10: Loss = 1.8348\n",
            "  - Class 11: Loss = 2.4641\n",
            "  - Class 12: Loss = 4.2857\n",
            "  - Class 13: Loss = 1.0611\n",
            "  - Class 14: Loss = 0.9094\n",
            "  - Class 15: Loss = 4.1002\n",
            "  - Class 16: Loss = 3.8763\n",
            "  - Class 17: Loss = 0.7075\n",
            "  - Class 18: Loss = 2.4439\n",
            "  - Class 19: Loss = 1.3318\n",
            "  - Class 20: Loss = 2.0050\n",
            "  - Class 21: Loss = 4.8761\n",
            "  - Class 22: Loss = 4.9110\n",
            "  - Class 23: Loss = 2.1704\n",
            "  - Class 24: Loss = 6.4127\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8022 - loss: 0.7785 - val_accuracy: 0.6085 - val_loss: 1.5643\n",
            "Epoch 16/30\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.7451 \n",
            "Epoch 16: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2312\n",
            "  - Class 1: Loss = 3.0120\n",
            "  - Class 2: Loss = 0.0523\n",
            "  - Class 3: Loss = 0.9476\n",
            "  - Class 4: Loss = 0.2050\n",
            "  - Class 5: Loss = 5.0861\n",
            "  - Class 6: Loss = 0.0659\n",
            "  - Class 7: Loss = 1.3199\n",
            "  - Class 8: Loss = 1.9731\n",
            "  - Class 9: Loss = 1.1192\n",
            "  - Class 10: Loss = 1.6309\n",
            "  - Class 11: Loss = 2.3163\n",
            "  - Class 12: Loss = 3.9135\n",
            "  - Class 13: Loss = 1.0006\n",
            "  - Class 14: Loss = 0.8674\n",
            "  - Class 15: Loss = 3.9888\n",
            "  - Class 16: Loss = 3.7119\n",
            "  - Class 17: Loss = 0.5686\n",
            "  - Class 18: Loss = 2.2187\n",
            "  - Class 19: Loss = 1.2582\n",
            "  - Class 20: Loss = 1.9960\n",
            "  - Class 21: Loss = 4.6937\n",
            "  - Class 22: Loss = 4.9750\n",
            "  - Class 23: Loss = 2.0853\n",
            "  - Class 24: Loss = 6.0118\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8063 - loss: 0.7375 - val_accuracy: 0.6005 - val_loss: 1.5902\n",
            "Trial 52 Complete [00h 00m 28s]\n",
            "val_accuracy: 0.6296296119689941\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 26m 48s\n",
            "\n",
            "Search: Running Trial #53\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0001            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "128               |256               |units_layer_1\n",
            "128               |32                |units_layer_2\n",
            "32                |64                |units_layer_3\n",
            "24                |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.0809 - loss: 3.1157\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.3461\n",
            "  - Class 1: Loss = 3.5339\n",
            "  - Class 2: Loss = 2.7993\n",
            "  - Class 3: Loss = 3.2971\n",
            "  - Class 4: Loss = 2.8493\n",
            "  - Class 5: Loss = 4.1757\n",
            "  - Class 6: Loss = 2.6657\n",
            "  - Class 7: Loss = 2.6902\n",
            "  - Class 8: Loss = 3.3984\n",
            "  - Class 9: Loss = 3.2017\n",
            "  - Class 10: Loss = 3.5224\n",
            "  - Class 11: Loss = 3.2081\n",
            "  - Class 12: Loss = 3.2739\n",
            "  - Class 13: Loss = 3.5402\n",
            "  - Class 14: Loss = 3.4460\n",
            "  - Class 15: Loss = 3.2565\n",
            "  - Class 16: Loss = 3.5845\n",
            "  - Class 17: Loss = 3.2684\n",
            "  - Class 18: Loss = 2.8465\n",
            "  - Class 19: Loss = 3.1525\n",
            "  - Class 20: Loss = 3.2650\n",
            "  - Class 21: Loss = 3.5730\n",
            "  - Class 22: Loss = 3.3413\n",
            "  - Class 23: Loss = 3.1901\n",
            "  - Class 24: Loss = 4.4866\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 618ms/step - accuracy: 0.0821 - loss: 3.1133 - val_accuracy: 0.2963 - val_loss: 2.7991\n",
            "Epoch 2/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3869 - loss: 2.6519 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.6736\n",
            "  - Class 1: Loss = 3.5157\n",
            "  - Class 2: Loss = 2.3217\n",
            "  - Class 3: Loss = 3.3797\n",
            "  - Class 4: Loss = 2.7413\n",
            "  - Class 5: Loss = 4.4558\n",
            "  - Class 6: Loss = 2.7636\n",
            "  - Class 7: Loss = 2.7495\n",
            "  - Class 8: Loss = 3.6796\n",
            "  - Class 9: Loss = 3.1187\n",
            "  - Class 10: Loss = 3.6498\n",
            "  - Class 11: Loss = 3.5110\n",
            "  - Class 12: Loss = 3.3412\n",
            "  - Class 13: Loss = 3.6115\n",
            "  - Class 14: Loss = 3.6758\n",
            "  - Class 15: Loss = 3.3991\n",
            "  - Class 16: Loss = 3.7540\n",
            "  - Class 17: Loss = 3.2802\n",
            "  - Class 18: Loss = 2.7832\n",
            "  - Class 19: Loss = 3.3119\n",
            "  - Class 20: Loss = 3.4347\n",
            "  - Class 21: Loss = 3.7608\n",
            "  - Class 22: Loss = 3.5469\n",
            "  - Class 23: Loss = 3.6008\n",
            "  - Class 24: Loss = 4.8753\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4125 - loss: 2.6177 - val_accuracy: 0.5132 - val_loss: 2.4771\n",
            "Epoch 3/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5746 - loss: 2.3059 \n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.2561\n",
            "  - Class 1: Loss = 3.5567\n",
            "  - Class 2: Loss = 2.0211\n",
            "  - Class 3: Loss = 3.4468\n",
            "  - Class 4: Loss = 2.7461\n",
            "  - Class 5: Loss = 4.6455\n",
            "  - Class 6: Loss = 2.8819\n",
            "  - Class 7: Loss = 2.8935\n",
            "  - Class 8: Loss = 3.8946\n",
            "  - Class 9: Loss = 3.1103\n",
            "  - Class 10: Loss = 3.7609\n",
            "  - Class 11: Loss = 3.7889\n",
            "  - Class 12: Loss = 3.4742\n",
            "  - Class 13: Loss = 3.6152\n",
            "  - Class 14: Loss = 3.8537\n",
            "  - Class 15: Loss = 3.5392\n",
            "  - Class 16: Loss = 3.9244\n",
            "  - Class 17: Loss = 3.2900\n",
            "  - Class 18: Loss = 2.8416\n",
            "  - Class 19: Loss = 3.4884\n",
            "  - Class 20: Loss = 3.6292\n",
            "  - Class 21: Loss = 3.9164\n",
            "  - Class 22: Loss = 3.7896\n",
            "  - Class 23: Loss = 3.8859\n",
            "  - Class 24: Loss = 5.1201\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.5653 - loss: 2.3059 - val_accuracy: 0.5317 - val_loss: 2.2936\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5541 - loss: 2.1659 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.0065\n",
            "  - Class 1: Loss = 3.6162\n",
            "  - Class 2: Loss = 1.8079\n",
            "  - Class 3: Loss = 3.5031\n",
            "  - Class 4: Loss = 2.7415\n",
            "  - Class 5: Loss = 4.7801\n",
            "  - Class 6: Loss = 2.9536\n",
            "  - Class 7: Loss = 3.0207\n",
            "  - Class 8: Loss = 4.0617\n",
            "  - Class 9: Loss = 3.1502\n",
            "  - Class 10: Loss = 3.8452\n",
            "  - Class 11: Loss = 4.0060\n",
            "  - Class 12: Loss = 3.6059\n",
            "  - Class 13: Loss = 3.5744\n",
            "  - Class 14: Loss = 3.9354\n",
            "  - Class 15: Loss = 3.6708\n",
            "  - Class 16: Loss = 4.0785\n",
            "  - Class 17: Loss = 3.2714\n",
            "  - Class 18: Loss = 2.9259\n",
            "  - Class 19: Loss = 3.6328\n",
            "  - Class 20: Loss = 3.7981\n",
            "  - Class 21: Loss = 4.0519\n",
            "  - Class 22: Loss = 3.9842\n",
            "  - Class 23: Loss = 4.0990\n",
            "  - Class 24: Loss = 5.2935\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5599 - loss: 2.1477 - val_accuracy: 0.5423 - val_loss: 2.1900\n",
            "Trial 53 Complete [00h 00m 41s]\n",
            "val_accuracy: 0.5423280596733093\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 27m 29s\n",
            "\n",
            "Search: Running Trial #54\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "160               |256               |units_layer_1\n",
            "128               |32                |units_layer_2\n",
            "16                |64                |units_layer_3\n",
            "16                |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "2025-08-27 10:06:12.339324: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_392', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:12.424439: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:12.740012: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 192 bytes spill stores, 192 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:12.783305: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_392', 24 bytes spill stores, 24 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:13.065506: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 100 bytes spill stores, 100 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:13.098724: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_392', 28 bytes spill stores, 28 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:13.379563: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 1020 bytes spill stores, 1020 bytes spill loads\n",
            "\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0317 - loss: 1242965.5000     2025-08-27 10:06:16.442434: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_203', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.0838 - loss: 937266.31252025-08-27 10:06:19.763787: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:19.809321: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 100 bytes spill stores, 100 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:20.044576: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 204 bytes spill stores, 204 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:20.200838: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 1024 bytes spill stores, 1024 bytes spill loads\n",
            "\n",
            "\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 12791.3418\n",
            "2025-08-27 10:06:23.082488: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "  - Class 1: Loss = 27584.6211\n",
            "2025-08-27 10:06:25.040702: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "  - Class 2: Loss = 3.2155\n",
            "2025-08-27 10:06:27.059614: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 808 bytes spill stores, 808 bytes spill loads\n",
            "\n",
            "  - Class 3: Loss = 4862.1138\n",
            "2025-08-27 10:06:28.974297: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "  - Class 4: Loss = 3.1590\n",
            "  - Class 5: Loss = 57985.5312\n",
            "  - Class 6: Loss = 2001.5481\n",
            "2025-08-27 10:06:31.842767: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "  - Class 7: Loss = 3.1904\n",
            "2025-08-27 10:06:33.970809: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "  - Class 8: Loss = 3.2450\n",
            "2025-08-27 10:06:35.675600: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:35.834311: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 204 bytes spill stores, 204 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:35.931544: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 100 bytes spill stores, 100 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:36.115958: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 1024 bytes spill stores, 1024 bytes spill loads\n",
            "\n",
            "  - Class 9: Loss = 708.9039\n",
            "2025-08-27 10:06:38.186585: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "  - Class 10: Loss = 3.2281\n",
            "2025-08-27 10:06:40.128134: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "  - Class 11: Loss = 3.2056\n",
            "2025-08-27 10:06:42.132352: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "  - Class 12: Loss = 3.2725\n",
            "  - Class 13: Loss = 26687.6895\n",
            "  - Class 14: Loss = 3.1995\n",
            "  - Class 15: Loss = 3.2225\n",
            "  - Class 16: Loss = 3.2762\n",
            "  - Class 17: Loss = 8549.6650\n",
            "  - Class 18: Loss = 24628.3652\n",
            "2025-08-27 10:06:44.410474: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 100 bytes spill stores, 100 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:44.426024: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:44.670721: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 204 bytes spill stores, 204 bytes spill loads\n",
            "\n",
            "2025-08-27 10:06:44.766884: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 1024 bytes spill stores, 1024 bytes spill loads\n",
            "\n",
            "  - Class 19: Loss = 36111.6484\n",
            "  - Class 20: Loss = 3.2011\n",
            "  - Class 21: Loss = 3.2518\n",
            "2025-08-27 10:06:46.990018: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "  - Class 22: Loss = 3.2687\n",
            "  - Class 23: Loss = 2438.7310\n",
            "  - Class 24: Loss = 3.2377\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 704ms/step - accuracy: 0.0864 - loss: 927040.0000 - val_accuracy: 0.4656 - val_loss: 6034.3511\n",
            "Epoch 2/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5341 - loss: 4112.7456  \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 3.0162\n",
            "  - Class 1: Loss = 14.8528\n",
            "  - Class 2: Loss = 3.2011\n",
            "  - Class 3: Loss = 3.1424\n",
            "  - Class 4: Loss = 3.0886\n",
            "  - Class 5: Loss = 3.2768\n",
            "  - Class 6: Loss = 2.8843\n",
            "  - Class 7: Loss = 3.1740\n",
            "  - Class 8: Loss = 3.2308\n",
            "  - Class 9: Loss = 3.2504\n",
            "  - Class 10: Loss = 3.2029\n",
            "  - Class 11: Loss = 3.2252\n",
            "  - Class 12: Loss = 3.3905\n",
            "  - Class 13: Loss = 12.5612\n",
            "  - Class 14: Loss = 3.1897\n",
            "  - Class 15: Loss = 3.2506\n",
            "  - Class 16: Loss = 3.3883\n",
            "  - Class 17: Loss = 3.1378\n",
            "  - Class 18: Loss = 3.2241\n",
            "  - Class 19: Loss = 3.2568\n",
            "  - Class 20: Loss = 3.2130\n",
            "  - Class 21: Loss = 3.2607\n",
            "  - Class 22: Loss = 3.3491\n",
            "  - Class 23: Loss = 3.3180\n",
            "  - Class 24: Loss = 3.2585\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5330 - loss: 3271.5054 - val_accuracy: 0.5079 - val_loss: 12.5819\n",
            "Epoch 3/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5593 - loss: 3.0715 \n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.8989\n",
            "  - Class 1: Loss = 3.2603\n",
            "  - Class 2: Loss = 3.1872\n",
            "  - Class 3: Loss = 3.0855\n",
            "  - Class 4: Loss = 3.0196\n",
            "  - Class 5: Loss = 3.3402\n",
            "  - Class 6: Loss = 2.8446\n",
            "  - Class 7: Loss = 3.1599\n",
            "  - Class 8: Loss = 3.2191\n",
            "  - Class 9: Loss = 3.2370\n",
            "  - Class 10: Loss = 3.1826\n",
            "  - Class 11: Loss = 3.2378\n",
            "  - Class 12: Loss = 3.5256\n",
            "  - Class 13: Loss = 3.1021\n",
            "  - Class 14: Loss = 3.1876\n",
            "  - Class 15: Loss = 3.3087\n",
            "  - Class 16: Loss = 3.4942\n",
            "  - Class 17: Loss = 3.0902\n",
            "  - Class 18: Loss = 3.2523\n",
            "  - Class 19: Loss = 3.2683\n",
            "  - Class 20: Loss = 3.2145\n",
            "  - Class 21: Loss = 3.2625\n",
            "  - Class 22: Loss = 3.4283\n",
            "  - Class 23: Loss = 3.3633\n",
            "  - Class 24: Loss = 3.2995\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5506 - loss: 3.1120 - val_accuracy: 0.5079 - val_loss: 12.6223\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5514 - loss: 3.0001 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.7821\n",
            "  - Class 1: Loss = 3.2723\n",
            "  - Class 2: Loss = 3.1713\n",
            "  - Class 3: Loss = 3.0309\n",
            "  - Class 4: Loss = 2.9536\n",
            "  - Class 5: Loss = 3.4201\n",
            "  - Class 6: Loss = 2.8156\n",
            "  - Class 7: Loss = 3.1444\n",
            "  - Class 8: Loss = 3.2157\n",
            "  - Class 9: Loss = 3.2182\n",
            "  - Class 10: Loss = 3.1637\n",
            "  - Class 11: Loss = 3.2456\n",
            "  - Class 12: Loss = 3.6769\n",
            "  - Class 13: Loss = 3.0660\n",
            "  - Class 14: Loss = 3.1915\n",
            "  - Class 15: Loss = 3.3856\n",
            "  - Class 16: Loss = 3.5962\n",
            "  - Class 17: Loss = 3.0413\n",
            "  - Class 18: Loss = 3.2856\n",
            "  - Class 19: Loss = 3.2793\n",
            "  - Class 20: Loss = 3.2186\n",
            "  - Class 21: Loss = 3.2632\n",
            "  - Class 22: Loss = 3.5067\n",
            "  - Class 23: Loss = 3.4021\n",
            "  - Class 24: Loss = 3.3555\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5444 - loss: 2.9955 - val_accuracy: 0.5079 - val_loss: 12.5376\n",
            "Trial 54 Complete [00h 00m 45s]\n",
            "val_accuracy: 0.5079365372657776\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 28m 15s\n",
            "\n",
            "Search: Running Trial #55\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.005             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "64                |256               |units_layer_1\n",
            "64                |32                |units_layer_2\n",
            "16                |64                |units_layer_3\n",
            "32                |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4341 - loss: 2.3312\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4078\n",
            "  - Class 1: Loss = 3.9537\n",
            "  - Class 2: Loss = 0.2817\n",
            "  - Class 3: Loss = 3.1805\n",
            "  - Class 4: Loss = 1.8793\n",
            "  - Class 5: Loss = 4.8788\n",
            "  - Class 6: Loss = 2.1533\n",
            "  - Class 7: Loss = 3.2637\n",
            "  - Class 8: Loss = 5.0321\n",
            "  - Class 9: Loss = 3.4730\n",
            "  - Class 10: Loss = 3.9597\n",
            "  - Class 11: Loss = 4.7908\n",
            "  - Class 12: Loss = 6.4914\n",
            "  - Class 13: Loss = 2.9390\n",
            "  - Class 14: Loss = 3.7952\n",
            "  - Class 15: Loss = 4.9539\n",
            "  - Class 16: Loss = 5.5046\n",
            "  - Class 17: Loss = 2.3322\n",
            "  - Class 18: Loss = 3.7417\n",
            "  - Class 19: Loss = 4.4224\n",
            "  - Class 20: Loss = 3.9088\n",
            "  - Class 21: Loss = 6.6522\n",
            "  - Class 22: Loss = 5.6018\n",
            "  - Class 23: Loss = 4.2933\n",
            "  - Class 24: Loss = 6.9707\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 455ms/step - accuracy: 0.4361 - loss: 2.3241 - val_accuracy: 0.5767 - val_loss: 1.7999\n",
            "Epoch 2/4\n",
            "\u001b[1m26/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6209 - loss: 1.5856 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3557\n",
            "  - Class 1: Loss = 3.8304\n",
            "  - Class 2: Loss = 0.0921\n",
            "  - Class 3: Loss = 2.6885\n",
            "  - Class 4: Loss = 1.1012\n",
            "  - Class 5: Loss = 4.9214\n",
            "  - Class 6: Loss = 1.0506\n",
            "  - Class 7: Loss = 3.2236\n",
            "  - Class 8: Loss = 4.9914\n",
            "  - Class 9: Loss = 3.3404\n",
            "  - Class 10: Loss = 3.3476\n",
            "  - Class 11: Loss = 4.5887\n",
            "  - Class 12: Loss = 7.1856\n",
            "  - Class 13: Loss = 2.2447\n",
            "  - Class 14: Loss = 3.5508\n",
            "  - Class 15: Loss = 5.1466\n",
            "  - Class 16: Loss = 5.6248\n",
            "  - Class 17: Loss = 2.2082\n",
            "  - Class 18: Loss = 3.9576\n",
            "  - Class 19: Loss = 3.9817\n",
            "  - Class 20: Loss = 3.1674\n",
            "  - Class 21: Loss = 6.7619\n",
            "  - Class 22: Loss = 6.1722\n",
            "  - Class 23: Loss = 3.9836\n",
            "  - Class 24: Loss = 7.1312\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6222 - loss: 1.5900 - val_accuracy: 0.5820 - val_loss: 1.6827\n",
            "Epoch 3/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6645 - loss: 1.3365 \n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5113\n",
            "  - Class 1: Loss = 3.1990\n",
            "  - Class 2: Loss = 0.0540\n",
            "  - Class 3: Loss = 1.7456\n",
            "  - Class 4: Loss = 0.5377\n",
            "  - Class 5: Loss = 5.2520\n",
            "  - Class 6: Loss = 0.4641\n",
            "  - Class 7: Loss = 2.0263\n",
            "  - Class 8: Loss = 4.1317\n",
            "  - Class 9: Loss = 2.9182\n",
            "  - Class 10: Loss = 2.7226\n",
            "  - Class 11: Loss = 3.4010\n",
            "  - Class 12: Loss = 6.4822\n",
            "  - Class 13: Loss = 1.8532\n",
            "  - Class 14: Loss = 2.5555\n",
            "  - Class 15: Loss = 4.7579\n",
            "  - Class 16: Loss = 4.9689\n",
            "  - Class 17: Loss = 1.7620\n",
            "  - Class 18: Loss = 3.6506\n",
            "  - Class 19: Loss = 3.1086\n",
            "  - Class 20: Loss = 2.8795\n",
            "  - Class 21: Loss = 6.0599\n",
            "  - Class 22: Loss = 5.6585\n",
            "  - Class 23: Loss = 3.6580\n",
            "  - Class 24: Loss = 6.0273\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6562 - loss: 1.3673 - val_accuracy: 0.5926 - val_loss: 1.5313\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6501 - loss: 1.2917 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3890\n",
            "  - Class 1: Loss = 3.1337\n",
            "  - Class 2: Loss = 0.0377\n",
            "  - Class 3: Loss = 1.6230\n",
            "  - Class 4: Loss = 0.6521\n",
            "  - Class 5: Loss = 5.1451\n",
            "  - Class 6: Loss = 0.1835\n",
            "  - Class 7: Loss = 2.3058\n",
            "  - Class 8: Loss = 4.5932\n",
            "  - Class 9: Loss = 2.3381\n",
            "  - Class 10: Loss = 2.1856\n",
            "  - Class 11: Loss = 3.2022\n",
            "  - Class 12: Loss = 6.1802\n",
            "  - Class 13: Loss = 2.0349\n",
            "  - Class 14: Loss = 2.5445\n",
            "  - Class 15: Loss = 4.7268\n",
            "  - Class 16: Loss = 4.5328\n",
            "  - Class 17: Loss = 1.5449\n",
            "  - Class 18: Loss = 3.5574\n",
            "  - Class 19: Loss = 2.2189\n",
            "  - Class 20: Loss = 2.9259\n",
            "  - Class 21: Loss = 6.2610\n",
            "  - Class 22: Loss = 5.7224\n",
            "  - Class 23: Loss = 2.7529\n",
            "  - Class 24: Loss = 6.8169\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6539 - loss: 1.2922 - val_accuracy: 0.6111 - val_loss: 1.4453\n",
            "Trial 55 Complete [00h 00m 33s]\n",
            "val_accuracy: 0.6111111044883728\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 28m 47s\n",
            "\n",
            "Search: Running Trial #56\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0005            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "96                |256               |units_layer_1\n",
            "64                |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "8                 |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.0577 - loss: 3.1957\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.4921\n",
            "  - Class 1: Loss = 3.2557\n",
            "  - Class 2: Loss = 2.0977\n",
            "  - Class 3: Loss = 2.7878\n",
            "  - Class 4: Loss = 3.3559\n",
            "  - Class 5: Loss = 3.7845\n",
            "  - Class 6: Loss = 3.0233\n",
            "  - Class 7: Loss = 2.3340\n",
            "  - Class 8: Loss = 3.1681\n",
            "  - Class 9: Loss = 3.0864\n",
            "  - Class 10: Loss = 3.1311\n",
            "  - Class 11: Loss = 3.9643\n",
            "  - Class 12: Loss = 3.1254\n",
            "  - Class 13: Loss = 3.2921\n",
            "  - Class 14: Loss = 3.2344\n",
            "  - Class 15: Loss = 3.6218\n",
            "  - Class 16: Loss = 3.4581\n",
            "  - Class 17: Loss = 3.3868\n",
            "  - Class 18: Loss = 3.5078\n",
            "  - Class 19: Loss = 3.4379\n",
            "  - Class 20: Loss = 3.3312\n",
            "  - Class 21: Loss = 3.1679\n",
            "  - Class 22: Loss = 3.3785\n",
            "  - Class 23: Loss = 3.3904\n",
            "  - Class 24: Loss = 3.8102\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 483ms/step - accuracy: 0.0591 - loss: 3.1930 - val_accuracy: 0.3042 - val_loss: 2.8210\n",
            "Epoch 2/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4080 - loss: 2.7395 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.8577\n",
            "  - Class 1: Loss = 3.2686\n",
            "  - Class 2: Loss = 1.9887\n",
            "  - Class 3: Loss = 2.6601\n",
            "  - Class 4: Loss = 3.3593\n",
            "  - Class 5: Loss = 3.8876\n",
            "  - Class 6: Loss = 3.2406\n",
            "  - Class 7: Loss = 2.2362\n",
            "  - Class 8: Loss = 3.3310\n",
            "  - Class 9: Loss = 2.9059\n",
            "  - Class 10: Loss = 3.1071\n",
            "  - Class 11: Loss = 4.1733\n",
            "  - Class 12: Loss = 3.5364\n",
            "  - Class 13: Loss = 3.3561\n",
            "  - Class 14: Loss = 3.2328\n",
            "  - Class 15: Loss = 3.9647\n",
            "  - Class 16: Loss = 3.6261\n",
            "  - Class 17: Loss = 3.3046\n",
            "  - Class 18: Loss = 3.6449\n",
            "  - Class 19: Loss = 3.7215\n",
            "  - Class 20: Loss = 3.4345\n",
            "  - Class 21: Loss = 3.3097\n",
            "  - Class 22: Loss = 3.7366\n",
            "  - Class 23: Loss = 3.6494\n",
            "  - Class 24: Loss = 4.2291\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4416 - loss: 2.7005 - val_accuracy: 0.5503 - val_loss: 2.5052\n",
            "Epoch 3/4\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5765 - loss: 2.4364 \n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.4978\n",
            "  - Class 1: Loss = 3.2301\n",
            "  - Class 2: Loss = 2.0103\n",
            "  - Class 3: Loss = 2.6921\n",
            "  - Class 4: Loss = 3.2277\n",
            "  - Class 5: Loss = 4.0792\n",
            "  - Class 6: Loss = 3.2335\n",
            "  - Class 7: Loss = 2.3581\n",
            "  - Class 8: Loss = 3.5203\n",
            "  - Class 9: Loss = 2.8184\n",
            "  - Class 10: Loss = 3.1000\n",
            "  - Class 11: Loss = 4.1619\n",
            "  - Class 12: Loss = 3.8176\n",
            "  - Class 13: Loss = 3.3906\n",
            "  - Class 14: Loss = 3.2996\n",
            "  - Class 15: Loss = 4.0297\n",
            "  - Class 16: Loss = 3.7827\n",
            "  - Class 17: Loss = 3.2062\n",
            "  - Class 18: Loss = 3.7271\n",
            "  - Class 19: Loss = 3.8151\n",
            "  - Class 20: Loss = 3.4819\n",
            "  - Class 21: Loss = 3.5486\n",
            "  - Class 22: Loss = 3.9685\n",
            "  - Class 23: Loss = 3.7806\n",
            "  - Class 24: Loss = 4.4621\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5743 - loss: 2.4131 - val_accuracy: 0.5344 - val_loss: 2.3260\n",
            "Epoch 4/4\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5344 - loss: 2.2853 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.2566\n",
            "  - Class 1: Loss = 3.2477\n",
            "  - Class 2: Loss = 2.0580\n",
            "  - Class 3: Loss = 2.7710\n",
            "  - Class 4: Loss = 3.0232\n",
            "  - Class 5: Loss = 4.4041\n",
            "  - Class 6: Loss = 3.0116\n",
            "  - Class 7: Loss = 2.5084\n",
            "  - Class 8: Loss = 3.6712\n",
            "  - Class 9: Loss = 2.7988\n",
            "  - Class 10: Loss = 3.0649\n",
            "  - Class 11: Loss = 4.1858\n",
            "  - Class 12: Loss = 4.0279\n",
            "  - Class 13: Loss = 3.4014\n",
            "  - Class 14: Loss = 3.3812\n",
            "  - Class 15: Loss = 4.0837\n",
            "  - Class 16: Loss = 3.9213\n",
            "  - Class 17: Loss = 3.0896\n",
            "  - Class 18: Loss = 3.7608\n",
            "  - Class 19: Loss = 3.8960\n",
            "  - Class 20: Loss = 3.5052\n",
            "  - Class 21: Loss = 3.7611\n",
            "  - Class 22: Loss = 4.1581\n",
            "  - Class 23: Loss = 3.8969\n",
            "  - Class 24: Loss = 4.6179\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5410 - loss: 2.2639 - val_accuracy: 0.5344 - val_loss: 2.2058\n",
            "Trial 56 Complete [00h 00m 34s]\n",
            "val_accuracy: 0.5502645373344421\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 29m 21s\n",
            "\n",
            "Search: Running Trial #57\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.005             |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "64                |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "16                |64                |units_layer_3\n",
            "24                |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3208 - loss: 968043.3750\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 57.0537\n",
            "  - Class 1: Loss = 35781.2266\n",
            "  - Class 2: Loss = 3.1151\n",
            "  - Class 3: Loss = 914.6922\n",
            "  - Class 4: Loss = 3.0385\n",
            "  - Class 5: Loss = 3.5269\n",
            "  - Class 6: Loss = 3.1710\n",
            "  - Class 7: Loss = 3.2118\n",
            "  - Class 8: Loss = 988.8474\n",
            "  - Class 9: Loss = 3.0097\n",
            "  - Class 10: Loss = 3.3772\n",
            "  - Class 11: Loss = 13444.8955\n",
            "  - Class 12: Loss = 3.3373\n",
            "  - Class 13: Loss = 19511.7246\n",
            "  - Class 14: Loss = 3.1439\n",
            "  - Class 15: Loss = 3.2632\n",
            "  - Class 16: Loss = 3.3389\n",
            "  - Class 17: Loss = 998.9673\n",
            "  - Class 18: Loss = 3.1890\n",
            "  - Class 19: Loss = 3.2453\n",
            "  - Class 20: Loss = 3.2278\n",
            "  - Class 21: Loss = 3.4082\n",
            "  - Class 22: Loss = 3.2663\n",
            "  - Class 23: Loss = 3.3024\n",
            "  - Class 24: Loss = 3.4723\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 308ms/step - accuracy: 0.3194 - loss: 955823.4375 - val_accuracy: 0.0794 - val_loss: 1944.8728\n",
            "Epoch 2/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4647 - loss: 1015.4391\n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 13.0036\n",
            "  - Class 1: Loss = 3.2224\n",
            "  - Class 2: Loss = 3.2273\n",
            "  - Class 3: Loss = 3.0286\n",
            "  - Class 4: Loss = 2.8644\n",
            "  - Class 5: Loss = 4.2881\n",
            "  - Class 6: Loss = 3.1244\n",
            "  - Class 7: Loss = 3.3016\n",
            "  - Class 8: Loss = 3.4907\n",
            "  - Class 9: Loss = 2.7984\n",
            "  - Class 10: Loss = 3.6583\n",
            "  - Class 11: Loss = 3.4045\n",
            "  - Class 12: Loss = 3.7168\n",
            "  - Class 13: Loss = 8.3749\n",
            "  - Class 14: Loss = 3.1485\n",
            "  - Class 15: Loss = 3.4056\n",
            "  - Class 16: Loss = 3.5234\n",
            "  - Class 17: Loss = 10.6393\n",
            "  - Class 18: Loss = 3.2836\n",
            "  - Class 19: Loss = 3.2682\n",
            "  - Class 20: Loss = 3.1787\n",
            "  - Class 21: Loss = 3.5622\n",
            "  - Class 22: Loss = 3.3740\n",
            "  - Class 23: Loss = 3.4329\n",
            "  - Class 24: Loss = 3.9976\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4835 - loss: 1039.2604 - val_accuracy: 0.5053 - val_loss: 11.8699\n",
            "Epoch 3/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5518 - loss: 14.8714 \n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.8596\n",
            "  - Class 1: Loss = 3.3233\n",
            "  - Class 2: Loss = 3.3608\n",
            "  - Class 3: Loss = 2.9565\n",
            "  - Class 4: Loss = 2.8051\n",
            "  - Class 5: Loss = 5.2951\n",
            "  - Class 6: Loss = 3.1715\n",
            "  - Class 7: Loss = 3.4010\n",
            "  - Class 8: Loss = 3.7029\n",
            "  - Class 9: Loss = 2.7311\n",
            "  - Class 10: Loss = 3.9358\n",
            "  - Class 11: Loss = 3.4878\n",
            "  - Class 12: Loss = 4.1850\n",
            "  - Class 13: Loss = 2.7956\n",
            "  - Class 14: Loss = 3.1905\n",
            "  - Class 15: Loss = 3.5318\n",
            "  - Class 16: Loss = 3.6830\n",
            "  - Class 17: Loss = 8.6871\n",
            "  - Class 18: Loss = 3.3935\n",
            "  - Class 19: Loss = 3.3300\n",
            "  - Class 20: Loss = 3.2108\n",
            "  - Class 21: Loss = 3.7262\n",
            "  - Class 22: Loss = 3.5391\n",
            "  - Class 23: Loss = 3.5869\n",
            "  - Class 24: Loss = 4.6283\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5465 - loss: 10.7336 - val_accuracy: 0.5079 - val_loss: 6.0978\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5472 - loss: 2.3811 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1.5106\n",
            "  - Class 1: Loss = 3.4267\n",
            "  - Class 2: Loss = 3.4666\n",
            "  - Class 3: Loss = 2.9744\n",
            "  - Class 4: Loss = 2.8110\n",
            "  - Class 5: Loss = 6.1355\n",
            "  - Class 6: Loss = 3.2441\n",
            "  - Class 7: Loss = 3.4786\n",
            "  - Class 8: Loss = 3.8968\n",
            "  - Class 9: Loss = 2.7437\n",
            "  - Class 10: Loss = 4.1556\n",
            "  - Class 11: Loss = 3.6083\n",
            "  - Class 12: Loss = 4.6461\n",
            "  - Class 13: Loss = 2.7730\n",
            "  - Class 14: Loss = 3.2714\n",
            "  - Class 15: Loss = 3.6780\n",
            "  - Class 16: Loss = 3.8574\n",
            "  - Class 17: Loss = 3.4705\n",
            "  - Class 18: Loss = 3.4879\n",
            "  - Class 19: Loss = 3.4194\n",
            "  - Class 20: Loss = 3.3019\n",
            "  - Class 21: Loss = 3.9096\n",
            "  - Class 22: Loss = 3.7192\n",
            "  - Class 23: Loss = 3.7070\n",
            "  - Class 24: Loss = 5.2056\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5390 - loss: 2.4156 - val_accuracy: 0.5079 - val_loss: 4.2627\n",
            "Trial 57 Complete [00h 00m 25s]\n",
            "val_accuracy: 0.5079365372657776\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 29m 46s\n",
            "\n",
            "Search: Running Trial #58\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "96                |256               |units_layer_1\n",
            "32                |32                |units_layer_2\n",
            "32                |64                |units_layer_3\n",
            "16                |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0689 - loss: 2467724.7500\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 26486.1348\n",
            "  - Class 1: Loss = 75995.9531\n",
            "  - Class 2: Loss = 17.9092\n",
            "  - Class 3: Loss = 22119.7812\n",
            "  - Class 4: Loss = 46352.6250\n",
            "  - Class 5: Loss = 3.2448\n",
            "  - Class 6: Loss = 71042.7266\n",
            "  - Class 7: Loss = 3155.7102\n",
            "  - Class 8: Loss = 106264.3516\n",
            "  - Class 9: Loss = 9633.7305\n",
            "  - Class 10: Loss = 2656.9358\n",
            "  - Class 11: Loss = 19616.0273\n",
            "  - Class 12: Loss = 3.2403\n",
            "  - Class 13: Loss = 37508.3320\n",
            "  - Class 14: Loss = 154233.6250\n",
            "  - Class 15: Loss = 158529.3906\n",
            "  - Class 16: Loss = 48237.7773\n",
            "  - Class 17: Loss = 34431.0312\n",
            "  - Class 18: Loss = 13317.9873\n",
            "  - Class 19: Loss = 71683.2109\n",
            "  - Class 20: Loss = 123277.1797\n",
            "  - Class 21: Loss = 88276.1875\n",
            "  - Class 22: Loss = 60849.8438\n",
            "  - Class 23: Loss = 131870.1875\n",
            "  - Class 24: Loss = 3.2359\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 285ms/step - accuracy: 0.0704 - loss: 2440296.2500 - val_accuracy: 0.3545 - val_loss: 43144.1133\n",
            "Epoch 2/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4752 - loss: 20073.2578 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 1804.9720\n",
            "  - Class 1: Loss = 962.7969\n",
            "  - Class 2: Loss = 3.1880\n",
            "  - Class 3: Loss = 62.6724\n",
            "  - Class 4: Loss = 1125.0253\n",
            "  - Class 5: Loss = 3.2473\n",
            "  - Class 6: Loss = 74.8850\n",
            "  - Class 7: Loss = 3.2053\n",
            "  - Class 8: Loss = 3.2484\n",
            "  - Class 9: Loss = 27.3889\n",
            "  - Class 10: Loss = 253.0001\n",
            "  - Class 11: Loss = 3.2305\n",
            "  - Class 12: Loss = 3.2825\n",
            "  - Class 13: Loss = 436.9518\n",
            "  - Class 14: Loss = 3.2212\n",
            "  - Class 15: Loss = 3.2387\n",
            "  - Class 16: Loss = 3.2483\n",
            "  - Class 17: Loss = 826.2644\n",
            "  - Class 18: Loss = 3.2289\n",
            "  - Class 19: Loss = 3.2264\n",
            "  - Class 20: Loss = 11236.3662\n",
            "  - Class 21: Loss = 3.2556\n",
            "  - Class 22: Loss = 6769.1577\n",
            "  - Class 23: Loss = 3.2662\n",
            "  - Class 24: Loss = 3.2863\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.4753 - loss: 16297.9902 - val_accuracy: 0.4656 - val_loss: 2928.9255\n",
            "Epoch 3/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5369 - loss: 427.1844\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 759.5034\n",
            "  - Class 1: Loss = 23.3659\n",
            "  - Class 2: Loss = 3.1832\n",
            "  - Class 3: Loss = 27.9196\n",
            "  - Class 4: Loss = 3.1905\n",
            "  - Class 5: Loss = 3.2518\n",
            "  - Class 6: Loss = 3.1130\n",
            "  - Class 7: Loss = 3.1951\n",
            "  - Class 8: Loss = 3.2716\n",
            "  - Class 9: Loss = 3.2558\n",
            "  - Class 10: Loss = 170.4221\n",
            "  - Class 11: Loss = 3.2609\n",
            "  - Class 12: Loss = 3.3200\n",
            "  - Class 13: Loss = 145.3765\n",
            "  - Class 14: Loss = 3.2185\n",
            "  - Class 15: Loss = 3.2697\n",
            "  - Class 16: Loss = 3.2839\n",
            "  - Class 17: Loss = 119.0734\n",
            "  - Class 18: Loss = 3.2148\n",
            "  - Class 19: Loss = 3.2435\n",
            "  - Class 20: Loss = 2612.9856\n",
            "  - Class 21: Loss = 3.2517\n",
            "  - Class 22: Loss = 282.2680\n",
            "  - Class 23: Loss = 3.2555\n",
            "  - Class 24: Loss = 3.3269\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5297 - loss: 567.6047 - val_accuracy: 0.4841 - val_loss: 1456.8403\n",
            "Epoch 4/4\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5458 - loss: 190.6494\n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 556.9642\n",
            "  - Class 1: Loss = 369.4285\n",
            "  - Class 2: Loss = 3.1831\n",
            "  - Class 3: Loss = 2726.8738\n",
            "  - Class 4: Loss = 3.1603\n",
            "  - Class 5: Loss = 3.2604\n",
            "  - Class 6: Loss = 3.1153\n",
            "  - Class 7: Loss = 3.1848\n",
            "  - Class 8: Loss = 3.2927\n",
            "  - Class 9: Loss = 3.1244\n",
            "  - Class 10: Loss = 3.2973\n",
            "  - Class 11: Loss = 3.2866\n",
            "  - Class 12: Loss = 3.3523\n",
            "  - Class 13: Loss = 80.6055\n",
            "  - Class 14: Loss = 3.2220\n",
            "  - Class 15: Loss = 3.2973\n",
            "  - Class 16: Loss = 3.3140\n",
            "  - Class 17: Loss = 72.1394\n",
            "  - Class 18: Loss = 3.2033\n",
            "  - Class 19: Loss = 3.2615\n",
            "  - Class 20: Loss = 3.2308\n",
            "  - Class 21: Loss = 3.2509\n",
            "  - Class 22: Loss = 5050.0444\n",
            "  - Class 23: Loss = 839.1898\n",
            "  - Class 24: Loss = 3.3609\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5392 - loss: 318.3922 - val_accuracy: 0.4841 - val_loss: 2985.1160\n",
            "Trial 58 Complete [00h 00m 24s]\n",
            "val_accuracy: 0.4841269850730896\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 30m 10s\n",
            "\n",
            "Search: Running Trial #59\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.005             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "224               |256               |units_layer_1\n",
            "128               |32                |units_layer_2\n",
            "48                |64                |units_layer_3\n",
            "32                |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "2025-08-27 10:08:52.688200: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 104 bytes spill stores, 104 bytes spill loads\n",
            "\n",
            "2025-08-27 10:08:53.419035: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 956 bytes spill stores, 956 bytes spill loads\n",
            "\n",
            "2025-08-27 10:08:53.648683: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 10:08:53.879433: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 216 bytes spill stores, 216 bytes spill loads\n",
            "\n",
            "\u001b[1m26/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4351 - loss: 2.3705     2025-08-27 10:08:58.206042: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4991 - loss: 2.11762025-08-27 10:09:02.604167: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 104 bytes spill stores, 104 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:03.115117: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:03.154832: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 228 bytes spill stores, 228 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:03.753567: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 960 bytes spill stores, 960 bytes spill loads\n",
            "\n",
            "\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.7035\n",
            "2025-08-27 10:09:07.329906: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "  - Class 1: Loss = 3.1857\n",
            "2025-08-27 10:09:09.446535: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "  - Class 2: Loss = 0.1854\n",
            "2025-08-27 10:09:11.891163: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 716 bytes spill stores, 716 bytes spill loads\n",
            "\n",
            "  - Class 3: Loss = 1.5477\n",
            "2025-08-27 10:09:14.540287: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "  - Class 4: Loss = 0.3830\n",
            "  - Class 5: Loss = 6.5548\n",
            "  - Class 6: Loss = 0.7241\n",
            "2025-08-27 10:09:17.820643: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "  - Class 7: Loss = 2.6109\n",
            "2025-08-27 10:09:20.240060: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "  - Class 8: Loss = 4.2810\n",
            "2025-08-27 10:09:22.129510: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 104 bytes spill stores, 104 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:22.953323: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 960 bytes spill stores, 960 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:22.984125: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 228 bytes spill stores, 228 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:23.159178: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "  - Class 9: Loss = 2.2676\n",
            "2025-08-27 10:09:25.824086: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "  - Class 10: Loss = 4.1552\n",
            "2025-08-27 10:09:28.542673: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "  - Class 11: Loss = 4.1572\n",
            "2025-08-27 10:09:31.143110: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "  - Class 12: Loss = 4.8722\n",
            "  - Class 13: Loss = 2.2049\n",
            "  - Class 14: Loss = 2.6078\n",
            "  - Class 15: Loss = 3.1614\n",
            "  - Class 16: Loss = 5.0601\n",
            "  - Class 17: Loss = 1.5494\n",
            "  - Class 18: Loss = 3.9081\n",
            "2025-08-27 10:09:33.452105: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 88 bytes spill stores, 88 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:33.899441: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 228 bytes spill stores, 228 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:34.308347: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 104 bytes spill stores, 104 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:34.552325: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 960 bytes spill stores, 960 bytes spill loads\n",
            "\n",
            "  - Class 19: Loss = 3.7309\n",
            "  - Class 20: Loss = 2.7251\n",
            "  - Class 21: Loss = 4.3577\n",
            "2025-08-27 10:09:37.210525: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 720 bytes spill stores, 720 bytes spill loads\n",
            "\n",
            "  - Class 22: Loss = 5.5222\n",
            "  - Class 23: Loss = 3.8027\n",
            "  - Class 24: Loss = 5.0039\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 896ms/step - accuracy: 0.5009 - loss: 2.1101 - val_accuracy: 0.6085 - val_loss: 1.6207\n",
            "Epoch 2/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 1.3766 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4239\n",
            "  - Class 1: Loss = 2.7698\n",
            "  - Class 2: Loss = 0.0605\n",
            "  - Class 3: Loss = 1.1155\n",
            "  - Class 4: Loss = 0.4843\n",
            "  - Class 5: Loss = 6.8038\n",
            "  - Class 6: Loss = 0.3407\n",
            "  - Class 7: Loss = 1.8983\n",
            "  - Class 8: Loss = 4.2630\n",
            "  - Class 9: Loss = 2.1306\n",
            "  - Class 10: Loss = 3.2357\n",
            "  - Class 11: Loss = 3.1992\n",
            "  - Class 12: Loss = 5.1003\n",
            "  - Class 13: Loss = 1.5403\n",
            "  - Class 14: Loss = 1.9807\n",
            "  - Class 15: Loss = 4.4898\n",
            "  - Class 16: Loss = 5.0257\n",
            "  - Class 17: Loss = 1.5598\n",
            "  - Class 18: Loss = 3.4081\n",
            "  - Class 19: Loss = 2.4245\n",
            "  - Class 20: Loss = 2.9084\n",
            "  - Class 21: Loss = 5.3353\n",
            "  - Class 22: Loss = 5.3143\n",
            "  - Class 23: Loss = 2.5813\n",
            "  - Class 24: Loss = 6.0086\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6594 - loss: 1.3700 - val_accuracy: 0.6190 - val_loss: 1.4905\n",
            "Epoch 3/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 1.0855 \n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2149\n",
            "  - Class 1: Loss = 2.3471\n",
            "  - Class 2: Loss = 0.0620\n",
            "  - Class 3: Loss = 1.4091\n",
            "  - Class 4: Loss = 0.2304\n",
            "  - Class 5: Loss = 6.6145\n",
            "  - Class 6: Loss = 0.1119\n",
            "  - Class 7: Loss = 1.9391\n",
            "  - Class 8: Loss = 3.9572\n",
            "  - Class 9: Loss = 1.7103\n",
            "  - Class 10: Loss = 2.4165\n",
            "  - Class 11: Loss = 3.3721\n",
            "  - Class 12: Loss = 6.2276\n",
            "  - Class 13: Loss = 1.5760\n",
            "  - Class 14: Loss = 1.6361\n",
            "  - Class 15: Loss = 4.3907\n",
            "  - Class 16: Loss = 5.0609\n",
            "  - Class 17: Loss = 1.4450\n",
            "  - Class 18: Loss = 3.2270\n",
            "  - Class 19: Loss = 2.4442\n",
            "  - Class 20: Loss = 3.4637\n",
            "  - Class 21: Loss = 5.6225\n",
            "  - Class 22: Loss = 5.8527\n",
            "  - Class 23: Loss = 2.1120\n",
            "  - Class 24: Loss = 8.0487\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7093 - loss: 1.0830 - val_accuracy: 0.6296 - val_loss: 1.4709\n",
            "Epoch 4/4\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.9920 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.2563\n",
            "  - Class 1: Loss = 2.5761\n",
            "  - Class 2: Loss = 0.0904\n",
            "  - Class 3: Loss = 0.7719\n",
            "  - Class 4: Loss = 0.5141\n",
            "  - Class 5: Loss = 5.3214\n",
            "  - Class 6: Loss = 0.1804\n",
            "  - Class 7: Loss = 1.4330\n",
            "  - Class 8: Loss = 3.7213\n",
            "  - Class 9: Loss = 0.9309\n",
            "  - Class 10: Loss = 1.6295\n",
            "  - Class 11: Loss = 2.4659\n",
            "  - Class 12: Loss = 4.9242\n",
            "  - Class 13: Loss = 1.2248\n",
            "  - Class 14: Loss = 1.1347\n",
            "  - Class 15: Loss = 3.6203\n",
            "  - Class 16: Loss = 4.7140\n",
            "  - Class 17: Loss = 1.1663\n",
            "  - Class 18: Loss = 2.7547\n",
            "  - Class 19: Loss = 1.2757\n",
            "  - Class 20: Loss = 2.1125\n",
            "  - Class 21: Loss = 4.5996\n",
            "  - Class 22: Loss = 5.6718\n",
            "  - Class 23: Loss = 1.2899\n",
            "  - Class 24: Loss = 5.5060\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7393 - loss: 0.9660 - val_accuracy: 0.6296 - val_loss: 1.4291\n",
            "Trial 59 Complete [00h 00m 55s]\n",
            "val_accuracy: 0.6296296119689941\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 31m 05s\n",
            "\n",
            "Search: Running Trial #60\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.005             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "128               |256               |units_layer_1\n",
            "128               |32                |units_layer_2\n",
            "16                |64                |units_layer_3\n",
            "8                 |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "\u001b[1m26/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4220 - loss: 2.6611 2025-08-27 10:09:50.473727: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_206', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:50.821905: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_206', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4734 - loss: 2.4591\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5161\n",
            "2025-08-27 10:09:55.909762: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:55.989091: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 1: Loss = 3.8033\n",
            "2025-08-27 10:09:57.256193: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:57.288386: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 2: Loss = 1.7479\n",
            "2025-08-27 10:09:58.487934: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "  - Class 3: Loss = 3.5919\n",
            "2025-08-27 10:09:59.572758: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:09:59.798824: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 4: Loss = 1.9630\n",
            "  - Class 5: Loss = 3.7540\n",
            "  - Class 6: Loss = 2.7287\n",
            "2025-08-27 10:10:01.557947: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:01.639035: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 7: Loss = 3.7301\n",
            "2025-08-27 10:10:02.736033: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:02.868727: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 8: Loss = 4.1954\n",
            "  - Class 9: Loss = 3.1022\n",
            "2025-08-27 10:10:05.586348: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:05.609206: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 10: Loss = 4.1213\n",
            "2025-08-27 10:10:06.734747: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:06.956734: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 11: Loss = 4.1976\n",
            "2025-08-27 10:10:08.122851: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:08.215394: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 12: Loss = 4.9224\n",
            "  - Class 13: Loss = 2.6461\n",
            "  - Class 14: Loss = 4.0752\n",
            "  - Class 15: Loss = 4.5764\n",
            "  - Class 16: Loss = 4.8679\n",
            "  - Class 17: Loss = 2.6335\n",
            "  - Class 18: Loss = 3.7530\n",
            "  - Class 19: Loss = 4.1718\n",
            "  - Class 20: Loss = 4.0670\n",
            "  - Class 21: Loss = 5.0682\n",
            "2025-08-27 10:10:11.473659: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:11.501009: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "  - Class 22: Loss = 4.1084\n",
            "  - Class 23: Loss = 4.7297\n",
            "  - Class 24: Loss = 5.2701\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 483ms/step - accuracy: 0.4749 - loss: 2.4526 - val_accuracy: 0.5582 - val_loss: 1.9208\n",
            "Epoch 2/4\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5677 - loss: 1.7893 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.5354\n",
            "  - Class 1: Loss = 3.5928\n",
            "  - Class 2: Loss = 1.1026\n",
            "  - Class 3: Loss = 3.1402\n",
            "  - Class 4: Loss = 1.3622\n",
            "  - Class 5: Loss = 2.9116\n",
            "  - Class 6: Loss = 1.4200\n",
            "  - Class 7: Loss = 3.2686\n",
            "  - Class 8: Loss = 4.4111\n",
            "  - Class 9: Loss = 2.4390\n",
            "  - Class 10: Loss = 4.2061\n",
            "  - Class 11: Loss = 4.1363\n",
            "  - Class 12: Loss = 4.9144\n",
            "  - Class 13: Loss = 2.3819\n",
            "  - Class 14: Loss = 3.8291\n",
            "  - Class 15: Loss = 4.6452\n",
            "  - Class 16: Loss = 4.8837\n",
            "  - Class 17: Loss = 1.9439\n",
            "  - Class 18: Loss = 3.8479\n",
            "  - Class 19: Loss = 3.7170\n",
            "  - Class 20: Loss = 3.9294\n",
            "  - Class 21: Loss = 5.6338\n",
            "  - Class 22: Loss = 4.4413\n",
            "  - Class 23: Loss = 4.3608\n",
            "  - Class 24: Loss = 5.6250\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5856 - loss: 1.7557 - val_accuracy: 0.5820 - val_loss: 1.7771\n",
            "Epoch 3/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 1.5876 \n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4278\n",
            "  - Class 1: Loss = 3.7016\n",
            "  - Class 2: Loss = 0.6405\n",
            "  - Class 3: Loss = 2.8068\n",
            "  - Class 4: Loss = 1.0675\n",
            "  - Class 5: Loss = 3.4244\n",
            "  - Class 6: Loss = 1.0825\n",
            "  - Class 7: Loss = 2.8095\n",
            "  - Class 8: Loss = 4.5948\n",
            "  - Class 9: Loss = 2.1823\n",
            "  - Class 10: Loss = 3.9457\n",
            "  - Class 11: Loss = 4.1110\n",
            "  - Class 12: Loss = 5.2009\n",
            "  - Class 13: Loss = 2.3770\n",
            "  - Class 14: Loss = 3.7303\n",
            "  - Class 15: Loss = 4.4978\n",
            "  - Class 16: Loss = 4.9691\n",
            "  - Class 17: Loss = 1.9132\n",
            "  - Class 18: Loss = 3.7598\n",
            "  - Class 19: Loss = 3.0041\n",
            "  - Class 20: Loss = 3.7196\n",
            "  - Class 21: Loss = 5.5688\n",
            "  - Class 22: Loss = 5.0943\n",
            "  - Class 23: Loss = 3.4719\n",
            "  - Class 24: Loss = 6.1602\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6392 - loss: 1.5616 - val_accuracy: 0.5847 - val_loss: 1.6664\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6738 - loss: 1.4040 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3593\n",
            "  - Class 1: Loss = 3.5767\n",
            "  - Class 2: Loss = 0.4230\n",
            "  - Class 3: Loss = 2.4648\n",
            "  - Class 4: Loss = 0.9003\n",
            "  - Class 5: Loss = 3.7944\n",
            "  - Class 6: Loss = 0.5525\n",
            "  - Class 7: Loss = 2.5914\n",
            "  - Class 8: Loss = 4.6256\n",
            "  - Class 9: Loss = 2.0674\n",
            "  - Class 10: Loss = 3.9889\n",
            "  - Class 11: Loss = 4.1590\n",
            "  - Class 12: Loss = 5.4108\n",
            "  - Class 13: Loss = 2.2188\n",
            "  - Class 14: Loss = 3.6129\n",
            "  - Class 15: Loss = 4.4459\n",
            "  - Class 16: Loss = 5.0350\n",
            "  - Class 17: Loss = 1.7615\n",
            "  - Class 18: Loss = 3.7046\n",
            "  - Class 19: Loss = 2.6023\n",
            "  - Class 20: Loss = 3.5712\n",
            "  - Class 21: Loss = 5.8056\n",
            "  - Class 22: Loss = 5.4442\n",
            "  - Class 23: Loss = 2.8881\n",
            "  - Class 24: Loss = 6.8319\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6711 - loss: 1.4009 - val_accuracy: 0.5952 - val_loss: 1.6072\n",
            "Trial 60 Complete [00h 00m 34s]\n",
            "val_accuracy: 0.5952380895614624\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 31m 39s\n",
            "\n",
            "Search: Running Trial #61\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0001            |0.001             |learning_rate\n",
            "relu              |tanh              |activation\n",
            "160               |256               |units_layer_1\n",
            "96                |32                |units_layer_2\n",
            "32                |64                |units_layer_3\n",
            "32                |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2192 - loss: 3074498.0000\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 337345.5000\n",
            "  - Class 1: Loss = 6309067.0000\n",
            "  - Class 2: Loss = 3602.5366\n",
            "  - Class 3: Loss = 672435.6875\n",
            "  - Class 4: Loss = 4447293.5000\n",
            "  - Class 5: Loss = 10538245.0000\n",
            "  - Class 6: Loss = 3354605.5000\n",
            "  - Class 7: Loss = 1881276.6250\n",
            "  - Class 8: Loss = 4092162.5000\n",
            "  - Class 9: Loss = 713117.1875\n",
            "  - Class 10: Loss = 67287.8828\n",
            "  - Class 11: Loss = 8975304.0000\n",
            "  - Class 12: Loss = 12187914.0000\n",
            "  - Class 13: Loss = 2548277.5000\n",
            "  - Class 14: Loss = 5679628.0000\n",
            "  - Class 15: Loss = 10376828.0000\n",
            "  - Class 16: Loss = 13549803.0000\n",
            "  - Class 17: Loss = 1326753.7500\n",
            "  - Class 18: Loss = 1788285.0000\n",
            "  - Class 19: Loss = 2542505.5000\n",
            "  - Class 20: Loss = 6881221.5000\n",
            "  - Class 21: Loss = 5890004.5000\n",
            "  - Class 22: Loss = 4991764.0000\n",
            "  - Class 23: Loss = 9906592.0000\n",
            "  - Class 24: Loss = 6334293.0000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 350ms/step - accuracy: 0.2206 - loss: 3061651.7500 - val_accuracy: 0.3254 - val_loss: 1793533.2500\n",
            "Epoch 2/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3847 - loss: 1554981.5000 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 220640.7031\n",
            "  - Class 1: Loss = 4818129.0000\n",
            "  - Class 2: Loss = 1621.9260\n",
            "  - Class 3: Loss = 539191.8125\n",
            "  - Class 4: Loss = 2840522.0000\n",
            "  - Class 5: Loss = 10071358.0000\n",
            "  - Class 6: Loss = 766960.5000\n",
            "  - Class 7: Loss = 1554101.5000\n",
            "  - Class 8: Loss = 3517948.7500\n",
            "  - Class 9: Loss = 530796.4375\n",
            "  - Class 10: Loss = 48007.1992\n",
            "  - Class 11: Loss = 5755432.0000\n",
            "  - Class 12: Loss = 6537571.0000\n",
            "  - Class 13: Loss = 1880969.6250\n",
            "  - Class 14: Loss = 3781102.5000\n",
            "  - Class 15: Loss = 9033534.0000\n",
            "  - Class 16: Loss = 9598057.0000\n",
            "  - Class 17: Loss = 802873.9375\n",
            "  - Class 18: Loss = 1389467.8750\n",
            "  - Class 19: Loss = 2100282.0000\n",
            "  - Class 20: Loss = 5051306.5000\n",
            "  - Class 21: Loss = 4481688.5000\n",
            "  - Class 22: Loss = 3526432.7500\n",
            "  - Class 23: Loss = 7274878.5000\n",
            "  - Class 24: Loss = 5145556.5000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.3788 - loss: 1513689.0000 - val_accuracy: 0.3492 - val_loss: 1332045.6250\n",
            "Epoch 3/4\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3878 - loss: 1113377.5000\n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 138778.1875\n",
            "  - Class 1: Loss = 4058843.5000\n",
            "  - Class 2: Loss = 722.0758\n",
            "  - Class 3: Loss = 473784.1562\n",
            "  - Class 4: Loss = 1930144.6250\n",
            "  - Class 5: Loss = 10232402.0000\n",
            "  - Class 6: Loss = 458112.9062\n",
            "  - Class 7: Loss = 1250741.6250\n",
            "  - Class 8: Loss = 3126183.0000\n",
            "  - Class 9: Loss = 421334.5938\n",
            "  - Class 10: Loss = 43326.7539\n",
            "  - Class 11: Loss = 3902899.2500\n",
            "  - Class 12: Loss = 3608900.2500\n",
            "  - Class 13: Loss = 1495491.0000\n",
            "  - Class 14: Loss = 2731656.5000\n",
            "  - Class 15: Loss = 7407079.5000\n",
            "  - Class 16: Loss = 7416340.0000\n",
            "  - Class 17: Loss = 504697.8438\n",
            "  - Class 18: Loss = 1116013.2500\n",
            "  - Class 19: Loss = 1839069.0000\n",
            "  - Class 20: Loss = 4288967.5000\n",
            "  - Class 21: Loss = 3856195.0000\n",
            "  - Class 22: Loss = 2642588.2500\n",
            "  - Class 23: Loss = 5836951.5000\n",
            "  - Class 24: Loss = 4228150.5000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.3969 - loss: 1101009.0000 - val_accuracy: 0.3386 - val_loss: 1110326.3750\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4403 - loss: 772625.1875  \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 120221.9453\n",
            "  - Class 1: Loss = 3447323.0000\n",
            "  - Class 2: Loss = 404.3983\n",
            "  - Class 3: Loss = 416748.5312\n",
            "  - Class 4: Loss = 1148900.8750\n",
            "  - Class 5: Loss = 10017587.0000\n",
            "  - Class 6: Loss = 333435.0625\n",
            "  - Class 7: Loss = 942912.9375\n",
            "  - Class 8: Loss = 2797272.2500\n",
            "  - Class 9: Loss = 366134.5938\n",
            "  - Class 10: Loss = 38636.8008\n",
            "  - Class 11: Loss = 3180256.5000\n",
            "  - Class 12: Loss = 1850658.7500\n",
            "  - Class 13: Loss = 1226680.1250\n",
            "  - Class 14: Loss = 2033768.3750\n",
            "  - Class 15: Loss = 5889985.5000\n",
            "  - Class 16: Loss = 5718350.0000\n",
            "  - Class 17: Loss = 436333.9688\n",
            "  - Class 18: Loss = 863001.0000\n",
            "  - Class 19: Loss = 1615837.0000\n",
            "  - Class 20: Loss = 3472460.7500\n",
            "  - Class 21: Loss = 3298598.0000\n",
            "  - Class 22: Loss = 2168333.5000\n",
            "  - Class 23: Loss = 4718244.0000\n",
            "  - Class 24: Loss = 4085665.5000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.4305 - loss: 795088.6875 - val_accuracy: 0.3360 - val_loss: 959802.9375\n",
            "Trial 61 Complete [00h 00m 27s]\n",
            "val_accuracy: 0.3492063581943512\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 32m 06s\n",
            "\n",
            "Search: Running Trial #62\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0001            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "192               |256               |units_layer_1\n",
            "128               |32                |units_layer_2\n",
            "16                |64                |units_layer_3\n",
            "8                 |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "2025-08-27 10:10:48.736886: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:49.304678: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 100 bytes spill stores, 100 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:49.425736: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 180 bytes spill stores, 180 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:50.394846: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 996 bytes spill stores, 996 bytes spill loads\n",
            "\n",
            "\u001b[1m26/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0283 - loss: 3.3123 2025-08-27 10:10:53.816376: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.0416 - loss: 3.27122025-08-27 10:10:57.462372: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 100 bytes spill stores, 100 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:57.775335: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 192 bytes spill stores, 192 bytes spill loads\n",
            "\n",
            "2025-08-27 10:10:57.915200: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 1000 bytes spill stores, 1000 bytes spill loads\n",
            "\n",
            "\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.8475\n",
            "2025-08-27 10:11:01.031631: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "  - Class 1: Loss = 3.5251\n",
            "2025-08-27 10:11:03.117286: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "  - Class 2: Loss = 3.4977\n",
            "2025-08-27 10:11:05.250013: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 772 bytes spill stores, 772 bytes spill loads\n",
            "\n",
            "  - Class 3: Loss = 3.2201\n",
            "2025-08-27 10:11:07.386497: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "  - Class 4: Loss = 3.3290\n",
            "  - Class 5: Loss = 3.6527\n",
            "  - Class 6: Loss = 2.9919\n",
            "2025-08-27 10:11:10.081234: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "  - Class 7: Loss = 3.5883\n",
            "2025-08-27 10:11:12.303964: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "  - Class 8: Loss = 3.3175\n",
            "2025-08-27 10:11:14.424684: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 100 bytes spill stores, 100 bytes spill loads\n",
            "\n",
            "2025-08-27 10:11:14.641379: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 192 bytes spill stores, 192 bytes spill loads\n",
            "\n",
            "2025-08-27 10:11:14.663964: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 1000 bytes spill stores, 1000 bytes spill loads\n",
            "\n",
            "  - Class 9: Loss = 3.0849\n",
            "2025-08-27 10:11:16.828528: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "  - Class 10: Loss = 3.1638\n",
            "2025-08-27 10:11:18.903927: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "  - Class 11: Loss = 2.7910\n",
            "2025-08-27 10:11:20.893670: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "  - Class 12: Loss = 3.1759\n",
            "  - Class 13: Loss = 3.1058\n",
            "  - Class 14: Loss = 3.2410\n",
            "  - Class 15: Loss = 3.3260\n",
            "  - Class 16: Loss = 3.0040\n",
            "  - Class 17: Loss = 3.1723\n",
            "  - Class 18: Loss = 2.9827\n",
            "2025-08-27 10:11:23.217827: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 100 bytes spill stores, 100 bytes spill loads\n",
            "\n",
            "2025-08-27 10:11:23.382595: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 192 bytes spill stores, 192 bytes spill loads\n",
            "\n",
            "2025-08-27 10:11:23.646568: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 1000 bytes spill stores, 1000 bytes spill loads\n",
            "\n",
            "  - Class 19: Loss = 3.3840\n",
            "  - Class 20: Loss = 3.5543\n",
            "  - Class 21: Loss = 3.6370\n",
            "2025-08-27 10:11:25.965452: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 776 bytes spill stores, 776 bytes spill loads\n",
            "\n",
            "  - Class 22: Loss = 3.0373\n",
            "  - Class 23: Loss = 3.2875\n",
            "  - Class 24: Loss = 3.5581\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 742ms/step - accuracy: 0.0423 - loss: 3.2696 - val_accuracy: 0.1296 - val_loss: 3.0853\n",
            "Epoch 2/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1826 - loss: 2.9995 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.5413\n",
            "  - Class 1: Loss = 3.6192\n",
            "  - Class 2: Loss = 3.2613\n",
            "  - Class 3: Loss = 3.1903\n",
            "  - Class 4: Loss = 3.1622\n",
            "  - Class 5: Loss = 3.5480\n",
            "  - Class 6: Loss = 2.9812\n",
            "  - Class 7: Loss = 3.7683\n",
            "  - Class 8: Loss = 3.1842\n",
            "  - Class 9: Loss = 3.0450\n",
            "  - Class 10: Loss = 3.2310\n",
            "  - Class 11: Loss = 2.5136\n",
            "  - Class 12: Loss = 3.2396\n",
            "  - Class 13: Loss = 3.0094\n",
            "  - Class 14: Loss = 3.5641\n",
            "  - Class 15: Loss = 3.3737\n",
            "  - Class 16: Loss = 2.9919\n",
            "  - Class 17: Loss = 3.0893\n",
            "  - Class 18: Loss = 2.8150\n",
            "  - Class 19: Loss = 3.5125\n",
            "  - Class 20: Loss = 3.5933\n",
            "  - Class 21: Loss = 3.6863\n",
            "  - Class 22: Loss = 3.0268\n",
            "  - Class 23: Loss = 3.5106\n",
            "  - Class 24: Loss = 3.7789\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.2089 - loss: 2.9824 - val_accuracy: 0.3201 - val_loss: 2.9224\n",
            "Epoch 3/4\n",
            "\u001b[1m25/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3606 - loss: 2.8374 \n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.3685\n",
            "  - Class 1: Loss = 3.6329\n",
            "  - Class 2: Loss = 2.9639\n",
            "  - Class 3: Loss = 3.1644\n",
            "  - Class 4: Loss = 3.0117\n",
            "  - Class 5: Loss = 3.5342\n",
            "  - Class 6: Loss = 2.9774\n",
            "  - Class 7: Loss = 3.8096\n",
            "  - Class 8: Loss = 3.1438\n",
            "  - Class 9: Loss = 3.0026\n",
            "  - Class 10: Loss = 3.2570\n",
            "  - Class 11: Loss = 2.3788\n",
            "  - Class 12: Loss = 3.2223\n",
            "  - Class 13: Loss = 2.9637\n",
            "  - Class 14: Loss = 3.7197\n",
            "  - Class 15: Loss = 3.3571\n",
            "  - Class 16: Loss = 3.0756\n",
            "  - Class 17: Loss = 3.0383\n",
            "  - Class 18: Loss = 2.7498\n",
            "  - Class 19: Loss = 3.6004\n",
            "  - Class 20: Loss = 3.6234\n",
            "  - Class 21: Loss = 3.7537\n",
            "  - Class 22: Loss = 3.0648\n",
            "  - Class 23: Loss = 3.6099\n",
            "  - Class 24: Loss = 3.8838\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.3685 - loss: 2.8262 - val_accuracy: 0.3836 - val_loss: 2.8162\n",
            "Epoch 4/4\n",
            "\u001b[1m29/48\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4287 - loss: 2.7394 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.2510\n",
            "  - Class 1: Loss = 3.6165\n",
            "  - Class 2: Loss = 2.7014\n",
            "  - Class 3: Loss = 3.1411\n",
            "  - Class 4: Loss = 2.8505\n",
            "  - Class 5: Loss = 3.5566\n",
            "  - Class 6: Loss = 2.9665\n",
            "  - Class 7: Loss = 3.7799\n",
            "  - Class 8: Loss = 3.1406\n",
            "  - Class 9: Loss = 2.9709\n",
            "  - Class 10: Loss = 3.3126\n",
            "  - Class 11: Loss = 2.3144\n",
            "  - Class 12: Loss = 3.2147\n",
            "  - Class 13: Loss = 2.9095\n",
            "  - Class 14: Loss = 3.7774\n",
            "  - Class 15: Loss = 3.3531\n",
            "  - Class 16: Loss = 3.1487\n",
            "  - Class 17: Loss = 3.0085\n",
            "  - Class 18: Loss = 2.7237\n",
            "  - Class 19: Loss = 3.6497\n",
            "  - Class 20: Loss = 3.6500\n",
            "  - Class 21: Loss = 3.8084\n",
            "  - Class 22: Loss = 3.1115\n",
            "  - Class 23: Loss = 3.6675\n",
            "  - Class 24: Loss = 3.9726\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4373 - loss: 2.7289 - val_accuracy: 0.4524 - val_loss: 2.7377\n",
            "Trial 62 Complete [00h 00m 48s]\n",
            "val_accuracy: 0.4523809552192688\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 32m 54s\n",
            "\n",
            "Search: Running Trial #63\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "256               |256               |units_layer_1\n",
            "128               |32                |units_layer_2\n",
            "16                |64                |units_layer_3\n",
            "24                |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "2025-08-27 10:11:37.413088: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_388', 12 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "\u001b[1m24/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1445 - loss: 3.0023 2025-08-27 10:11:40.419213: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2757 - loss: 2.7990\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.9930\n",
            "2025-08-27 10:11:47.260823: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "  - Class 1: Loss = 3.3957\n",
            "2025-08-27 10:11:49.244322: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "  - Class 2: Loss = 1.7248\n",
            "  - Class 3: Loss = 3.2062\n",
            "2025-08-27 10:11:52.532311: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "  - Class 4: Loss = 1.7558\n",
            "  - Class 5: Loss = 4.1892\n",
            "  - Class 6: Loss = 1.8431\n",
            "2025-08-27 10:11:54.805565: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "  - Class 7: Loss = 3.7250\n",
            "2025-08-27 10:11:57.055557: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "  - Class 8: Loss = 4.0016\n",
            "  - Class 9: Loss = 3.9230\n",
            "2025-08-27 10:12:00.451712: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "  - Class 10: Loss = 3.7978\n",
            "2025-08-27 10:12:02.086514: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "  - Class 11: Loss = 4.2359\n",
            "2025-08-27 10:12:03.963640: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "  - Class 12: Loss = 3.7257\n",
            "  - Class 13: Loss = 3.2933\n",
            "  - Class 14: Loss = 3.9273\n",
            "  - Class 15: Loss = 3.9467\n",
            "  - Class 16: Loss = 4.5804\n",
            "  - Class 17: Loss = 2.0661\n",
            "  - Class 18: Loss = 3.1576\n",
            "  - Class 19: Loss = 4.0839\n",
            "  - Class 20: Loss = 3.5264\n",
            "  - Class 21: Loss = 3.5928\n",
            "2025-08-27 10:12:08.798083: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 24 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "  - Class 22: Loss = 3.8703\n",
            "  - Class 23: Loss = 3.2041\n",
            "  - Class 24: Loss = 4.5196\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 640ms/step - accuracy: 0.2795 - loss: 2.7922 - val_accuracy: 0.5873 - val_loss: 2.0332\n",
            "Epoch 2/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6472 - loss: 1.8489 \n",
            "Epoch 2: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.6095\n",
            "  - Class 1: Loss = 3.5404\n",
            "  - Class 2: Loss = 1.1378\n",
            "  - Class 3: Loss = 2.8246\n",
            "  - Class 4: Loss = 1.1436\n",
            "  - Class 5: Loss = 4.3643\n",
            "  - Class 6: Loss = 1.2008\n",
            "  - Class 7: Loss = 3.6851\n",
            "  - Class 8: Loss = 4.2111\n",
            "  - Class 9: Loss = 3.1655\n",
            "  - Class 10: Loss = 3.9334\n",
            "  - Class 11: Loss = 4.1908\n",
            "  - Class 12: Loss = 4.6011\n",
            "  - Class 13: Loss = 3.0161\n",
            "  - Class 14: Loss = 3.7572\n",
            "  - Class 15: Loss = 4.3483\n",
            "  - Class 16: Loss = 4.7577\n",
            "  - Class 17: Loss = 2.0938\n",
            "  - Class 18: Loss = 3.4134\n",
            "  - Class 19: Loss = 4.3032\n",
            "  - Class 20: Loss = 3.6442\n",
            "  - Class 21: Loss = 4.3364\n",
            "  - Class 22: Loss = 4.5695\n",
            "  - Class 23: Loss = 3.8385\n",
            "  - Class 24: Loss = 5.0850\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6385 - loss: 1.8341 - val_accuracy: 0.5952 - val_loss: 1.8084\n",
            "Epoch 3/4\n",
            "\u001b[1m27/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6305 - loss: 1.6918 \n",
            "Epoch 3: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.4703\n",
            "  - Class 1: Loss = 3.5390\n",
            "  - Class 2: Loss = 0.7636\n",
            "  - Class 3: Loss = 2.4681\n",
            "  - Class 4: Loss = 0.9879\n",
            "  - Class 5: Loss = 4.4754\n",
            "  - Class 6: Loss = 1.1980\n",
            "  - Class 7: Loss = 3.2666\n",
            "  - Class 8: Loss = 4.3318\n",
            "  - Class 9: Loss = 2.6206\n",
            "  - Class 10: Loss = 3.7935\n",
            "  - Class 11: Loss = 4.0136\n",
            "  - Class 12: Loss = 4.7723\n",
            "  - Class 13: Loss = 2.9462\n",
            "  - Class 14: Loss = 3.7041\n",
            "  - Class 15: Loss = 4.5110\n",
            "  - Class 16: Loss = 4.7026\n",
            "  - Class 17: Loss = 1.8489\n",
            "  - Class 18: Loss = 3.4924\n",
            "  - Class 19: Loss = 4.3710\n",
            "  - Class 20: Loss = 3.6639\n",
            "  - Class 21: Loss = 4.7280\n",
            "  - Class 22: Loss = 4.7533\n",
            "  - Class 23: Loss = 3.9978\n",
            "  - Class 24: Loss = 5.3607\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6421 - loss: 1.6464 - val_accuracy: 0.6085 - val_loss: 1.6971\n",
            "Epoch 4/4\n",
            "\u001b[1m28/48\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6453 - loss: 1.4733 \n",
            "Epoch 4: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 0.3974\n",
            "  - Class 1: Loss = 3.6082\n",
            "  - Class 2: Loss = 0.5024\n",
            "  - Class 3: Loss = 2.3701\n",
            "  - Class 4: Loss = 0.8503\n",
            "  - Class 5: Loss = 4.5617\n",
            "  - Class 6: Loss = 0.7065\n",
            "  - Class 7: Loss = 2.8002\n",
            "  - Class 8: Loss = 4.3847\n",
            "  - Class 9: Loss = 2.1681\n",
            "  - Class 10: Loss = 3.8512\n",
            "  - Class 11: Loss = 3.8766\n",
            "  - Class 12: Loss = 5.2105\n",
            "  - Class 13: Loss = 2.6681\n",
            "  - Class 14: Loss = 3.4742\n",
            "  - Class 15: Loss = 4.4400\n",
            "  - Class 16: Loss = 4.6657\n",
            "  - Class 17: Loss = 1.7851\n",
            "  - Class 18: Loss = 3.5668\n",
            "  - Class 19: Loss = 4.1965\n",
            "  - Class 20: Loss = 3.6428\n",
            "  - Class 21: Loss = 4.7830\n",
            "  - Class 22: Loss = 4.9218\n",
            "  - Class 23: Loss = 4.1226\n",
            "  - Class 24: Loss = 4.7827\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6507 - loss: 1.4721 - val_accuracy: 0.6058 - val_loss: 1.6246\n",
            "Trial 63 Complete [00h 00m 43s]\n",
            "val_accuracy: 0.6084656119346619\n",
            "\n",
            "Best val_accuracy So Far: 0.6322751045227051\n",
            "Total elapsed time: 00h 33m 37s\n",
            "\n",
            "Search: Running Trial #64\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.0001            |0.001             |learning_rate\n",
            "tanh              |tanh              |activation\n",
            "192               |256               |units_layer_1\n",
            "64                |32                |units_layer_2\n",
            "64                |64                |units_layer_3\n",
            "8                 |16                |units_layer_4\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "2                 |3                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "🏗️ Costruzione modello mlp_4_layer (tuner-ready)\n",
            "📊 Input shape: (290,)\n",
            "🏷️ Classi: 25\n",
            "✅ Modello mlp_4_layer (tuner-ready) creato e compilato\n",
            "Epoch 1/4\n",
            "2025-08-27 10:12:19.415536: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-08-27 10:12:20.262339: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 180 bytes spill stores, 180 bytes spill loads\n",
            "\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.1345 - loss: 3.20812025-08-27 10:12:27.089550: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 192 bytes spill stores, 192 bytes spill loads\n",
            "\n",
            "\n",
            "Epoch 1: Calculating per-class training loss...\n",
            "  - Class 0: Loss = 2.6971\n",
            "  - Class 1: Loss = 3.4125\n",
            "  - Class 2: Loss = 2.6119\n",
            "  - Class 3: Loss = 3.3204\n",
            "  - Class 4: Loss = 3.2402\n",
            "  - Class 5: Loss = 3.3242\n",
            "  - Class 6: Loss = 3.7316\n",
            "  - Class 7: Loss = 4.0005\n",
            "  - Class 8: Loss = 3.3818\n",
            "2025-08-27 10:12:41.306227: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 192 bytes spill stores, 192 bytes spill loads\n",
            "\n",
            "  - Class 9: Loss = 3.5058\n",
            "  - Class 10: Loss = 2.8809\n",
            "  - Class 11: Loss = 2.9371\n",
            "  - Class 12: Loss = 3.4526\n",
            "  - Class 13: Loss = 3.1403\n",
            "  - Class 14: Loss = 4.0082\n",
            "  - Class 15: Loss = 2.7930\n",
            "  - Class 16: Loss = 3.4920\n",
            "  - Class 17: Loss = 3.0051\n",
            "  - Class 18: Loss = 3.1266\n",
            "2025-08-27 10:12:48.713824: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 192 bytes spill stores, 192 bytes spill loads\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 benchmark.py --hyperband --model mlp_4_layer --hb-max-epochs 20 --hb-final-epochs 30 --hb-batch-size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taiRS4YgoZIO",
        "outputId": "97f4f1f2-3f29-4b80-f4f2-face894fbaba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: mlp_analysis_results_20250826_220126/ (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "!zip \"mlp_4_layer_results_$(date +%Y%m%d_%H%M%S).zip\" *.zip\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copia lo zip in Drive\n",
        "!cp mlp_4_layer_results_* /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb0jAbNirKhJ"
      },
      "source": [
        "Esempi di utilizzo:\n",
        "\n",
        "  # 1. Eseguire un test rapido (smoke test) per verificare che tutto funzioni\n",
        "  python3 benchmark.py --smoke-test\n",
        "\n",
        "  # 2. Eseguire un singolo test con un modello specifico e dimensione del campione\n",
        "  python3 benchmark.py --model gru --sample-size 20000\n",
        "\n",
        "  # 3. Eseguire il benchmark completo su tutti i modelli e iperparametri di default\n",
        "  python3 benchmark.py --full\n",
        "\n",
        "  # 4. Eseguire il benchmark completo con una dimensione del campione personalizzata\n",
        "  python3 benchmark.py --full --sample-size 50000\n",
        "\n",
        "  # 5. Eseguire un singolo test specificando iperparametri custom (nota: devono essere nel formato atteso dal modulo di training)\n",
        "  python3 benchmark.py --model lstm --epochs 15 --batch-size 128 --learning-rate 0.0005\n",
        "        '''\n",
        "    )\n",
        "    \n",
        "    # Argomenti principali per la selezione della modalità\n",
        "    parser.add_argument('--smoke-test', action='store_true', help='Esegue uno smoke test veloce e leggero.')\n",
        "    parser.add_argument('--full', action='store_true', help='Esegue il benchmark completo su più modelli e iperparametri.')\n",
        "    \n",
        "    # Argomenti per la configurazione di base\n",
        "    parser.add_argument('--sample-size', type=int, help='Numero totale di campioni da utilizzare (BENIGN + ATTACK).')\n",
        "    parser.add_argument('--data-path', type=str, help='Path alla directory contenente i file CSV del dataset.')\n",
        "    parser.add_argument('--output-dir', type=str, default='benchmark_results', help='Directory per salvare i risultati.')\n",
        "\n",
        "    # Argomenti per la configurazione del modello (usati in test singoli o come override)\n",
        "    parser.add_argument('--model', choices=['dense', 'gru', 'lstm'], help='Tipo di modello da testare in un singolo run.')\n",
        "    parser.add_argument('--epochs', type=int, help=\"Override del numero di epoche per il training (es. 10).\")\n",
        "    parser.add_argument('--batch-size', type=int, help=\"Override della batch size per il training (es. 64).\")\n",
        "    parser.add_argument('--learning-rate', type=float, help=\"Override del learning rate (es. 0.001).\")\n",
        "    \n",
        "    args = parser.parse_args()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5aAuGCcrKhJ"
      },
      "source": [
        "## 3) Smoke test (GRU)\n",
        "Esegue pipeline ridotta per verificare fine-to-end: bilanciamento security, IP→ottetti, finestre, training GRU (K-Fold), valutazione con PNG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2VBtO0XrKhJ"
      },
      "outputs": [],
      "source": [
        "# Smoke test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Override per test rapido\n",
        "PREPROCESSING_CONFIG['sample_size'] = 3000\n",
        "TRAINING_CONFIG['model_type'] = 'gru'\n",
        "TRAINING_CONFIG['hyperparameters']['epochs'] = [2]\n",
        "TRAINING_CONFIG['hyperparameters']['batch_size'] = [32]\n",
        "\n",
        "X, y, label_encoder = preprocess_pipeline()\n",
        "model, log, model_path = train_model(X, y, model_type='gru')\n",
        "\n",
        "# Valutazione rapida\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "report = evaluate_model_comprehensive(model, X_te, y_te, class_names=label_encoder.classes_.tolist(), output_dir='notebook_eval/smoke')\n",
        "report['basic_metrics']['accuracy']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cebUrLi7rKhJ"
      },
      "source": [
        "## 4) Test completo (GRU) con finestre 5s, 1m, 5m e grid LR\n",
        "In questo test variamo:\n",
        "- finestre temporali: `window_size` e `step` coerenti con risoluzioni 5s, 1m, 5m\n",
        "- learning rate: `[1e-3, 5e-4, 1e-4]`\n",
        "- epoche moderate per tempi ragionevoli\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlQwN1EGrKhJ"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "results = []\n",
        "base_prep = deepcopy(PREPROCESSING_CONFIG)\n",
        "base_train = deepcopy(TRAINING_CONFIG)\n",
        "\n",
        "# Grid finestre (timesteps) e learning rate\n",
        "window_configs = [\n",
        "    {\"name\": \"5s\", \"window_size\": 10, \"step\": 5},\n",
        "    {\"name\": \"1m\", \"window_size\": 60//6, \"step\": 10},  # es: 10 step\n",
        "    {\"name\": \"5m\", \"window_size\": 50, \"step\": 10},\n",
        "]\n",
        "lr_grid = [1e-3, 5e-4, 1e-4]\n",
        "\n",
        "for wc in window_configs:\n",
        "    PREPROCESSING_CONFIG['use_time_windows'] = True\n",
        "    PREPROCESSING_CONFIG['window_size'] = wc['window_size']\n",
        "    PREPROCESSING_CONFIG['step'] = wc['step']\n",
        "\n",
        "    for lr in lr_grid:\n",
        "        TRAINING_CONFIG['model_type'] = 'gru'\n",
        "        TRAINING_CONFIG['hyperparameters']['epochs'] = [5]\n",
        "        TRAINING_CONFIG['hyperparameters']['batch_size'] = [64]\n",
        "        TRAINING_CONFIG['hyperparameters']['learning_rate'] = [lr]\n",
        "\n",
        "        print(f\"\\n=== Config: {wc['name']} | lr={lr} ===\")\n",
        "        X, y, le = preprocess_pipeline()\n",
        "        model, log, path = train_model(X, y, model_type='gru')\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "        rep = evaluate_model_comprehensive(model, X_te, y_te, le.classes_.tolist(), output_dir=f'notebook_eval/{wc[\"name\"]}_lr{lr}')\n",
        "        results.append({'window': wc['name'], 'lr': lr, 'accuracy': rep['basic_metrics']['accuracy']})\n",
        "\n",
        "# Ripristina config\n",
        "PREPROCESSING_CONFIG.update(base_prep)\n",
        "TRAINING_CONFIG.update(base_train)\n",
        "\n",
        "pd.DataFrame(results).sort_values('accuracy', ascending=False).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTFiaEtlrKhJ"
      },
      "source": [
        "## 5) Riproducibilità\n",
        "Impostiamo i seed per rendere i risultati ripetibili (entro i limiti dell'hardware).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFV-q5qsrKhJ"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print('Seed impostato:', SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIE5S_2CrKhJ"
      },
      "source": [
        "## 6) Audit dati e feature\n",
        "Controlliamo distribuzione classi, percentuali, e presenza di attacchi rilevanti nel sample selezionato.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtFFHYWprKhJ"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def audit_distribution(y, label_encoder):\n",
        "    counts = Counter(y)\n",
        "    classes = label_encoder.classes_.tolist()\n",
        "    dist = {classes[i]: int(counts.get(i, 0)) for i in range(len(classes))}\n",
        "    total = sum(dist.values())\n",
        "    df = pd.DataFrame({\n",
        "        'classe': list(dist.keys()),\n",
        "        'conteggio': list(dist.values())\n",
        "    }).sort_values('conteggio', ascending=False)\n",
        "    df['percentuale'] = (df['conteggio'] / total * 100).round(2)\n",
        "    return df\n",
        "\n",
        "# Esempio live (riutilizza X,y,label_encoder se esistono)\n",
        "try:\n",
        "    audit_distribution(y, label_encoder)\n",
        "except Exception as e:\n",
        "    print('Esegui prima il smoke test per generare X,y,label_encoder')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbcpRjz6rKhJ"
      },
      "source": [
        "## 7) Metriche e calibrazione\n",
        "Oltre alle metriche standard, aggiungiamo ECE (Expected Calibration Error) per valutare la calibrazione delle probabilità.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGFrgT4UrKhJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def expected_calibration_error(y_true, y_proba, n_bins=10):\n",
        "    # binning su max probability\n",
        "    confidences = y_proba.max(axis=1)\n",
        "    predictions = y_proba.argmax(axis=1)\n",
        "    accuracies = (predictions == y_true).astype(float)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
        "        if mask.any():\n",
        "            avg_conf = confidences[mask].mean()\n",
        "            avg_acc = accuracies[mask].mean()\n",
        "            ece += np.abs(avg_acc - avg_conf) * mask.mean()\n",
        "    return float(ece)\n",
        "\n",
        "# Esempio: usa il modello dallo smoke test, se disponibile\n",
        "try:\n",
        "    y_proba = model.predict(X_te, verbose=0)\n",
        "    print('ECE:', expected_calibration_error(y_te, y_proba, n_bins=15))\n",
        "except Exception as e:\n",
        "    print('Esegui prima smoke test e valutazione per avere y_te e y_proba')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZbXz9JirKhJ"
      },
      "source": [
        "## 8) Documentazione file-per-file\n",
        "In questa sezione spieghiamo le scelte implementative nei file chiave: `preprocessing/process.py`, `training/train.py`, `evaluation/metrics.py`, `benchmark.py` e `config.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1Do7VN5rKhJ"
      },
      "outputs": [],
      "source": [
        "import inspect, textwrap\n",
        "import preprocessing.process as P\n",
        "import training.train as T\n",
        "import evaluation.metrics as E\n",
        "import benchmark as B\n",
        "import config as C\n",
        "\n",
        "def show_source(obj, start=None, end=None):\n",
        "    src = inspect.getsource(obj)\n",
        "    if start or end:\n",
        "        lines = src.splitlines()\n",
        "        src = \"\\n\".join(lines[start:end])\n",
        "    print(textwrap.dedent(src))\n",
        "\n",
        "print('--- config.py (sezioni principali) ---')\n",
        "print('DATA_CONFIG:'); print(C.DATA_CONFIG)\n",
        "print('\\nPREPROCESSING_CONFIG:'); print(C.PREPROCESSING_CONFIG)\n",
        "print('\\nTRAINING_CONFIG:'); print(C.TRAINING_CONFIG)\n",
        "\n",
        "print('\\n--- preprocessing.process: load_and_balance_dataset ---')\n",
        "show_source(P.load_and_balance_dataset)\n",
        "print('\\n--- preprocessing.process: preprocess_pipeline ---')\n",
        "show_source(P.preprocess_pipeline)\n",
        "\n",
        "print('\\n--- training.train: _train_k_fold ---')\n",
        "show_source(T._train_k_fold)\n",
        "print('\\n--- training.train: _train_split ---')\n",
        "show_source(T._train_split)\n",
        "\n",
        "print('\\n--- evaluation.metrics: evaluate_model_comprehensive ---')\n",
        "show_source(E.evaluate_model_comprehensive)\n",
        "\n",
        "print('\\n--- benchmark.SNNIDSBenchmark (run_smoke_test) ---')\n",
        "show_source(B.SNNIDSBenchmark.run_smoke_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAqowqpUrKhK"
      },
      "source": [
        "### Note progettuali\n",
        "- Zero hard-code: tutte le scelte sono in `config.py`; il notebook applica override solo per esperimenti.\n",
        "- Pipeline riproducibile: sampling e bilanciamento documentati; seed fissati.\n",
        "- Training recipe tabulari: GRU su finestre 3D, scaling per-fold, StratifiedKFold.\n",
        "- Metriche e PNG: confusion matrix dettagliata, cybersecurity, ROC, accuracy per classe, ECE.\n",
        "- Notebook auditabile: usa `inspect` per mostrare il codice sorgente eseguito.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8o7B-9mrKhK"
      },
      "source": [
        "## 9) Limitazioni\n",
        "- I risultati su classi rare vanno interpretati con cautela; forniamo sempre breakdown per‑classe.\n",
        "- La calibrazione (ECE) è informativa ma non esaustiva.\n",
        "- Il bilanciamento “security” riduce bias ma non sostituisce protocolli di acquisizione realistici.\n",
        "- Evitiamo leakage scalando per‑fold; ulteriori audit sono comunque consigliati in ambienti operativi.\n",
        "- Per produzione sono necessarie valutazioni cost‑sensitive e monitoraggio del drift.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPbtUaf0rKhK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggiornamento: Seeding centralizzato e riproducibilità\n",
        "Questa sezione integra il notebook mantenendo intatti i blocchi precedenti.\n",
        "\n",
        "- Il seed unico del progetto è definito in `config.py` come `RANDOM_CONFIG['seed']` (default: 79).\n",
        "- Per massimizzare la riproducibilità, usiamo `set_global_seed(SEED)` che imposta i seed per Python, NumPy e TensorFlow.\n",
        "- Per `random_state` in Scikit‑Learn (es. `KFold`, `StratifiedKFold`, `train_test_split`), usare sempre il seed da config.\n",
        "\n",
        "Le celle successive impostano il seed centralizzato da usare in tutto il notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importa config e utility di seeding dal repository\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Aggiunge il project root al sys.path se serve\n",
        "ROOT = Path.cwd()\n",
        "if (ROOT / 'config.py').exists():\n",
        "    sys.path.append(str(ROOT))\n",
        "\n",
        "from config import RANDOM_CONFIG\n",
        "from src.utils import set_global_seed\n",
        "\n",
        "SEED = int(RANDOM_CONFIG.get('seed', 79))\n",
        "set_global_seed(SEED)\n",
        "\n",
        "# Mantiene a disposizione una variabile RS da usare come random_state Sklearn\n",
        "RS = SEED\n",
        "RS\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
