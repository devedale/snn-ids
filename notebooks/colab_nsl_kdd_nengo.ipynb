{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SNN (Nengo/NengoDL) su NSL-KDD — Colab\n",
        "\n",
        "Notebook end-to-end: download NSL-KDD, preprocessing, rete Nengo con neuroni LIF, training con NengoDL, valutazione e salvataggio parametri.\n",
        "\n",
        "- Framework: Nengo + NengoDL (TensorFlow backend)\n",
        "- Codifica: rate coding (ripetizione su T step)\n",
        "- Task: binaria (anomalo vs normale)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installazione dipendenze Nengo/NengoDL\n",
        "!pip -q install nengo nengo-dl pandas scikit-learn pyyaml\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download NSL-KDD (train/test)\n",
        "base = Path('/content/data'); base.mkdir(parents=True, exist_ok=True)\n",
        "urls = {\n",
        "    'KDDTrain+': 'https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt',\n",
        "    'KDDTest+':  'https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest+.txt',\n",
        "}\n",
        "for name, url in urls.items():\n",
        "    !wget -q -O /content/data/{name}.txt \"{url}\"\n",
        "!ls -lh /content/data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing NSL-KDD\n",
        "cols = [\n",
        "  \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\n",
        "  \"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "  \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\n",
        "  \"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "  \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\"dst_host_same_srv_rate\",\n",
        "  \"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
        "  \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty\"\n",
        "]\n",
        "\n",
        "def load_split(split):\n",
        "  df = pd.read_csv(f\"/content/data/{split}.txt\", names=cols)\n",
        "  df.drop(columns=[\"difficulty\"], inplace=True, errors=\"ignore\")\n",
        "  return df\n",
        "\n",
        "train_df, test_df = load_split(\"KDDTrain+\"), load_split(\"KDDTest+\")\n",
        "\n",
        "y_train = (train_df[\"label\"] != \"normal\").astype(int).values\n",
        "y_test  = (test_df[\"label\"]  != \"normal\").astype(int).values\n",
        "X_train_df = train_df.drop(columns=[\"label\"])\n",
        "X_test_df  = test_df.drop(columns=[\"label\"])\n",
        "\n",
        "cat_cols = [\"protocol_type\",\"service\",\"flag\"]\n",
        "num_cols = [c for c in X_train_df.columns if c not in cat_cols]\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_num = scaler.fit_transform(X_train_df[num_cols].values.astype(float))\n",
        "X_test_num  = scaler.transform(X_test_df[num_cols].values.astype(float))\n",
        "\n",
        "X_train_cat = pd.get_dummies(X_train_df[cat_cols].astype(str)).values\n",
        "X_test_cat  = pd.get_dummies(X_test_df[cat_cols].astype(str)).reindex(\n",
        "    columns=pd.get_dummies(X_train_df[cat_cols].astype(str)).columns, fill_value=0\n",
        ").values\n",
        "\n",
        "X_train = np.hstack([X_train_num, X_train_cat]).astype(np.float32)\n",
        "X_test  = np.hstack([X_test_num,  X_test_cat]).astype(np.float32)\n",
        "input_size, output_size = X_train.shape[1], 2\n",
        "X_train.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Costruzione rete Nengo e training con NengoDL\n",
        "import nengo, nengo_dl, tensorflow as tf\n",
        "\n",
        "timesteps = 10\n",
        "with nengo.Network() as net:\n",
        "  inp = nengo.Node(np.zeros(input_size))\n",
        "  ens1 = nengo.Ensemble(n_neurons=256, dimensions=input_size, neuron_type=nengo.LIF())\n",
        "  nengo.Connection(inp, ens1)\n",
        "  ens2 = nengo.Ensemble(n_neurons=output_size, dimensions=output_size, neuron_type=nengo.LIF())\n",
        "  nengo.Connection(ens1, ens2)\n",
        "  p_out = nengo.Probe(ens2, synapse=0.1)\n",
        "\n",
        "# rate coding per NengoDL: ripeti features su T\n",
        "X_train_enc = np.repeat(X_train[:, None, :], timesteps, axis=1)\n",
        "X_test_enc  = np.repeat(X_test[:,  None, :], timesteps, axis=1)\n",
        "y_train_oh = tf.keras.utils.to_categorical(y_train, num_classes=output_size)\n",
        "y_test_oh  = tf.keras.utils.to_categorical(y_test,  num_classes=output_size)\n",
        "y_train_enc = np.repeat(y_train_oh[:, None, :], timesteps, axis=1)\n",
        "y_test_enc  = np.repeat(y_test_oh[:,  None, :], timesteps, axis=1)\n",
        "\n",
        "minibatch = 128\n",
        "with nengo_dl.Simulator(net, minibatch_size=minibatch) as sim:\n",
        "  # input mapping: primo input del modello → X\n",
        "  inputs = {inp: X_train_enc}\n",
        "  targets = {p_out: y_train_enc}\n",
        "  sim.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=tf.keras.losses.MSE)\n",
        "  sim.fit(inputs, targets, epochs=5, validation_split=0.2, verbose=2)\n",
        "  # valutazione\n",
        "  test_dict = {inp: X_test_enc}\n",
        "  sim.run_steps(X_test_enc.shape[1], data=test_dict)\n",
        "  out = sim.data[p_out]\n",
        "\n",
        "pred = out.mean(axis=1)\n",
        "acc = (pred.argmax(axis=1) == y_test).mean()\n",
        "print('Test accuracy:', acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvataggio artefatti (parametri rete)\n",
        "import pickle, os\n",
        "os.makedirs('/content/out', exist_ok=True)\n",
        "with open('/content/out/nengo_nslkdd.pkl', 'wb') as f:\n",
        "  pickle.dump(net, f)\n",
        "print('Salvato /content/out/nengo_nslkdd.pkl')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
