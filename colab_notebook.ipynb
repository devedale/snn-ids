{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Ambiente di Lavoro\n",
    "\n",
    "Prima di tutto, è **necessario** configurare l'ambiente di lavoro. La cella seguente clonerà il repository GitHub contenente tutti i moduli Python (`.py`) e si posizionerà nella directory corretta. \n",
    "\n",
    "**Esegui questa cella come primo passo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clona il repository e posizionati nella directory corretta\n",
    "# NOTA: Assicurati che l'URL del repository e il nome del branch siano corretti.\n",
    "!git clone https://github.com/devedale/snn-ids.git snn-ids\n",
    "%cd snn-ids\n",
    "# Assicurati di usare il nome del branch corretto.\n",
    "!git checkout feat/modular-ml-pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline ML Avanzata per Cybersecurity: Guida Completa\n",
    "\n",
    "Questo notebook è una guida interattiva a una pipeline di machine learning **avanzata** per l'analisi di traffico di rete. Oltre a una struttura modulare, include funzionalità specifiche per dati sequenziali e strategie di validazione robuste.\n",
    "\n",
    "**Funzionalità Chiave:**\n",
    "- **Finestre Temporali**: I dati non vengono trattati come eventi isolati, ma come sequenze (finestre temporali), permettendo a modelli come gli LSTM di catturare pattern nel tempo.\n",
    "- **Validazione K-Fold**: Invece di una singola divisione train/test, usiamo la validazione incrociata (K-Fold) per una stima più robusta e affidabile della performance del modello.\n",
    "- **Architettura Configurabile**: Puoi scegliere tra diversi tipi di modelli (es. `dense` vs `lstm`) direttamente dal file di configurazione.\n",
    "- **Massima Configurabilità**: Ogni aspetto, dalla dimensione della finestra alla strategia di validazione, è controllato dal file `config.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Architettura e Scelte Tecniche\n",
    "\n",
    "La pipeline è composta dai seguenti elementi:\n",
    "\n",
    "- `create_synthetic_data.py`: Uno script per generare dati di esempio realistici.\n",
    "- `config.py`: Il cuore della configurazione. Qui si definiscono i percorsi, le colonne da usare e gli iperparametri per il training.\n",
    "- `preprocessing/process.py`: Contiene tutta la logica per caricare i dati e trasformarli in un formato numerico che il modello può comprendere.\n",
    "- `training/train.py`: Gestisce la creazione del modello, la grid search e il salvataggio del modello più performante.\n",
    "- `prediction/predict.py`: Carica un modello salvato e lo usa per fare predizioni su nuovi dati.\n",
    "\n",
    "**Librerie Utilizzate:**\n",
    "- **Pandas**: Per la manipolazione efficiente dei dati.\n",
    "- **Scikit-learn**: Per utility di preprocessing e strategie di validazione come K-Fold.\n",
    "- **TensorFlow (Keras)**: Come framework di deep learning, scelto per la sua flessibilità e potenza.\n",
    "- **Faker**: Per generare dati fittizi ma realistici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Iniziale\n",
    "\n",
    "Installiamo le librerie necessarie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installa le dipendenze\n",
    "!pip install pandas scikit-learn tensorflow faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analisi del File di Configurazione (`config.py`)\n",
    "\n",
    "Prima di iniziare, diamo un'occhiata alle nuove potenti opzioni che abbiamo introdotto in `config.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PREPROCESSING_CONFIG`\n",
    "- `use_time_windows` (bool): Se `True`, la pipeline trasforma i dati in sequenze. Essenziale per modelli come LSTM.\n",
    "- `window_size` (int): Il numero di eventi (righe) in ogni sequenza/finestra. Una finestra più grande cattura pattern a lungo termine, ma richiede più memoria.\n",
    "- `step` (int): Di quanti eventi si sposta la finestra. Se `step < window_size`, le finestre si sovrappongono, generando più dati di training e aiutando il modello a imparare transizioni fluide.\n",
    "\n",
    "### `TRAINING_CONFIG`\n",
    "- `validation_strategy` (str): Scegli come validare il modello.\n",
    "  - `'train_test_split'`: Veloce, ma meno affidabile. Divide i dati una sola volta.\n",
    "  - `'k_fold'`: Più robusto. Divide i dati `k` volte, addestrando e testando il modello su ogni divisione per ottenere una media delle performance. Ideale per avere una stima realistica delle prestazioni.\n",
    "- `k_fold_splits` (int): Il numero di `k` (folds) da usare.\n",
    "- `model_type` (str): Scegli l'architettura.\n",
    "  - `'lstm'`: Una Rete Neurale Ricorrente, perfetta per dati sequenziali (le nostre finestre temporali).\n",
    "  - `'dense'`: Una rete neurale standard. Richiede che `use_time_windows` sia `False` o che i dati vengano appiattiti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Esecuzione della Pipeline Avanzata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 1: Generazione Dati con Timestamp\n",
    "Eseguiamo lo script per creare dati sintetici, ora con una colonna `timestamp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_synthetic_data import generate_synthetic_data\n",
    "generate_synthetic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 2: Preprocessing in Finestre Temporali\n",
    "Eseguiamo il preprocessing. Notare la shape 3D dell'output `X`, che è `(numero_di_finestre, dimensione_finestra, numero_feature)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.process import preprocess_data\n",
    "\n",
    "X, y = preprocess_data()\n",
    "\n",
    "if X is not None:\n",
    "    print(\"\\n--- Dati Processati ---\")\n",
    "    print(f\"Shape di X: {X.shape}\")\n",
    "    print(f\"Shape di y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 3: Training con K-Fold e LSTM\n",
    "Eseguiamo il training usando le strategie definite in `config.py` (di default, K-Fold e LSTM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import train_and_evaluate\n",
    "\n",
    "_, _ = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 4: Predizione su una Finestra di Dati\n",
    "Per fare una predizione, ora dobbiamo fornire un'intera finestra di dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction.predict import predict_on_window\n",
    "from config import PREPROCESSING_CONFIG\n",
    "\n",
    "# Creiamo una finestra di dati fittizia\n",
    "window_size = PREPROCESSING_CONFIG.get('window_size', 10)\n",
    "sample_window = [\n",
    "    {\n",
    "        \"ip_sorgente\": \"192.168.1.10\", \"ip_destinazione\": \"10.0.0.5\",\n",
    "        \"porta_sorgente\": 12345, \"porta_destinazione\": 443,\n",
    "        \"protocollo\": \"UDP\", \"byte_inviati\": 250, \"byte_ricevuti\": 1800\n",
    "    } for _ in range(window_size)\n",
    "]\n",
    "\n",
    "prediction_label = predict_on_window(sample_window)\n",
    "\n",
    "if prediction_label:\n",
    "    print(f\"\\nRISULTATO FINALE: La finestra di dati è stata classificata come: '{prediction_label}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Guida all'Estensione e Personalizzazione\n",
    "\n",
    "La forza di questa architettura è la facilità con cui puoi usarla per i tuoi dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passaggio 1: Aggiorna `config.py`\n",
    "\n",
    "Immagina di avere un nuovo dataset `my_traffic.csv` con le seguenti colonne: `['Timestamp', 'SourceIP', 'DestIP', 'SourcePort', 'DestPort', 'ProtocolType', 'PacketCount', 'TrafficType']`.\n",
    "\n",
    "Per adattare la pipeline, dovrai modificare `DATA_CONFIG` in `config.py` così:\n",
    "\n",
    "```python\n",
    "DATA_CONFIG = {\n",
    "    \"dataset_path\": \"data/my_traffic.csv\",\n",
    "    \"timestamp_column\": \"Timestamp\",\n",
    "    \"feature_columns\": [\"SourcePort\", \"DestPort\", \"ProtocolType\", \"PacketCount\"],\n",
    "    \"ip_columns_to_anonymize\": [\"SourceIP\", \"DestIP\"],\n",
    "    \"target_column\": \"TrafficType\",\n",
    "}\n",
    "```\n",
    "**Fatto!** Eseguendo di nuovo il notebook o gli script, la pipeline userà automaticamente il tuo nuovo dataset e le tue colonne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passaggio 2: Creare Nuove Feature (Feature Engineering)\n",
    "\n",
    "Spesso, le feature migliori non sono quelle originali, ma quelle che creiamo noi. Immaginiamo di voler creare una feature `is_well_known_port` che è `1` se la porta di destinazione è una porta comune (es. 80, 443) e `0` altrimenti.\n",
    "\n",
    "Puoi farlo modificando leggermente `preprocessing/process.py`:\n",
    "\n",
    "1. Apri `preprocessing/process.py`.\n",
    "2. Trova la sezione dove viene caricato il DataFrame `df`.\n",
    "3. **Aggiungi il tuo codice** per creare la nuova colonna, prima che le feature vengano assemblate in `X`.\n",
    "\n",
    "```python\n",
    "# Esempio da aggiungere in process.py dopo il caricamento di df\n",
    "\n",
    "well_known_ports = [80, 443, 22, 21, 53]\n",
    "df['is_well_known_port'] = df['porta_destinazione'].isin(well_known_ports).astype(int)\n",
    "```\n",
    "\n",
    "4. Infine, **aggiorna `config.py`** per includere la tua nuova feature nella lista `feature_columns`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
