{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IDS Pipeline Audit: Preprocessing avanzato e Training\n",
        "\n",
        "Questa sezione documenta dettagliatamente le scelte progettuali e operative per:\n",
        "- **Flow reassembly** e **sessionizzazione** (timeout configurabile)\n",
        "- **Finestre N/T** attorno al primo evento malevolo per `Flow_ID`\n",
        "- **Label propagation** con modalità configurabile (any/majority/probabilistica/smoothing)\n",
        "- **Noise handling** tramite majority/temporal smoothing\n",
        "- **Dataset balancing** a livello di flusso (undersampling/SMOTE)\n",
        "- **Output** per modelli sequenziali e MLP aggregato\n",
        "- **Supporto training** con MLP 4 layer e logging delle loss\n",
        "\n",
        "Tutte le funzioni sono eseguibili da **comandi** (no Python inline), per favorire riproducibilità e tracciabilità.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Struttura della pipeline (overview)\n",
        "\n",
        "- **Input**: CSV con campi `Flow_ID`, `Timestamp`, `Label` (es. `BENIGN` o altro)\n",
        "- **Reassembly & Sessionizzazione**: raggruppa per `Flow_ID` e separa in `Session_ID` con timeout (default 60s)\n",
        "- **Noise filtering**: smoothing/majority sulle etichette temporali\n",
        "- **Finestra N/T**: per ogni `Session_ID`, crea una finestra centrata sul primo evento malevolo con `N` secondi prima e `T` dopo\n",
        "- **Aggregazione**: in bin temporali (e.g., 5s) per sequenze; oppure aggregazione globale per MLP\n",
        "- **Label propagation**: se la finestra contiene almeno un malevolo (o secondo strategia), etichetta la finestra come malevola\n",
        "- **Bilanciamento**: seleziona tutte le sessioni malevole e un ugual numero di `BENIGN` (undersample) o usa SMOTE\n",
        "- **Output**: salva `X.npy` e `y.npy` o shard per-epoca per training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parametri configurabili (config.py)\n",
        "\n",
        "- **Dataset**:\n",
        "  - `DATA_CONFIG.dataset_path`, `timestamp_column`, `flow_id_column`, `target_column`, `benign_label`, `timestamp_format`\n",
        "- **Sessionizzazione**:\n",
        "  - `PREPROCESSING_CONFIG.session_timeout_seconds`\n",
        "- **Finestre**:\n",
        "  - `flow_window_strategy` (e.g., `first_malicious_context`)\n",
        "  - `window_before_first_malicious_s` (N), `window_after_first_malicious_s` (T)\n",
        "  - `time_bin_seconds` (granularità per sequenze)\n",
        "- **Label propagation / Noise**:\n",
        "  - `label_propagation.mode` (`any`/`majority`/`probabilistic`/`smoothing`)\n",
        "  - `prob_threshold`, `smoothing_alpha`\n",
        "  - `noise_filter.enabled`, `noise_filter.method`, `noise_filter.window`, `noise_filter.threshold`\n",
        "- **Bilanciamento a flusso**:\n",
        "  - `flow_balance.enabled`, `flow_balance.method` (`undersample`/`smote`/`none`), `flow_balance.ratio`\n",
        "- **Output**:\n",
        "  - `output_mode` (`sequence`/`mlp_aggregated`), `aggregation_stats`\n",
        "- **Training**:\n",
        "  - `model_type`, `mlp_hidden_layers`, `dropout_rate`, `hyperparameters.epochs/batch_size/learning_rate`, `max_epochs`\n",
        "  - `preprocess_per_epoch`, `flows_per_epoch`, `epoch_selection_mode`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Esecuzione preprocessing (solo comandi)\n",
        "\n",
        "1) Installare dipendenze\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "2) Verifica/adegua `config.py` (path dataset, colonne, parametri)\n",
        "\n",
        "3) Esegui preprocessing completo\n",
        "```bash\n",
        "python -m preprocessing.process | cat\n",
        "```\n",
        "\n",
        "- Output: `models/preprocessed/X.npy`, `models/preprocessed/y.npy`\n",
        "- Se `preprocess_per_epoch=True`: `models/preprocessed/X_epoch_XXX.npy`, `y_epoch_XXX.npy`\n",
        "\n",
        "4) Parametri chiave da ricordare\n",
        "- `session_timeout_seconds`, `window_before_first_malicious_s`, `window_after_first_malicious_s`, `time_bin_seconds`\n",
        "- `label_propagation.mode`, `noise_filter.*`\n",
        "- `flow_balance.method`, `flow_balance.ratio`\n",
        "- `output_mode` (`sequence` vs `mlp_aggregated`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Esecuzione training (solo comandi)\n",
        "\n",
        "1) Seleziona modello\n",
        "- `TRAINING_CONFIG.model_type`: `gru`, `lstm`, `dense`\n",
        "- Se `X.npy` è 2D (MLP aggregato), la CLI forza `dense`\n",
        "\n",
        "2) Avvia training\n",
        "```bash\n",
        "python -m training.train | cat\n",
        "```\n",
        "\n",
        "- Salvataggi:\n",
        "  - Modello: `models/best_model.keras`\n",
        "  - Log configurazioni: `models/training_log.json`\n",
        "  - Storico loss/accuracy per epoca: `models/training_history.json`\n",
        "\n",
        "3) Epoche e loss\n",
        "- Fino a `max_epochs=30`\n",
        "- Tracciamento `loss`/`val_loss` per analisi convergenza\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Considerazioni progettuali e trade-off\n",
        "\n",
        "- **Sessionizzazione**: separa conversazioni distinte sullo stesso `Flow_ID` per evitare leakage temporale.\n",
        "- **N/T finestra**: simula detection realistiche (contesto pre-attacco e persistenza post-detection). Importante per ridurre falsi positivi.\n",
        "- **Label propagation**: modalità `any` garantisce recall, `majority` bilancia precision/recall, `probabilistic` consente soglia adattiva, `smoothing` robusto a label rumorose.\n",
        "- **Bilanciamento a flusso**: evitare che pochi attacchi dominino; `undersample` è stabile, `SMOTE` richiede feature aggregate per sessione.\n",
        "- **Output**: `sequence` utile per RNN/GRU/LSTM; `mlp_aggregated` per MLP rapido con statistiche robuste.\n",
        "- **Robustezza a label imperfette**: smoothing temporale e majority voting mitigano errori di annotazione.\n",
        "- **Per-epoca**: shard per allenare in sequenza o parallelo sottinsiemi di flussi.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deep dive: Sessionizzazione e reassembly\n",
        "\n",
        "- Obiettivo: ricostruire conversazioni coerenti gestendo discontinuità temporali sullo stesso `Flow_ID`.\n",
        "- Algoritmo:\n",
        "  - Ordina per `Flow_ID` e `Timestamp`.\n",
        "  - Avvia `Session_Index=0` al primo record; incrementa l'indice quando l'intervallo tra record successivi supera `session_timeout_seconds`.\n",
        "  - Costruisci `Session_ID = Flow_ID#Session_Index`.\n",
        "- Proprietà:\n",
        "  - Complessità lineare O(N) dopo ordinamento.\n",
        "  - Resiliente a timestamp mancanti: avvia una nuova sessione quando il timestamp non è valido.\n",
        "- Rischi/Pitfall:\n",
        "  - Timeout troppo corto frammenta sessioni; troppo lungo fonde conversazioni distinte.\n",
        "  - Assicurare la normalizzazione del fuso e il parsing coerente dei timestamp (`timestamp_format` se necessario).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deep dive: Noise handling (majority & temporal smoothing)\n",
        "\n",
        "- Majority window: media mobile della variabile binaria `is_malicious`; soglia `threshold` decide la classe.\n",
        "- Temporal smoothing (EMA): `s_t = alpha * x_t + (1 - alpha) * s_{t-1}` con `alpha` in `(0,1]`.\n",
        "  - `alpha` alto reagisce più velocemente ma è più sensibile al rumore; `alpha` basso è più stabile.\n",
        "- Applicazione per sessione: evita bleed-over tra flussi diversi.\n",
        "- Effetti:\n",
        "  - Riduce flip sporadici delle etichette.\n",
        "  - Utile con dataset reali con labeling non perfetto o delay di annotazione.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deep dive: Label propagation (any/majority/probabilistica/smoothing)\n",
        "\n",
        "- any: recall massimo; finestra = malevola se presente QUALSIASI evento malevolo.\n",
        "- majority: trade-off; richiede >50% eventi malevoli nella finestra.\n",
        "- probabilistica: imposta soglia `prob_threshold` (es. 0.3, 0.5, 0.7) sulla frazione di eventi malevoli.\n",
        "- smoothing: usa output filtrato (EMA/majority) e poi majority \"soft\" per la finestra.\n",
        "- Scelta operativa:\n",
        "  - In ambienti ad alto rischio → preferire `any` o soglia bassa.\n",
        "  - Per ridurre falsi positivi in produzione → `majority` o `smoothing`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deep dive: Finestre N/T e binning temporale\n",
        "\n",
        "- Strategia `first_malicious_context`:\n",
        "  - Trova il primo timestamp malevolo nella sessione.\n",
        "  - Crea una finestra da `N` secondi prima a `T` secondi dopo.\n",
        "- Binning:\n",
        "  - Discretizza la finestra in intervalli di `time_bin_seconds` (es. 5s).\n",
        "  - Aggrega le feature per bin per costruire sequenze temporali regolari.\n",
        "- Mancanza di eventi in un bin:\n",
        "  - Il bin risulta zero o con statistiche neutre; il padding finale uniforma le lunghezze.\n",
        "- Allineamento:\n",
        "  - Base temporale = minimo timestamp della finestra per robustezza.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deep dive: Aggregazioni statistiche e feature engineering\n",
        "\n",
        "- Statistiche per bin/finestra: `sum`, `mean`, `std`, `min`, `max`.\n",
        "- Perché:\n",
        "  - `sum` e `mean` catturano intensità media; `std` quantifica variabilità; `min/max` estremi utili per burst.\n",
        "- Estensioni possibili (future):\n",
        "  - Entropia di porte/destinazioni IP per finestra; tassi di errore; inter-arrival variance robusta.\n",
        "  - Indicatori di burst (peak-to-average ratio), code di coda (kurtosi) per anomalia.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bilanciamento a livello di flusso\n",
        "\n",
        "- Definizione di finestra/Session come unità di campionamento.\n",
        "- `undersample`: seleziona tutte le sessioni malevole + sottoinsieme di `BENIGN` fino a parità (configurabile via `ratio`).\n",
        "- `SMOTE`: richiede rappresentazione tabellare per sessione (aggregate), poi genera campioni sintetici nello spazio feature.\n",
        "- Considerazioni:\n",
        "  - `SMOTE` su feature aggregate preserva statistiche di finestra ma non la cronologia di pacchetti.\n",
        "  - Alternativa avanzata: ADASYN o SMOTE-NC per misti cat/num.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comandi utili di audit e ispezione artefatti\n",
        "\n",
        "- Verifica artefatti preprocessing\n",
        "```bash\n",
        "ls -lh models/preprocessed | cat\n",
        "```\n",
        "\n",
        "- Ispeziona dimensioni dei file NPY (solo comandi)\n",
        "```bash\n",
        "for f in models/preprocessed/*.npy; do python -c \"import numpy as np, sys; a=np.load(sys.argv[1], allow_pickle=False); print(sys.argv[1], a.shape)\" \"$f\"; done | cat\n",
        "```\n",
        "\n",
        "- Installa jq (se mancante) e visualizza log/history\n",
        "```bash\n",
        "sudo apt-get update && sudo apt-get install -y jq\n",
        "jq '.' models/training_log.json | head -n 50 | cat\n",
        "jq '.' models/training_history.json | head -n 80 | cat\n",
        "```\n",
        "\n",
        "- Pulizia artefatti\n",
        "```bash\n",
        "rm -f models/preprocessed/*.npy models/best_model.keras models/training_*.json\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training per-epoca con shard\n",
        "\n",
        "Se `TRAINING_CONFIG.preprocess_per_epoch=True`, il preprocessing salva shard `X_epoch_XXX.npy` e `y_epoch_XXX.npy`.\n",
        "\n",
        "- Esempio di training sequenziale per shard (solo comandi)\n",
        "```bash\n",
        "for xp in models/preprocessed/X_epoch_*.npy; do \n",
        "  yp=${xp/X_epoch_/y_epoch_}\n",
        "  echo \"== Training su $xp ==\"\n",
        "  # sostituisci i file full con shard correnti\n",
        "  cp \"$xp\" models/preprocessed/X.npy\n",
        "  cp \"$yp\" models/preprocessed/y.npy\n",
        "  python -m training.train | cat\n",
        "done\n",
        "```\n",
        "\n",
        "- Esempio di ispezione prestazioni cumulative (placeholder, solo aggregazione file)\n",
        "```bash\n",
        "cat models/training_log.json | wc -l\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SNN-IDS Audit Notebook (CSE-CIC-IDS2018)\n",
        "\n",
        "Questo notebook è pensato per essere auditabile: ogni scelta è documentata file-per-file e riga-per-riga dove rilevante. Include:\n",
        "- Setup ambiente e dati\n",
        "- Pipeline dati riproducibile\n",
        "- Training recipe ottimizzata per tabulari (GRU per finestre temporali)\n",
        "- Metriche e calibrazione\n",
        "- Smoke test e test completo (finestre: 5s, 1m, 5m; LR grid)\n",
        "\n",
        "Note: il codice vive nel repository; il notebook chiama le funzioni senza duplicazioni di logica.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup ambiente\n",
        "\n",
        "Requisiti minimi:\n",
        "- Python 3.10+\n",
        "- pacchetti: pandas, numpy, scikit-learn, tensorflow, matplotlib, seaborn, tqdm\n",
        "\n",
        "In Colab eseguire le celle seguenti; in locale assicurarsi che `pip install -r requirements.txt` sia stato eseguito.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Se sei in Colab, decommenta le righe seguenti\n",
        "!git clone https://github.com/devedale/snn-ids.git\n",
        "%cd snn-ids\n",
        "!pip install -q pandas numpy scikit-learn tensorflow matplotlib seaborn tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Setup dati\n",
        "Scarica i CSV CSE-CIC-IDS2018 nelle cartelle già attese da `config.py` (`data/cicids/2018`). In Colab puoi caricare dal tuo Drive o usare Kaggle API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p Downloads\n",
        "!curl -L -o ./Downloads/improved-cicids2017-and-csecicids2018.zip  https://www.kaggle.com/api/v1/datasets/download/ernie55ernie/improved-cicids2017-and-csecicids2018\n",
        "!unzip -o ./Downloads/improved-cicids2017-and-csecicids2018.zip  \"CSECICIDS2018_improved/Tuesday-20-02-2018.csv\"   \"CSECICIDS2018_improved/Wednesday-21-02-2018.csv\"  \"CSECICIDS2018_improved/Thursday-22-02-2018.csv\" \"CSECICIDS2018_improved/Friday-23-02-2018.csv\" -d ./data\n",
        "\n",
        "# Importa librerie del progetto\n",
        "import os, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from config import DATA_CONFIG, PREPROCESSING_CONFIG, TRAINING_CONFIG, BENCHMARK_CONFIG\n",
        "from preprocessing.process import preprocess_pipeline\n",
        "from training.train import train_model\n",
        "from evaluation.metrics import evaluate_model_comprehensive\n",
        "\n",
        "print(\"Config dataset:\", DATA_CONFIG[\"dataset_path\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Smoke test (GRU)\n",
        "Esegue pipeline ridotta per verificare fine-to-end: bilanciamento security, IP→ottetti, finestre, training GRU (K-Fold), valutazione con PNG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Smoke test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Override per test rapido\n",
        "PREPROCESSING_CONFIG['sample_size'] = 3000\n",
        "TRAINING_CONFIG['model_type'] = 'gru'\n",
        "TRAINING_CONFIG['hyperparameters']['epochs'] = [2]\n",
        "TRAINING_CONFIG['hyperparameters']['batch_size'] = [32]\n",
        "\n",
        "X, y, label_encoder = preprocess_pipeline()\n",
        "model, log, model_path = train_model(X, y, model_type='gru')\n",
        "\n",
        "# Valutazione rapida\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "report = evaluate_model_comprehensive(model, X_te, y_te, class_names=label_encoder.classes_.tolist(), output_dir='notebook_eval/smoke')\n",
        "report['basic_metrics']['accuracy']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Test completo (GRU) con finestre 5s, 1m, 5m e grid LR\n",
        "In questo test variamo:\n",
        "- finestre temporali: `window_size` e `step` coerenti con risoluzioni 5s, 1m, 5m\n",
        "- learning rate: `[1e-3, 5e-4, 1e-4]`\n",
        "- epoche moderate per tempi ragionevoli\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "results = []\n",
        "base_prep = deepcopy(PREPROCESSING_CONFIG)\n",
        "base_train = deepcopy(TRAINING_CONFIG)\n",
        "\n",
        "# Grid finestre (timesteps) e learning rate\n",
        "window_configs = [\n",
        "    {\"name\": \"5s\", \"window_size\": 10, \"step\": 5},\n",
        "    {\"name\": \"1m\", \"window_size\": 60//6, \"step\": 10},  # es: 10 step \n",
        "    {\"name\": \"5m\", \"window_size\": 50, \"step\": 10},\n",
        "]\n",
        "lr_grid = [1e-3, 5e-4, 1e-4]\n",
        "\n",
        "for wc in window_configs:\n",
        "    PREPROCESSING_CONFIG['use_time_windows'] = True\n",
        "    PREPROCESSING_CONFIG['window_size'] = wc['window_size']\n",
        "    PREPROCESSING_CONFIG['step'] = wc['step']\n",
        "    \n",
        "    for lr in lr_grid:\n",
        "        TRAINING_CONFIG['model_type'] = 'gru'\n",
        "        TRAINING_CONFIG['hyperparameters']['epochs'] = [5]\n",
        "        TRAINING_CONFIG['hyperparameters']['batch_size'] = [64]\n",
        "        TRAINING_CONFIG['hyperparameters']['learning_rate'] = [lr]\n",
        "        \n",
        "        print(f\"\\n=== Config: {wc['name']} | lr={lr} ===\")\n",
        "        X, y, le = preprocess_pipeline()\n",
        "        model, log, path = train_model(X, y, model_type='gru')\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "        rep = evaluate_model_comprehensive(model, X_te, y_te, le.classes_.tolist(), output_dir=f'notebook_eval/{wc[\"name\"]}_lr{lr}')\n",
        "        results.append({'window': wc['name'], 'lr': lr, 'accuracy': rep['basic_metrics']['accuracy']})\n",
        "\n",
        "# Ripristina config\n",
        "PREPROCESSING_CONFIG.update(base_prep)\n",
        "TRAINING_CONFIG.update(base_train)\n",
        "\n",
        "pd.DataFrame(results).sort_values('accuracy', ascending=False).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Riproducibilità\n",
        "Impostiamo i seed per rendere i risultati ripetibili (entro i limiti dell'hardware).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print('Seed impostato:', SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Audit dati e feature\n",
        "Controlliamo distribuzione classi, percentuali, e presenza di attacchi rilevanti nel sample selezionato.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def audit_distribution(y, label_encoder):\n",
        "    counts = Counter(y)\n",
        "    classes = label_encoder.classes_.tolist()\n",
        "    dist = {classes[i]: int(counts.get(i, 0)) for i in range(len(classes))}\n",
        "    total = sum(dist.values())\n",
        "    df = pd.DataFrame({\n",
        "        'classe': list(dist.keys()),\n",
        "        'conteggio': list(dist.values())\n",
        "    }).sort_values('conteggio', ascending=False)\n",
        "    df['percentuale'] = (df['conteggio'] / total * 100).round(2)\n",
        "    return df\n",
        "\n",
        "# Esempio live (riutilizza X,y,label_encoder se esistono)\n",
        "try:\n",
        "    audit_distribution(y, label_encoder)\n",
        "except Exception as e:\n",
        "    print('Esegui prima il smoke test per generare X,y,label_encoder')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Metriche e calibrazione\n",
        "Oltre alle metriche standard, aggiungiamo ECE (Expected Calibration Error) per valutare la calibrazione delle probabilità.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def expected_calibration_error(y_true, y_proba, n_bins=10):\n",
        "    # binning su max probability\n",
        "    confidences = y_proba.max(axis=1)\n",
        "    predictions = y_proba.argmax(axis=1)\n",
        "    accuracies = (predictions == y_true).astype(float)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
        "        if mask.any():\n",
        "            avg_conf = confidences[mask].mean()\n",
        "            avg_acc = accuracies[mask].mean()\n",
        "            ece += np.abs(avg_acc - avg_conf) * mask.mean()\n",
        "    return float(ece)\n",
        "\n",
        "# Esempio: usa il modello dallo smoke test, se disponibile\n",
        "try:\n",
        "    y_proba = model.predict(X_te, verbose=0)\n",
        "    print('ECE:', expected_calibration_error(y_te, y_proba, n_bins=15))\n",
        "except Exception as e:\n",
        "    print('Esegui prima smoke test e valutazione per avere y_te e y_proba')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Documentazione file-per-file\n",
        "In questa sezione spieghiamo le scelte implementative nei file chiave: `preprocessing/process.py`, `training/train.py`, `evaluation/metrics.py`, `benchmark.py` e `config.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import inspect, textwrap\n",
        "import preprocessing.process as P\n",
        "import training.train as T\n",
        "import evaluation.metrics as E\n",
        "import benchmark as B\n",
        "import config as C\n",
        "\n",
        "def show_source(obj, start=None, end=None):\n",
        "    src = inspect.getsource(obj)\n",
        "    if start or end:\n",
        "        lines = src.splitlines()\n",
        "        src = \"\\n\".join(lines[start:end])\n",
        "    print(textwrap.dedent(src))\n",
        "\n",
        "print('--- config.py (sezioni principali) ---')\n",
        "print('DATA_CONFIG:'); print(C.DATA_CONFIG)\n",
        "print('\\nPREPROCESSING_CONFIG:'); print(C.PREPROCESSING_CONFIG)\n",
        "print('\\nTRAINING_CONFIG:'); print(C.TRAINING_CONFIG)\n",
        "\n",
        "print('\\n--- preprocessing.process: load_and_balance_dataset ---')\n",
        "show_source(P.load_and_balance_dataset)\n",
        "print('\\n--- preprocessing.process: preprocess_pipeline ---')\n",
        "show_source(P.preprocess_pipeline)\n",
        "\n",
        "print('\\n--- training.train: _train_k_fold ---')\n",
        "show_source(T._train_k_fold)\n",
        "print('\\n--- training.train: _train_split ---')\n",
        "show_source(T._train_split)\n",
        "\n",
        "print('\\n--- evaluation.metrics: evaluate_model_comprehensive ---')\n",
        "show_source(E.evaluate_model_comprehensive)\n",
        "\n",
        "print('\\n--- benchmark.SNNIDSBenchmark (run_smoke_test) ---')\n",
        "show_source(B.SNNIDSBenchmark.run_smoke_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Note progettuali\n",
        "- Zero hard-code: tutte le scelte sono in `config.py`; il notebook applica override solo per esperimenti.\n",
        "- Pipeline riproducibile: sampling e bilanciamento documentati; seed fissati.\n",
        "- Training recipe tabulari: GRU su finestre 3D, scaling per-fold, StratifiedKFold.\n",
        "- Metriche e PNG: confusion matrix dettagliata, cybersecurity, ROC, accuracy per classe, ECE.\n",
        "- Notebook auditabile: usa `inspect` per mostrare il codice sorgente eseguito.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Limitazioni\n",
        "- I risultati su classi rare vanno interpretati con cautela; forniamo sempre breakdown per‑classe.\n",
        "- La calibrazione (ECE) è informativa ma non esaustiva.\n",
        "- Il bilanciamento “security” riduce bias ma non sostituisce protocolli di acquisizione realistici.\n",
        "- Evitiamo leakage scalando per‑fold; ulteriori audit sono comunque consigliati in ambienti operativi.\n",
        "- Per produzione sono necessarie valutazioni cost‑sensitive e monitoraggio del drift.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
